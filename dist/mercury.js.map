{"version":3,"file":null,"sources":["../src/utils/range.js","../src/utils/validate-url.js","../src/utils/errors.js","../src/resource/utils/constants.js","../src/resource/utils/fetch-resource.js","../src/resource/utils/dom/normalize-meta-tags.js","../src/utils/dom/constants.js","../src/utils/dom/strip-unlikely-candidates.js","../src/utils/dom/brs-to-ps.js","../src/utils/dom/paragraphize.js","../src/utils/dom/convert-to-paragraphs.js","../src/utils/dom/convert-node-to.js","../src/utils/dom/clean-images.js","../src/utils/dom/mark-to-keep.js","../src/utils/dom/strip-junk-tags.js","../src/utils/dom/clean-h-ones.js","../src/utils/dom/clean-attributes.js","../src/utils/dom/remove-empty.js","../src/extractors/generic/content/scoring/constants.js","../src/extractors/generic/content/scoring/get-weight.js","../src/extractors/generic/content/scoring/get-score.js","../src/extractors/generic/content/scoring/score-commas.js","../src/extractors/generic/content/scoring/score-length.js","../src/extractors/generic/content/scoring/score-paragraph.js","../src/extractors/generic/content/scoring/set-score.js","../src/extractors/generic/content/scoring/add-score.js","../src/extractors/generic/content/scoring/add-to-parent.js","../src/extractors/generic/content/scoring/get-or-init-score.js","../src/extractors/generic/content/scoring/score-node.js","../src/extractors/generic/content/scoring/score-content.js","../src/utils/text/normalize-spaces.js","../src/utils/text/extract-from-url.js","../src/utils/text/constants.js","../src/utils/text/page-num-from-url.js","../src/utils/text/remove-anchor.js","../src/utils/text/article-base-url.js","../src/utils/text/has-sentence-end.js","../src/utils/text/excerpt-content.js","../src/extractors/generic/content/scoring/merge-siblings.js","../src/extractors/generic/content/scoring/find-top-candidate.js","../src/extractors/generic/content/scoring/index.js","../src/utils/dom/clean-tags.js","../src/utils/dom/clean-headers.js","../src/utils/dom/rewrite-top-level.js","../src/utils/dom/make-links-absolute.js","../src/utils/dom/link-density.js","../src/utils/dom/extract-from-meta.js","../src/utils/dom/extract-from-selectors.js","../src/utils/dom/strip-tags.js","../src/utils/dom/within-comment.js","../src/utils/dom/node-is-sufficient.js","../src/utils/dom/is-wordpress.js","../src/utils/dom/get-attrs.js","../src/utils/dom/set-attr.js","../src/utils/dom/set-attrs.js","../src/utils/dom/index.js","../src/resource/utils/dom/constants.js","../src/resource/utils/dom/convert-lazy-loaded-images.js","../src/resource/utils/dom/clean.js","../src/resource/index.js","../src/utils/merge-supported-domains.js","../src/extractors/custom/blogspot.com/index.js","../src/extractors/custom/nymag.com/index.js","../src/extractors/custom/wikipedia.org/index.js","../src/extractors/custom/twitter.com/index.js","../src/extractors/custom/www.nytimes.com/index.js","../src/extractors/custom/www.theatlantic.com/index.js","../src/extractors/custom/www.newyorker.com/index.js","../src/extractors/custom/www.wired.com/index.js","../src/extractors/custom/www.msn.com/index.js","../src/extractors/custom/www.yahoo.com/index.js","../src/extractors/custom/www.buzzfeed.com/index.js","../src/extractors/custom/fandom.wikia.com/index.js","../src/extractors/custom/www.littlethings.com/index.js","../src/extractors/custom/www.politico.com/index.js","../src/extractors/custom/deadspin.com/index.js","../src/extractors/custom/www.broadwayworld.com/index.js","../src/extractors/custom/www.apartmenttherapy.com/index.js","../src/extractors/custom/medium.com/index.js","../src/extractors/all.js","../src/cleaners/constants.js","../src/cleaners/author.js","../src/cleaners/lead-image-url.js","../src/cleaners/dek.js","../src/cleaners/date-published.js","../src/cleaners/content.js","../src/cleaners/title.js","../src/cleaners/resolve-split-title.js","../src/cleaners/index.js","../src/extractors/generic/content/extract-best-node.js","../src/extractors/generic/content/extractor.js","../src/extractors/generic/title/constants.js","../src/extractors/generic/title/extractor.js","../src/extractors/generic/author/constants.js","../src/extractors/generic/author/extractor.js","../src/extractors/generic/date-published/constants.js","../src/extractors/generic/date-published/extractor.js","../src/extractors/generic/dek/extractor.js","../src/extractors/generic/lead-image-url/constants.js","../src/extractors/generic/lead-image-url/score-image.js","../src/extractors/generic/lead-image-url/extractor.js","../src/extractors/generic/next-page-url/scoring/utils/score-similarity.js","../src/extractors/generic/next-page-url/scoring/utils/score-link-text.js","../src/extractors/generic/next-page-url/scoring/utils/score-page-in-link.js","../src/extractors/generic/next-page-url/scoring/constants.js","../src/extractors/generic/next-page-url/scoring/utils/score-extraneous-links.js","../src/extractors/generic/next-page-url/scoring/utils/score-by-parents.js","../src/extractors/generic/next-page-url/scoring/utils/score-prev-link.js","../src/extractors/generic/next-page-url/scoring/utils/should-score.js","../src/extractors/generic/next-page-url/scoring/utils/score-base-url.js","../src/extractors/generic/next-page-url/scoring/utils/score-next-link-text.js","../src/extractors/generic/next-page-url/scoring/utils/score-cap-links.js","../src/extractors/generic/next-page-url/scoring/score-links.js","../src/extractors/generic/next-page-url/extractor.js","../src/extractors/generic/url/constants.js","../src/extractors/generic/url/extractor.js","../src/extractors/generic/excerpt/constants.js","../src/extractors/generic/excerpt/extractor.js","../src/extractors/generic/word-count/extractor.js","../src/extractors/generic/index.js","../src/extractors/get-extractor.js","../src/extractors/root-extractor.js","../src/extractors/collect-all-pages.js","../src/mercury.js"],"sourcesContent":["export default function* range(start = 1, end = 1) {\n  while (start <= end) {\n    yield start += 1;\n  }\n}\n","// extremely simple url validation as a first step\nexport default function validateUrl({ hostname }) {\n  // If this isn't a valid url, return an error message\n  return !!hostname;\n}\n","const Errors = {\n  badUrl: {\n    error: true,\n    messages: 'The url parameter passed does not look like a valid URL. Please check your data and try again.',\n  },\n};\n\nexport default Errors;\n","import cheerio from 'cheerio';\n\n// Browser does not like us setting user agent\nexport const REQUEST_HEADERS = cheerio.browser ? {} : {\n  'User-Agent': 'Mercury - https://mercury.postlight.com/web-parser/',\n};\n\n// The number of milliseconds to attempt to fetch a resource before timing out.\nexport const FETCH_TIMEOUT = 10000;\n\n// Content types that we do not extract content from\nconst BAD_CONTENT_TYPES = [\n  'audio/mpeg',\n  'image/gif',\n  'image/jpeg',\n  'image/jpg',\n];\n\nexport const BAD_CONTENT_TYPES_RE = new RegExp(`^(${BAD_CONTENT_TYPES.join('|')})$`, 'i');\n\n// Use this setting as the maximum size an article can be\n// for us to attempt parsing. Defaults to 5 MB.\nexport const MAX_CONTENT_LENGTH = 5242880;\n\n// Turn the global proxy on or off\n// Proxying is not currently enabled in Python source\n// so not implementing logic in port.\nexport const PROXY_DOMAINS = false;\nexport const REQUESTS_PROXIES = {\n  http: 'http://38.98.105.139:33333',\n  https: 'http://38.98.105.139:33333',\n};\n\nexport const DOMAINS_TO_PROXY = [\n  'nih.gov',\n  'gutenberg.org',\n];\n","import URL from 'url';\nimport request from 'request';\nimport { Errors } from 'utils';\n\nimport {\n  REQUEST_HEADERS,\n  FETCH_TIMEOUT,\n  BAD_CONTENT_TYPES_RE,\n  MAX_CONTENT_LENGTH,\n} from './constants';\n\nfunction get(options) {\n  return new Promise((resolve, reject) => {\n    request(options, (err, response, body) => {\n      if (err) {\n        reject(err);\n      } else {\n        resolve({ body, response });\n      }\n    });\n  });\n}\n\n// Evaluate a response to ensure it's something we should be keeping.\n// This does not validate in the sense of a response being 200 level or\n// not. Validation here means that we haven't found reason to bail from\n// further processing of this url.\n\nexport function validateResponse(response, parseNon2xx = false) {\n  // Check if we got a valid status code\n  // This isn't great, but I'm requiring a statusMessage to be set\n  // before short circuiting b/c nock doesn't set it in tests\n  // statusMessage only not set in nock response, in which case\n  // I check statusCode, which is currently only 200 for OK responses\n  // in tests\n  if (\n    (response.statusMessage && response.statusMessage !== 'OK') ||\n      response.statusCode !== 200\n  ) {\n    if (!response.statusCode) {\n      throw new Error(\n        `Unable to fetch content. Original exception was ${response.error}`\n      );\n    } else if (!parseNon2xx) {\n      throw new Error(\n        `Resource returned a response status code of ${response.statusCode} and resource was instructed to reject non-2xx level status codes.`\n      );\n    }\n  }\n\n  const {\n    'content-type': contentType,\n    'content-length': contentLength,\n  } = response.headers;\n\n  // Check that the content is not in BAD_CONTENT_TYPES\n  if (BAD_CONTENT_TYPES_RE.test(contentType)) {\n    throw new Error(\n      `Content-type for this resource was ${contentType} and is not allowed.`\n    );\n  }\n\n  // Check that the content length is below maximum\n  if (contentLength > MAX_CONTENT_LENGTH) {\n    throw new Error(\n      `Content for this resource was too large. Maximum content length is ${MAX_CONTENT_LENGTH}.`\n    );\n  }\n\n  return true;\n}\n\n// Grabs the last two pieces of the URL and joins them back together\n// This is to get the 'livejournal.com' from 'erotictrains.livejournal.com'\nexport function baseDomain({ host }) {\n  return host.split('.').slice(-2).join('.');\n}\n\n// Set our response attribute to the result of fetching our URL.\n// TODO: This should gracefully handle timeouts and raise the\n//       proper exceptions on the many failure cases of HTTP.\n// TODO: Ensure we are not fetching something enormous. Always return\n//       unicode content for HTML, with charset conversion.\n\nexport default async function fetchResource(url, parsedUrl) {\n  parsedUrl = parsedUrl || URL.parse(encodeURI(url));\n\n  const options = {\n    url: parsedUrl.href,\n    headers: { ...REQUEST_HEADERS },\n    timeout: FETCH_TIMEOUT,\n    // Don't set encoding; fixes issues\n    // w/gzipped responses\n    encoding: null,\n    // Accept cookies\n    jar: true,\n    // Accept and decode gzip\n    gzip: true,\n    // Follow any redirect\n    followAllRedirects: true,\n  };\n\n  const { response, body } = await get(options);\n\n  try {\n    validateResponse(response);\n    return {\n      body,\n      response,\n    };\n  } catch (e) {\n    return Errors.badUrl;\n  }\n}\n","function convertMetaProp($, from, to) {\n  $(`meta[${from}]`).each((_, node) => {\n    const $node = $(node);\n\n    const value = $node.attr(from);\n    $node.attr(to, value);\n    $node.removeAttr(from);\n  });\n\n  return $;\n}\n\n// For ease of use in extracting from meta tags,\n// replace the \"content\" attribute on meta tags with the\n// \"value\" attribute.\n//\n// In addition, normalize 'property' attributes to 'name' for ease of\n// querying later. See, e.g., og or twitter meta tags.\n\nexport default function normalizeMetaTags($) {\n  $ = convertMetaProp($, 'content', 'value');\n  $ = convertMetaProp($, 'property', 'name');\n  return $;\n}\n","// Spacer images to be removed\nexport const SPACER_RE = new RegExp('trans|transparent|spacer|blank', 'i');\n\n// The class we will use to mark elements we want to keep\n// but would normally remove\nexport const KEEP_CLASS = 'mercury-parser-keep';\n\nexport const KEEP_SELECTORS = [\n  'iframe[src^=\"https://www.youtube.com\"]',\n  'iframe[src^=\"http://www.youtube.com\"]',\n  'iframe[src^=\"https://player.vimeo\"]',\n  'iframe[src^=\"http://player.vimeo\"]',\n];\n\n// A list of tags to strip from the output if we encounter them.\nexport const STRIP_OUTPUT_TAGS = [\n  'title',\n  'script',\n  'noscript',\n  'link',\n  'style',\n  'hr',\n  'embed',\n  'iframe',\n  'object',\n];\n\n// cleanAttributes\nexport const REMOVE_ATTRS = ['style', 'align'];\nexport const REMOVE_ATTR_SELECTORS = REMOVE_ATTRS.map(selector => `[${selector}]`);\nexport const REMOVE_ATTR_LIST = REMOVE_ATTRS.join(',');\nexport const WHITELIST_ATTRS = ['src', 'srcset', 'href', 'class', 'id', 'alt'];\nexport const WHITELIST_ATTRS_RE = new RegExp(`^(${WHITELIST_ATTRS.join('|')})$`, 'i');\n\n// removeEmpty\nexport const REMOVE_EMPTY_TAGS = ['p'];\nexport const REMOVE_EMPTY_SELECTORS = REMOVE_EMPTY_TAGS.map(tag => `${tag}:empty`).join(',');\n\n// cleanTags\nexport const CLEAN_CONDITIONALLY_TAGS = ['ul', 'ol', 'table', 'div', 'button', 'form'].join(',');\n\n// cleanHeaders\nconst HEADER_TAGS = ['h2', 'h3', 'h4', 'h5', 'h6'];\nexport const HEADER_TAG_LIST = HEADER_TAGS.join(',');\n\n// // CONTENT FETCHING CONSTANTS ////\n\n// A list of strings that can be considered unlikely candidates when\n// extracting content from a resource. These strings are joined together\n// and then tested for existence using re:test, so may contain simple,\n// non-pipe style regular expression queries if necessary.\nexport const UNLIKELY_CANDIDATES_BLACKLIST = [\n  'ad-break',\n  'adbox',\n  'advert',\n  'addthis',\n  'agegate',\n  'aux',\n  'blogger-labels',\n  'combx',\n  'comment',\n  'conversation',\n  'disqus',\n  'entry-unrelated',\n  'extra',\n  'foot',\n  // 'form', // This is too generic, has too many false positives\n  'header',\n  'hidden',\n  'loader',\n  'login',                     // Note: This can hit 'blogindex'.\n  'menu',\n  'meta',\n  'nav',\n  'outbrain',\n  'pager',\n  'pagination',\n  'predicta',                  // readwriteweb inline ad box\n  'presence_control_external', // lifehacker.com container full of false positives\n  'popup',\n  'printfriendly',\n  'related',\n  'remove',\n  'remark',\n  'rss',\n  'share',\n  'shoutbox',\n  'sidebar',\n  'sociable',\n  'sponsor',\n  'taboola',\n  'tools',\n];\n\n// A list of strings that can be considered LIKELY candidates when\n// extracting content from a resource. Essentially, the inverse of the\n// blacklist above - if something matches both blacklist and whitelist,\n// it is kept. This is useful, for example, if something has a className\n// of \"rss-content entry-content\". It matched 'rss', so it would normally\n// be removed, however, it's also the entry content, so it should be left\n// alone.\n//\n// These strings are joined together and then tested for existence using\n// re:test, so may contain simple, non-pipe style regular expression queries\n// if necessary.\nexport const UNLIKELY_CANDIDATES_WHITELIST = [\n  'and',\n  'article',\n  'body',\n  'blogindex',\n  'column',\n  'content',\n  'entry-content-asset',\n  'format', // misuse of form\n  'hfeed',\n  'hentry',\n  'hatom',\n  'main',\n  'page',\n  'posts',\n  'shadow',\n];\n\n// A list of tags which, if found inside, should cause a <div /> to NOT\n// be turned into a paragraph tag. Shallow div tags without these elements\n// should be turned into <p /> tags.\nexport const DIV_TO_P_BLOCK_TAGS = [\n  'a',\n  'blockquote',\n  'dl',\n  'div',\n  'img',\n  'p',\n  'pre',\n  'table',\n].join(',');\n\n// A list of tags that should be ignored when trying to find the top candidate\n// for a document.\nexport const NON_TOP_CANDIDATE_TAGS = [\n  'br',\n  'b',\n  'i',\n  'label',\n  'hr',\n  'area',\n  'base',\n  'basefont',\n  'input',\n  'img',\n  'link',\n  'meta',\n];\n\nexport const NON_TOP_CANDIDATE_TAGS_RE =\n  new RegExp(`^(${NON_TOP_CANDIDATE_TAGS.join('|')})$`, 'i');\n\n// A list of selectors that specify, very clearly, either hNews or other\n// very content-specific style content, like Blogger templates.\n// More examples here: http://microformats.org/wiki/blog-post-formats\nexport const HNEWS_CONTENT_SELECTORS = [\n  ['.hentry', '.entry-content'],\n  ['entry', '.entry-content'],\n  ['.entry', '.entry_content'],\n  ['.post', '.postbody'],\n  ['.post', '.post_body'],\n  ['.post', '.post-body'],\n];\n\nexport const PHOTO_HINTS = [\n  'figure',\n  'photo',\n  'image',\n  'caption',\n];\nexport const PHOTO_HINTS_RE = new RegExp(PHOTO_HINTS.join('|'), 'i');\n\n// A list of strings that denote a positive scoring for this content as being\n// an article container. Checked against className and id.\n//\n// TODO: Perhaps have these scale based on their odds of being quality?\nexport const POSITIVE_SCORE_HINTS = [\n  'article',\n  'articlecontent',\n  'instapaper_body',\n  'blog',\n  'body',\n  'content',\n  'entry-content-asset',\n  'entry',\n  'hentry',\n  'main',\n  'Normal',\n  'page',\n  'pagination',\n  'permalink',\n  'post',\n  'story',\n  'text',\n  '[-_]copy', // usatoday\n  '\\\\Bcopy',\n];\n\n// The above list, joined into a matching regular expression\nexport const POSITIVE_SCORE_RE = new RegExp(POSITIVE_SCORE_HINTS.join('|'), 'i');\n\n// Readability publisher-specific guidelines\nexport const READABILITY_ASSET = new RegExp('entry-content-asset', 'i');\n\n// A list of strings that denote a negative scoring for this content as being\n// an article container. Checked against className and id.\n//\n// TODO: Perhaps have these scale based on their odds of being quality?\nexport const NEGATIVE_SCORE_HINTS = [\n  'adbox',\n  'advert',\n  'author',\n  'bio',\n  'bookmark',\n  'bottom',\n  'byline',\n  'clear',\n  'com-',\n  'combx',\n  'comment',\n  'comment\\\\B',\n  'contact',\n  'copy',\n  'credit',\n  'crumb',\n  'date',\n  'deck',\n  'excerpt',\n  'featured', // tnr.com has a featured_content which throws us off\n  'foot',\n  'footer',\n  'footnote',\n  'graf',\n  'head',\n  'info',\n  'infotext', // newscientist.com copyright\n  'instapaper_ignore',\n  'jump',\n  'linebreak',\n  'link',\n  'masthead',\n  'media',\n  'meta',\n  'modal',\n  'outbrain', // slate.com junk\n  'promo',\n  'pr_', // autoblog - press release\n  'related',\n  'respond',\n  'roundcontent', // lifehacker restricted content warning\n  'scroll',\n  'secondary',\n  'share',\n  'shopping',\n  'shoutbox',\n  'side',\n  'sidebar',\n  'sponsor',\n  'stamp',\n  'sub',\n  'summary',\n  'tags',\n  'tools',\n  'widget',\n];\n// The above list, joined into a matching regular expression\nexport const NEGATIVE_SCORE_RE = new RegExp(NEGATIVE_SCORE_HINTS.join('|'), 'i');\n\n// XPath to try to determine if a page is wordpress. Not always successful.\nexport const IS_WP_SELECTOR = 'meta[name=generator][value^=WordPress]';\n\n// Match a digit. Pretty clear.\nexport const DIGIT_RE = new RegExp('[0-9]');\n\n// A list of words that, if found in link text or URLs, likely mean that\n// this link is not a next page link.\nexport const EXTRANEOUS_LINK_HINTS = [\n  'print',\n  'archive',\n  'comment',\n  'discuss',\n  'e-mail',\n  'email',\n  'share',\n  'reply',\n  'all',\n  'login',\n  'sign',\n  'single',\n  'adx',\n  'entry-unrelated',\n];\nexport const EXTRANEOUS_LINK_HINTS_RE = new RegExp(EXTRANEOUS_LINK_HINTS.join('|'), 'i');\n\n// Match any phrase that looks like it could be page, or paging, or pagination\nexport const PAGE_RE = new RegExp('pag(e|ing|inat)', 'i');\n\n// Match any link text/classname/id that looks like it could mean the next\n// page. Things like: next, continue, >, >>, » but not >|, »| as those can\n// mean last page.\n// export const NEXT_LINK_TEXT_RE = new RegExp('(next|weiter|continue|>([^\\|]|$)|»([^\\|]|$))', 'i');\nexport const NEXT_LINK_TEXT_RE = /(next|weiter|continue|>([^|]|$)|»([^|]|$))/i;\n\n// Match any link text/classname/id that looks like it is an end link: things\n// like \"first\", \"last\", \"end\", etc.\nexport const CAP_LINK_TEXT_RE = new RegExp('(first|last|end)', 'i');\n\n// Match any link text/classname/id that looks like it means the previous\n// page.\nexport const PREV_LINK_TEXT_RE = new RegExp('(prev|earl|old|new|<|«)', 'i');\n\n// Match 2 or more consecutive <br> tags\nexport const BR_TAGS_RE = new RegExp('(<br[^>]*>[ \\n\\r\\t]*){2,}', 'i');\n\n// Match 1 BR tag.\nexport const BR_TAG_RE = new RegExp('<br[^>]*>', 'i');\n\n// A list of all of the block level tags known in HTML5 and below. Taken from\n// http://bit.ly/qneNIT\nexport const BLOCK_LEVEL_TAGS = [\n  'article',\n  'aside',\n  'blockquote',\n  'body',\n  'br',\n  'button',\n  'canvas',\n  'caption',\n  'col',\n  'colgroup',\n  'dd',\n  'div',\n  'dl',\n  'dt',\n  'embed',\n  'fieldset',\n  'figcaption',\n  'figure',\n  'footer',\n  'form',\n  'h1',\n  'h2',\n  'h3',\n  'h4',\n  'h5',\n  'h6',\n  'header',\n  'hgroup',\n  'hr',\n  'li',\n  'map',\n  'object',\n  'ol',\n  'output',\n  'p',\n  'pre',\n  'progress',\n  'section',\n  'table',\n  'tbody',\n  'textarea',\n  'tfoot',\n  'th',\n  'thead',\n  'tr',\n  'ul',\n  'video',\n];\nexport const BLOCK_LEVEL_TAGS_RE = new RegExp(`^(${BLOCK_LEVEL_TAGS.join('|')})$`, 'i');\n\n// The removal is implemented as a blacklist and whitelist, this test finds\n// blacklisted elements that aren't whitelisted. We do this all in one\n// expression-both because it's only one pass, and because this skips the\n// serialization for whitelisted nodes.\nconst candidatesBlacklist = UNLIKELY_CANDIDATES_BLACKLIST.join('|');\nexport const CANDIDATES_BLACKLIST = new RegExp(candidatesBlacklist, 'i');\n\nconst candidatesWhitelist = UNLIKELY_CANDIDATES_WHITELIST.join('|');\nexport const CANDIDATES_WHITELIST = new RegExp(candidatesWhitelist, 'i');\n\nexport const UNLIKELY_RE = new RegExp(`!(${candidatesWhitelist})|(${candidatesBlacklist})`, 'i');\n\nexport const PARAGRAPH_SCORE_TAGS = new RegExp('^(p|li|span|pre)$', 'i');\nexport const CHILD_CONTENT_TAGS = new RegExp('^(td|blockquote|ol|ul|dl)$', 'i');\nexport const BAD_TAGS = new RegExp('^(address|form)$', 'i');\n\nexport const HTML_OR_BODY_RE = new RegExp('^(html|body)$', 'i');\n","import {\n  CANDIDATES_WHITELIST,\n  CANDIDATES_BLACKLIST,\n} from './constants';\n\nexport default function stripUnlikelyCandidates($) {\n  //  Loop through the provided document and remove any non-link nodes\n  //  that are unlikely candidates for article content.\n  //\n  //  Links are ignored because there are very often links to content\n  //  that are identified as non-body-content, but may be inside\n  //  article-like content.\n  //\n  //  :param $: a cheerio object to strip nodes from\n  //  :return $: the cleaned cheerio object\n  $('*').not('a').each((index, node) => {\n    const $node = $(node);\n    const classes = $node.attr('class');\n    const id = $node.attr('id');\n    if (!id && !classes) return;\n\n    const classAndId = `${classes || ''} ${id || ''}`;\n    if (CANDIDATES_WHITELIST.test(classAndId)) {\n      return;\n    } else if (CANDIDATES_BLACKLIST.test(classAndId)) {\n      $node.remove();\n    }\n  });\n\n  return $;\n}\n","import { paragraphize } from './index';\n\n// ## NOTES:\n// Another good candidate for refactoring/optimizing.\n// Very imperative code, I don't love it. - AP\n\n//  Given cheerio object, convert consecutive <br /> tags into\n//  <p /> tags instead.\n//\n//  :param $: A cheerio object\n\nexport default function brsToPs($) {\n  let collapsing = false;\n  $('br').each((index, element) => {\n    const $element = $(element);\n    const nextElement = $element.next().get(0);\n\n    if (nextElement && nextElement.tagName.toLowerCase() === 'br') {\n      collapsing = true;\n      $element.remove();\n    } else if (collapsing) {\n      collapsing = false;\n      // $(element).replaceWith('<p />')\n      paragraphize(element, $, true);\n    }\n  });\n\n  return $;\n}\n","import { BLOCK_LEVEL_TAGS_RE } from './constants';\n\n// Given a node, turn it into a P if it is not already a P, and\n// make sure it conforms to the constraints of a P tag (I.E. does\n// not contain any other block tags.)\n//\n// If the node is a <br />, it treats the following inline siblings\n// as if they were its children.\n//\n// :param node: The node to paragraphize; this is a raw node\n// :param $: The cheerio object to handle dom manipulation\n// :param br: Whether or not the passed node is a br\n\nexport default function paragraphize(node, $, br = false) {\n  const $node = $(node);\n\n  if (br) {\n    let sibling = node.nextSibling;\n    const p = $('<p></p>');\n\n    // while the next node is text or not a block level element\n    // append it to a new p node\n    while (sibling && !(sibling.tagName && BLOCK_LEVEL_TAGS_RE.test(sibling.tagName))) {\n      const nextSibling = sibling.nextSibling;\n      $(sibling).appendTo(p);\n      sibling = nextSibling;\n    }\n\n    $node.replaceWith(p);\n    $node.remove();\n    return $;\n  }\n\n  return $;\n}\n","import { brsToPs, convertNodeTo } from 'utils/dom';\n\nimport { DIV_TO_P_BLOCK_TAGS } from './constants';\n\nfunction convertDivs($) {\n  $('div').each((index, div) => {\n    const $div = $(div);\n    const convertable = $div.children(DIV_TO_P_BLOCK_TAGS).length === 0;\n\n    if (convertable) {\n      convertNodeTo($div, $, 'p');\n    }\n  });\n\n  return $;\n}\n\nfunction convertSpans($) {\n  $('span').each((index, span) => {\n    const $span = $(span);\n    const convertable = $span.parents('p, div').length === 0;\n    if (convertable) {\n      convertNodeTo($span, $, 'p');\n    }\n  });\n\n  return $;\n}\n\n// Loop through the provided doc, and convert any p-like elements to\n// actual paragraph tags.\n//\n//   Things fitting this criteria:\n//   * Multiple consecutive <br /> tags.\n//   * <div /> tags without block level elements inside of them\n//   * <span /> tags who are not children of <p /> or <div /> tags.\n//\n//   :param $: A cheerio object to search\n//   :return cheerio object with new p elements\n//   (By-reference mutation, though. Returned just for convenience.)\n\nexport default function convertToParagraphs($) {\n  $ = brsToPs($);\n  $ = convertDivs($);\n  $ = convertSpans($);\n\n  return $;\n}\n","import { getAttrs } from 'utils/dom';\n\nexport default function convertNodeTo($node, $, tag = 'p') {\n  const node = $node.get(0);\n  if (!node) {\n    return $;\n  }\n  const attrs = getAttrs(node) || {};\n  // console.log(attrs)\n\n  const attribString = Reflect.ownKeys(attrs)\n                              .map(key => `${key}=${attrs[key]}`)\n                              .join(' ');\n  let html;\n\n  if ($.browser) {\n    // In the browser, the contents of noscript tags aren't rendered, therefore\n    // transforms on the noscript tag (commonly used for lazy-loading) don't work\n    // as expected. This test case handles that\n    html = node.tagName.toLowerCase() === 'noscript' ? $node.text() : $node.html();\n  } else {\n    html = $node.contents();\n  }\n  $node.replaceWith(\n    `<${tag} ${attribString}>${html}</${tag}>`\n  );\n  return $;\n}\n","import { SPACER_RE } from './constants';\n\nfunction cleanForHeight($img, $) {\n  const height = parseInt($img.attr('height'), 10);\n  const width = parseInt($img.attr('width'), 10) || 20;\n\n  // Remove images that explicitly have very small heights or\n  // widths, because they are most likely shims or icons,\n  // which aren't very useful for reading.\n  if ((height || 20) < 10 || width < 10) {\n    $img.remove();\n  } else if (height) {\n    // Don't ever specify a height on images, so that we can\n    // scale with respect to width without screwing up the\n    // aspect ratio.\n    $img.removeAttr('height');\n  }\n\n  return $;\n}\n\n// Cleans out images where the source string matches transparent/spacer/etc\n// TODO This seems very aggressive - AP\nfunction removeSpacers($img, $) {\n  if (SPACER_RE.test($img.attr('src'))) {\n    $img.remove();\n  }\n\n  return $;\n}\n\nexport default function cleanImages($article, $) {\n  $article.find('img').each((index, img) => {\n    const $img = $(img);\n\n    cleanForHeight($img, $);\n    removeSpacers($img, $);\n  });\n\n  return $;\n}\n","import URL from 'url';\n\nimport {\n  KEEP_SELECTORS,\n  KEEP_CLASS,\n} from './constants';\n\nexport default function markToKeep(article, $, url, tags = []) {\n  if (tags.length === 0) {\n    tags = KEEP_SELECTORS;\n  }\n\n  if (url) {\n    const { protocol, hostname } = URL.parse(url);\n    tags = [...tags, `iframe[src^=\"${protocol}//${hostname}\"]`];\n  }\n\n  $(tags.join(','), article).addClass(KEEP_CLASS);\n\n  return $;\n}\n","import {\n  STRIP_OUTPUT_TAGS,\n  KEEP_CLASS,\n} from './constants';\n\nexport default function stripJunkTags(article, $, tags = []) {\n  if (tags.length === 0) {\n    tags = STRIP_OUTPUT_TAGS;\n  }\n\n  // Remove matching elements, but ignore\n  // any element with a class of mercury-parser-keep\n  $(tags.join(','), article).not(`.${KEEP_CLASS}`).remove();\n\n  // Remove the mercury-parser-keep class from result\n  $(`.${KEEP_CLASS}`, article).removeClass(KEEP_CLASS);\n\n  return $;\n}\n","import { convertNodeTo } from 'utils/dom';\n\n// H1 tags are typically the article title, which should be extracted\n// by the title extractor instead. If there's less than 3 of them (<3),\n// strip them. Otherwise, turn 'em into H2s.\nexport default function cleanHOnes(article, $) {\n  const $hOnes = $('h1', article);\n\n  if ($hOnes.length < 3) {\n    $hOnes.each((index, node) => $(node).remove());\n  } else {\n    $hOnes.each((index, node) => {\n      convertNodeTo($(node), $, 'h2');\n    });\n  }\n\n  return $;\n}\n","import {\n  getAttrs,\n  setAttrs,\n} from 'utils/dom';\n\nimport { WHITELIST_ATTRS_RE } from './constants';\n\nfunction removeAllButWhitelist($article) {\n  $article.find('*').each((index, node) => {\n    const attrs = getAttrs(node);\n\n    setAttrs(node, Reflect.ownKeys(attrs).reduce((acc, attr) => {\n      if (WHITELIST_ATTRS_RE.test(attr)) {\n        return { ...acc, [attr]: attrs[attr] };\n      }\n\n      return acc;\n    }, {}));\n  });\n\n  return $article;\n}\n\n// function removeAttrs(article, $) {\n//   REMOVE_ATTRS.forEach((attr) => {\n//     $(`[${attr}]`, article).removeAttr(attr);\n//   });\n// }\n\n// Remove attributes like style or align\nexport default function cleanAttributes($article) {\n  // Grabbing the parent because at this point\n  // $article will be wrapped in a div which will\n  // have a score set on it.\n  return removeAllButWhitelist(\n    $article.parent().length ?\n      $article.parent() : $article\n  );\n}\n","export default function removeEmpty($article, $) {\n  $article.find('p').each((index, p) => {\n    const $p = $(p);\n    if ($p.find('iframe, img').length === 0 && $p.text().trim() === '') $p.remove();\n  });\n\n  return $;\n}\n","// // CONTENT FETCHING CONSTANTS ////\n\n// A list of strings that can be considered unlikely candidates when\n// extracting content from a resource. These strings are joined together\n// and then tested for existence using re:test, so may contain simple,\n// non-pipe style regular expression queries if necessary.\nexport const UNLIKELY_CANDIDATES_BLACKLIST = [\n  'ad-break',\n  'adbox',\n  'advert',\n  'addthis',\n  'agegate',\n  'aux',\n  'blogger-labels',\n  'combx',\n  'comment',\n  'conversation',\n  'disqus',\n  'entry-unrelated',\n  'extra',\n  'foot',\n  'form',\n  'header',\n  'hidden',\n  'loader',\n  'login',                     // Note: This can hit 'blogindex'.\n  'menu',\n  'meta',\n  'nav',\n  'pager',\n  'pagination',\n  'predicta',                  // readwriteweb inline ad box\n  'presence_control_external', // lifehacker.com container full of false positives\n  'popup',\n  'printfriendly',\n  'related',\n  'remove',\n  'remark',\n  'rss',\n  'share',\n  'shoutbox',\n  'sidebar',\n  'sociable',\n  'sponsor',\n  'tools',\n];\n\n// A list of strings that can be considered LIKELY candidates when\n// extracting content from a resource. Essentially, the inverse of the\n// blacklist above - if something matches both blacklist and whitelist,\n// it is kept. This is useful, for example, if something has a className\n// of \"rss-content entry-content\". It matched 'rss', so it would normally\n// be removed, however, it's also the entry content, so it should be left\n// alone.\n//\n// These strings are joined together and then tested for existence using\n// re:test, so may contain simple, non-pipe style regular expression queries\n// if necessary.\nexport const UNLIKELY_CANDIDATES_WHITELIST = [\n  'and',\n  'article',\n  'body',\n  'blogindex',\n  'column',\n  'content',\n  'entry-content-asset',\n  'format', // misuse of form\n  'hfeed',\n  'hentry',\n  'hatom',\n  'main',\n  'page',\n  'posts',\n  'shadow',\n];\n\n// A list of tags which, if found inside, should cause a <div /> to NOT\n// be turned into a paragraph tag. Shallow div tags without these elements\n// should be turned into <p /> tags.\nexport const DIV_TO_P_BLOCK_TAGS = [\n  'a',\n  'blockquote',\n  'dl',\n  'div',\n  'img',\n  'p',\n  'pre',\n  'table',\n].join(',');\n\n// A list of tags that should be ignored when trying to find the top candidate\n// for a document.\nexport const NON_TOP_CANDIDATE_TAGS = [\n  'br',\n  'b',\n  'i',\n  'label',\n  'hr',\n  'area',\n  'base',\n  'basefont',\n  'input',\n  'img',\n  'link',\n  'meta',\n];\n\nexport const NON_TOP_CANDIDATE_TAGS_RE =\n  new RegExp(`^(${NON_TOP_CANDIDATE_TAGS.join('|')})$`, 'i');\n\n// A list of selectors that specify, very clearly, either hNews or other\n// very content-specific style content, like Blogger templates.\n// More examples here: http://microformats.org/wiki/blog-post-formats\nexport const HNEWS_CONTENT_SELECTORS = [\n  ['.hentry', '.entry-content'],\n  ['entry', '.entry-content'],\n  ['.entry', '.entry_content'],\n  ['.post', '.postbody'],\n  ['.post', '.post_body'],\n  ['.post', '.post-body'],\n];\n\nexport const PHOTO_HINTS = [\n  'figure',\n  'photo',\n  'image',\n  'caption',\n];\nexport const PHOTO_HINTS_RE = new RegExp(PHOTO_HINTS.join('|'), 'i');\n\n// A list of strings that denote a positive scoring for this content as being\n// an article container. Checked against className and id.\n//\n// TODO: Perhaps have these scale based on their odds of being quality?\nexport const POSITIVE_SCORE_HINTS = [\n  'article',\n  'articlecontent',\n  'instapaper_body',\n  'blog',\n  'body',\n  'content',\n  'entry-content-asset',\n  'entry',\n  'hentry',\n  'main',\n  'Normal',\n  'page',\n  'pagination',\n  'permalink',\n  'post',\n  'story',\n  'text',\n  '[-_]copy', // usatoday\n  '\\\\Bcopy',\n];\n\n// The above list, joined into a matching regular expression\nexport const POSITIVE_SCORE_RE = new RegExp(POSITIVE_SCORE_HINTS.join('|'), 'i');\n\n// Readability publisher-specific guidelines\nexport const READABILITY_ASSET = new RegExp('entry-content-asset', 'i');\n\n// A list of strings that denote a negative scoring for this content as being\n// an article container. Checked against className and id.\n//\n// TODO: Perhaps have these scale based on their odds of being quality?\nexport const NEGATIVE_SCORE_HINTS = [\n  'adbox',\n  'advert',\n  'author',\n  'bio',\n  'bookmark',\n  'bottom',\n  'byline',\n  'clear',\n  'com-',\n  'combx',\n  'comment',\n  'comment\\\\B',\n  'contact',\n  'copy',\n  'credit',\n  'crumb',\n  'date',\n  'deck',\n  'excerpt',\n  'featured', // tnr.com has a featured_content which throws us off\n  'foot',\n  'footer',\n  'footnote',\n  'graf',\n  'head',\n  'info',\n  'infotext', // newscientist.com copyright\n  'instapaper_ignore',\n  'jump',\n  'linebreak',\n  'link',\n  'masthead',\n  'media',\n  'meta',\n  'modal',\n  'outbrain', // slate.com junk\n  'promo',\n  'pr_', // autoblog - press release\n  'related',\n  'respond',\n  'roundcontent', // lifehacker restricted content warning\n  'scroll',\n  'secondary',\n  'share',\n  'shopping',\n  'shoutbox',\n  'side',\n  'sidebar',\n  'sponsor',\n  'stamp',\n  'sub',\n  'summary',\n  'tags',\n  'tools',\n  'widget',\n];\n// The above list, joined into a matching regular expression\nexport const NEGATIVE_SCORE_RE = new RegExp(NEGATIVE_SCORE_HINTS.join('|'), 'i');\n\n// Match a digit. Pretty clear.\nexport const DIGIT_RE = new RegExp('[0-9]');\n\n// Match 2 or more consecutive <br> tags\nexport const BR_TAGS_RE = new RegExp('(<br[^>]*>[ \\n\\r\\t]*){2,}', 'i');\n\n// Match 1 BR tag.\nexport const BR_TAG_RE = new RegExp('<br[^>]*>', 'i');\n\n// A list of all of the block level tags known in HTML5 and below. Taken from\n// http://bit.ly/qneNIT\nexport const BLOCK_LEVEL_TAGS = [\n  'article',\n  'aside',\n  'blockquote',\n  'body',\n  'br',\n  'button',\n  'canvas',\n  'caption',\n  'col',\n  'colgroup',\n  'dd',\n  'div',\n  'dl',\n  'dt',\n  'embed',\n  'fieldset',\n  'figcaption',\n  'figure',\n  'footer',\n  'form',\n  'h1',\n  'h2',\n  'h3',\n  'h4',\n  'h5',\n  'h6',\n  'header',\n  'hgroup',\n  'hr',\n  'li',\n  'map',\n  'object',\n  'ol',\n  'output',\n  'p',\n  'pre',\n  'progress',\n  'section',\n  'table',\n  'tbody',\n  'textarea',\n  'tfoot',\n  'th',\n  'thead',\n  'tr',\n  'ul',\n  'video',\n];\nexport const BLOCK_LEVEL_TAGS_RE = new RegExp(`^(${BLOCK_LEVEL_TAGS.join('|')})$`, 'i');\n\n// The removal is implemented as a blacklist and whitelist, this test finds\n// blacklisted elements that aren't whitelisted. We do this all in one\n// expression-both because it's only one pass, and because this skips the\n// serialization for whitelisted nodes.\nconst candidatesBlacklist = UNLIKELY_CANDIDATES_BLACKLIST.join('|');\nexport const CANDIDATES_BLACKLIST = new RegExp(candidatesBlacklist, 'i');\n\nconst candidatesWhitelist = UNLIKELY_CANDIDATES_WHITELIST.join('|');\nexport const CANDIDATES_WHITELIST = new RegExp(candidatesWhitelist, 'i');\n\nexport const UNLIKELY_RE = new RegExp(`!(${candidatesWhitelist})|(${candidatesBlacklist})`, 'i');\n\nexport const PARAGRAPH_SCORE_TAGS = new RegExp('^(p|li|span|pre)$', 'i');\nexport const CHILD_CONTENT_TAGS = new RegExp('^(td|blockquote|ol|ul|dl)$', 'i');\nexport const BAD_TAGS = new RegExp('^(address|form)$', 'i');\n\nexport const HTML_OR_BODY_RE = new RegExp('^(html|body)$', 'i');\n","import {\n  NEGATIVE_SCORE_RE,\n  POSITIVE_SCORE_RE,\n  PHOTO_HINTS_RE,\n  READABILITY_ASSET,\n} from './constants';\n\n// Get the score of a node based on its className and id.\nexport default function getWeight(node) {\n  const classes = node.attr('class');\n  const id = node.attr('id');\n  let score = 0;\n\n  if (id) {\n    // if id exists, try to score on both positive and negative\n    if (POSITIVE_SCORE_RE.test(id)) {\n      score += 25;\n    }\n    if (NEGATIVE_SCORE_RE.test(id)) {\n      score -= 25;\n    }\n  }\n\n  if (classes) {\n    if (score === 0) {\n      // if classes exist and id did not contribute to score\n      // try to score on both positive and negative\n      if (POSITIVE_SCORE_RE.test(classes)) {\n        score += 25;\n      }\n      if (NEGATIVE_SCORE_RE.test(classes)) {\n        score -= 25;\n      }\n    }\n\n    // even if score has been set by id, add score for\n    // possible photo matches\n    // \"try to keep photos if we can\"\n    if (PHOTO_HINTS_RE.test(classes)) {\n      score += 10;\n    }\n\n    // add 25 if class matches entry-content-asset,\n    // a class apparently instructed for use in the\n    // Readability publisher guidelines\n    // https://www.readability.com/developers/guidelines\n    if (READABILITY_ASSET.test(classes)) {\n      score += 25;\n    }\n  }\n\n  return score;\n}\n","// returns the score of a node based on\n// the node's score attribute\n// returns null if no score set\nexport default function getScore($node) {\n  return parseFloat($node.attr('score')) || null;\n}\n","// return 1 for every comma in text\nexport default function scoreCommas(text) {\n  return (text.match(/,/g) || []).length;\n}\n","const idkRe = new RegExp('^(p|pre)$', 'i');\n\nexport default function scoreLength(textLength, tagName = 'p') {\n  const chunks = textLength / 50;\n\n  if (chunks > 0) {\n    let lengthBonus;\n\n    // No idea why p or pre are being tamped down here\n    // but just following the source for now\n    // Not even sure why tagName is included here,\n    // since this is only being called from the context\n    // of scoreParagraph\n    if (idkRe.test(tagName)) {\n      lengthBonus = chunks - 2;\n    } else {\n      lengthBonus = chunks - 1.25;\n    }\n\n    return Math.min(Math.max(lengthBonus, 0), 3);\n  }\n\n  return 0;\n}\n","import {\n  scoreCommas,\n  scoreLength,\n} from './index';\n\n// Score a paragraph using various methods. Things like number of\n// commas, etc. Higher is better.\nexport default function scoreParagraph(node) {\n  let score = 1;\n  const text = node.text().trim();\n  const textLength = text.length;\n\n  // If this paragraph is less than 25 characters, don't count it.\n  if (textLength < 25) {\n    return 0;\n  }\n\n  // Add points for any commas within this paragraph\n  score += scoreCommas(text);\n\n  // For every 50 characters in this paragraph, add another point. Up\n  // to 3 points.\n  score += scoreLength(textLength);\n\n  // Articles can end with short paragraphs when people are being clever\n  // but they can also end with short paragraphs setting up lists of junk\n  // that we strip. This negative tweaks junk setup paragraphs just below\n  // the cutoff threshold.\n  if (text.slice(-1) === ':') {\n    score -= 1;\n  }\n\n  return score;\n}\n","export default function setScore($node, $, score) {\n  $node.attr('score', score);\n  return $node;\n}\n","import {\n  getOrInitScore,\n  setScore,\n} from './index';\n\nexport default function addScore($node, $, amount) {\n  try {\n    const score = getOrInitScore($node, $) + amount;\n    setScore($node, $, score);\n  } catch (e) {\n    // Ignoring; error occurs in scoreNode\n  }\n\n  return $node;\n}\n","import { addScore } from './index';\n\n// Adds 1/4 of a child's score to its parent\nexport default function addToParent(node, $, score) {\n  const parent = node.parent();\n  if (parent) {\n    addScore(parent, $, score * 0.25);\n  }\n\n  return node;\n}\n","import {\n  getScore,\n  scoreNode,\n  getWeight,\n  addToParent,\n} from './index';\n\n// gets and returns the score if it exists\n// if not, initializes a score based on\n// the node's tag type\nexport default function getOrInitScore($node, $, weightNodes = true) {\n  let score = getScore($node);\n\n  if (score) {\n    return score;\n  }\n\n  score = scoreNode($node);\n\n  if (weightNodes) {\n    score += getWeight($node);\n  }\n\n  addToParent($node, $, score);\n\n  return score;\n}\n","import { scoreParagraph } from './index';\nimport {\n  PARAGRAPH_SCORE_TAGS,\n  CHILD_CONTENT_TAGS,\n  BAD_TAGS,\n} from './constants';\n\n// Score an individual node. Has some smarts for paragraphs, otherwise\n// just scores based on tag.\nexport default function scoreNode($node) {\n  const { tagName } = $node.get(0);\n\n  // TODO: Consider ordering by most likely.\n  // E.g., if divs are a more common tag on a page,\n  // Could save doing that regex test on every node – AP\n  if (PARAGRAPH_SCORE_TAGS.test(tagName)) {\n    return scoreParagraph($node);\n  } else if (tagName.toLowerCase() === 'div') {\n    return 5;\n  } else if (CHILD_CONTENT_TAGS.test(tagName)) {\n    return 3;\n  } else if (BAD_TAGS.test(tagName)) {\n    return -3;\n  } else if (tagName.toLowerCase() === 'th') {\n    return -5;\n  }\n\n  return 0;\n}\n","import { convertNodeTo } from 'utils/dom';\n\nimport { HNEWS_CONTENT_SELECTORS } from './constants';\nimport {\n  scoreNode,\n  setScore,\n  getOrInitScore,\n  addScore,\n} from './index';\n\nfunction convertSpans($node, $) {\n  if ($node.get(0)) {\n    const { tagName } = $node.get(0);\n\n    if (tagName === 'span') {\n      // convert spans to divs\n      convertNodeTo($node, $, 'div');\n    }\n  }\n}\n\nfunction addScoreTo($node, $, score) {\n  if ($node) {\n    convertSpans($node, $);\n    addScore($node, $, score);\n  }\n}\n\nfunction scorePs($, weightNodes) {\n  $('p, pre').not('[score]').each((index, node) => {\n    // The raw score for this paragraph, before we add any parent/child\n    // scores.\n    let $node = $(node);\n    $node = setScore($node, $, getOrInitScore($node, $, weightNodes));\n\n    const $parent = $node.parent();\n    const rawScore = scoreNode($node);\n\n    addScoreTo($parent, $, rawScore, weightNodes);\n    if ($parent) {\n      // Add half of the individual content score to the\n      // grandparent\n      addScoreTo($parent.parent(), $, rawScore / 2, weightNodes);\n    }\n  });\n\n  return $;\n}\n\n// score content. Parents get the full value of their children's\n// content score, grandparents half\nexport default function scoreContent($, weightNodes = true) {\n  // First, look for special hNews based selectors and give them a big\n  // boost, if they exist\n  HNEWS_CONTENT_SELECTORS.forEach(([parentSelector, childSelector]) => {\n    $(`${parentSelector} ${childSelector}`).each((index, node) => {\n      addScore($(node).parent(parentSelector), $, 80);\n    });\n  });\n\n  // Doubling this again\n  // Previous solution caused a bug\n  // in which parents weren't retaining\n  // scores. This is not ideal, and\n  // should be fixed.\n  scorePs($, weightNodes);\n  scorePs($, weightNodes);\n\n  return $;\n}\n","const NORMALIZE_RE = /\\s{2,}/g;\n\nexport default function normalizeSpaces(text) {\n  return text.replace(NORMALIZE_RE, ' ').trim();\n}\n","// Given a node type to search for, and a list of regular expressions,\n// look to see if this extraction can be found in the URL. Expects\n// that each expression in r_list will return group(1) as the proper\n// string to be cleaned.\n// Only used for date_published currently.\nexport default function extractFromUrl(url, regexList) {\n  const matchRe = regexList.find(re => re.test(url));\n  if (matchRe) {\n    return matchRe.exec(url)[1];\n  }\n\n  return null;\n}\n","// An expression that looks to try to find the page digit within a URL, if\n// it exists.\n// Matches:\n//  page=1\n//  pg=1\n//  p=1\n//  paging=12\n//  pag=7\n//  pagination/1\n//  paging/88\n//  pa/83\n//  p/11\n//\n// Does not match:\n//  pg=102\n//  page:2\nexport const PAGE_IN_HREF_RE = new RegExp('(page|paging|(p(a|g|ag)?(e|enum|ewanted|ing|ination)))?(=|/)([0-9]{1,3})', 'i');\n\nexport const HAS_ALPHA_RE = /[a-z]/i;\n\nexport const IS_ALPHA_RE = /^[a-z]+$/i;\nexport const IS_DIGIT_RE = /^[0-9]+$/i;\n","import { PAGE_IN_HREF_RE } from './constants';\n\nexport default function pageNumFromUrl(url) {\n  const matches = url.match(PAGE_IN_HREF_RE);\n  if (!matches) return null;\n\n  const pageNum = parseInt(matches[6], 10);\n\n  // Return pageNum < 100, otherwise\n  // return null\n  return pageNum < 100 ? pageNum : null;\n}\n","export default function removeAnchor(url) {\n  return url.split('#')[0].replace(/\\/$/, '');\n}\n","import URL from 'url';\n\nimport {\n  HAS_ALPHA_RE,\n  IS_ALPHA_RE,\n  IS_DIGIT_RE,\n  PAGE_IN_HREF_RE,\n} from './constants';\n\nfunction isGoodSegment(segment, index, firstSegmentHasLetters) {\n  let goodSegment = true;\n\n  // If this is purely a number, and it's the first or second\n  // url_segment, it's probably a page number. Remove it.\n  if (index < 2 && IS_DIGIT_RE.test(segment) && segment.length < 3) {\n    goodSegment = true;\n  }\n\n  // If this is the first url_segment and it's just \"index\",\n  // remove it\n  if (index === 0 && segment.toLowerCase() === 'index') {\n    goodSegment = false;\n  }\n\n  // If our first or second url_segment is smaller than 3 characters,\n  // and the first url_segment had no alphas, remove it.\n  if (index < 2 && segment.length < 3 && !firstSegmentHasLetters) {\n    goodSegment = false;\n  }\n\n  return goodSegment;\n}\n\n// Take a URL, and return the article base of said URL. That is, no\n// pagination data exists in it. Useful for comparing to other links\n// that might have pagination data within them.\nexport default function articleBaseUrl(url, parsed) {\n  const parsedUrl = parsed || URL.parse(url);\n  const { protocol, host, path } = parsedUrl;\n\n  let firstSegmentHasLetters = false;\n  const cleanedSegments = path.split('/')\n  .reverse()\n  .reduce((acc, rawSegment, index) => {\n    let segment = rawSegment;\n\n    // Split off and save anything that looks like a file type.\n    if (segment.includes('.')) {\n      const [possibleSegment, fileExt] = segment.split('.');\n      if (IS_ALPHA_RE.test(fileExt)) {\n        segment = possibleSegment;\n      }\n    }\n\n    // If our first or second segment has anything looking like a page\n    // number, remove it.\n    if (PAGE_IN_HREF_RE.test(segment) && index < 2) {\n      segment = segment.replace(PAGE_IN_HREF_RE, '');\n    }\n\n    // If we're on the first segment, check to see if we have any\n    // characters in it. The first segment is actually the last bit of\n    // the URL, and this will be helpful to determine if we're on a URL\n    // segment that looks like \"/2/\" for example.\n    if (index === 0) {\n      firstSegmentHasLetters = HAS_ALPHA_RE.test(segment);\n    }\n\n    // If it's not marked for deletion, push it to cleaned_segments.\n    if (isGoodSegment(segment, index, firstSegmentHasLetters)) {\n      acc.push(segment);\n    }\n\n    return acc;\n  }, []);\n\n  return `${protocol}//${host}${cleanedSegments.reverse().join('/')}`;\n}\n","// Given a string, return True if it appears to have an ending sentence\n// within it, false otherwise.\nconst SENTENCE_END_RE = new RegExp('.( |$)');\nexport default function hasSentenceEnd(text) {\n  return SENTENCE_END_RE.test(text);\n}\n","export default function excerptContent(content, words = 10) {\n  return content.trim()\n                .split(/\\s+/)\n                .slice(0, words)\n                .join(' ');\n}\n","import {\n  textLength,\n  linkDensity,\n} from 'utils/dom';\nimport { hasSentenceEnd } from 'utils/text';\n\nimport { NON_TOP_CANDIDATE_TAGS_RE } from './constants';\nimport { getScore } from './index';\n\n// Now that we have a top_candidate, look through the siblings of\n// it to see if any of them are decently scored. If they are, they\n// may be split parts of the content (Like two divs, a preamble and\n// a body.) Example:\n// http://articles.latimes.com/2009/oct/14/business/fi-bigtvs14\nexport default function mergeSiblings($candidate, topScore, $) {\n  if (!$candidate.parent().length) {\n    return $candidate;\n  }\n\n  const siblingScoreThreshold = Math.max(10, topScore * 0.25);\n  const wrappingDiv = $('<div></div>');\n\n  $candidate.parent().children().each((index, sibling) => {\n    const $sibling = $(sibling);\n    // Ignore tags like BR, HR, etc\n    if (NON_TOP_CANDIDATE_TAGS_RE.test(sibling.tagName)) {\n      return null;\n    }\n\n    const siblingScore = getScore($sibling);\n    if (siblingScore) {\n      if ($sibling.get(0) === $candidate.get(0)) {\n        wrappingDiv.append($sibling);\n      } else {\n        let contentBonus = 0;\n        const density = linkDensity($sibling);\n\n        // If sibling has a very low link density,\n        // give it a small bonus\n        if (density < 0.05) {\n          contentBonus += 20;\n        }\n\n        // If sibling has a high link density,\n        // give it a penalty\n        if (density >= 0.5) {\n          contentBonus -= 20;\n        }\n\n        // If sibling node has the same class as\n        // candidate, give it a bonus\n        if ($sibling.attr('class') === $candidate.attr('class')) {\n          contentBonus += topScore * 0.2;\n        }\n\n        const newScore = siblingScore + contentBonus;\n\n        if (newScore >= siblingScoreThreshold) {\n          return wrappingDiv.append($sibling);\n        } else if (sibling.tagName === 'p') {\n          const siblingContent = $sibling.text();\n          const siblingContentLength = textLength(siblingContent);\n\n          if (siblingContentLength > 80 && density < 0.25) {\n            return wrappingDiv.append($sibling);\n          } else if (siblingContentLength <= 80 && density === 0 &&\n                    hasSentenceEnd(siblingContent)) {\n            return wrappingDiv.append($sibling);\n          }\n        }\n      }\n    }\n\n    return null;\n  });\n\n  if (wrappingDiv.children().length === 1 &&\n    wrappingDiv.children().first().get(0) === $candidate.get(0)) {\n    return $candidate;\n  }\n\n  return wrappingDiv;\n}\n","import { NON_TOP_CANDIDATE_TAGS_RE } from './constants';\nimport { getScore } from './index';\nimport mergeSiblings from './merge-siblings';\n\n// After we've calculated scores, loop through all of the possible\n// candidate nodes we found and find the one with the highest score.\nexport default function findTopCandidate($) {\n  let $candidate;\n  let topScore = 0;\n\n  $('[score]').each((index, node) => {\n    // Ignore tags like BR, HR, etc\n    if (NON_TOP_CANDIDATE_TAGS_RE.test(node.tagName)) {\n      return;\n    }\n\n    const $node = $(node);\n    const score = getScore($node);\n\n    if (score > topScore) {\n      topScore = score;\n      $candidate = $node;\n    }\n  });\n\n  // If we don't have a candidate, return the body\n  // or whatever the first element is\n  if (!$candidate) {\n    return $('body') || $('*').first();\n  }\n\n  $candidate = mergeSiblings($candidate, topScore, $);\n\n  return $candidate;\n}\n","// Scoring\nexport { default as getWeight } from './get-weight';\nexport { default as getScore } from './get-score';\nexport { default as scoreCommas } from './score-commas';\nexport { default as scoreLength } from './score-length';\nexport { default as scoreParagraph } from './score-paragraph';\nexport { default as setScore } from './set-score';\nexport { default as addScore } from './add-score';\nexport { default as addToParent } from './add-to-parent';\nexport { default as getOrInitScore } from './get-or-init-score';\nexport { default as scoreNode } from './score-node';\nexport { default as scoreContent } from './score-content';\nexport { default as findTopCandidate } from './find-top-candidate';\n","import {\n  getScore,\n  setScore,\n  getOrInitScore,\n  scoreCommas,\n} from 'extractors/generic/content/scoring';\n\nimport { CLEAN_CONDITIONALLY_TAGS } from './constants';\nimport { normalizeSpaces } from '../text';\nimport { linkDensity } from './index';\n\nfunction removeUnlessContent($node, $, weight) {\n    // Explicitly save entry-content-asset tags, which are\n    // noted as valuable in the Publisher guidelines. For now\n    // this works everywhere. We may want to consider making\n    // this less of a sure-thing later.\n  if ($node.hasClass('entry-content-asset')) {\n    return;\n  }\n\n  const content = normalizeSpaces($node.text());\n\n  if (scoreCommas(content) < 10) {\n    const pCount = $('p', $node).length;\n    const inputCount = $('input', $node).length;\n\n      // Looks like a form, too many inputs.\n    if (inputCount > (pCount / 3)) {\n      $node.remove();\n      return;\n    }\n\n    const contentLength = content.length;\n    const imgCount = $('img', $node).length;\n\n      // Content is too short, and there are no images, so\n      // this is probably junk content.\n    if (contentLength < 25 && imgCount === 0) {\n      $node.remove();\n      return;\n    }\n\n    const density = linkDensity($node);\n\n      // Too high of link density, is probably a menu or\n      // something similar.\n      // console.log(weight, density, contentLength)\n    if (weight < 25 && density > 0.2 && contentLength > 75) {\n      $node.remove();\n      return;\n    }\n\n      // Too high of a link density, despite the score being\n      // high.\n    if (weight >= 25 && density > 0.5) {\n        // Don't remove the node if it's a list and the\n        // previous sibling starts with a colon though. That\n        // means it's probably content.\n      const tagName = $node.get(0).tagName.toLowerCase();\n      const nodeIsList = tagName === 'ol' || tagName === 'ul';\n      if (nodeIsList) {\n        const previousNode = $node.prev();\n        if (previousNode && normalizeSpaces(previousNode.text()).slice(-1) === ':') {\n          return;\n        }\n      }\n\n      $node.remove();\n      return;\n    }\n\n    const scriptCount = $('script', $node).length;\n\n      // Too many script tags, not enough content.\n    if (scriptCount > 0 && contentLength < 150) {\n      $node.remove();\n      return;\n    }\n  }\n}\n\n// Given an article, clean it of some superfluous content specified by\n// tags. Things like forms, ads, etc.\n//\n// Tags is an array of tag name's to search through. (like div, form,\n// etc)\n//\n// Return this same doc.\nexport default function cleanTags($article, $) {\n  $(CLEAN_CONDITIONALLY_TAGS, $article).each((index, node) => {\n    const $node = $(node);\n    let weight = getScore($node);\n    if (!weight) {\n      weight = getOrInitScore($node, $);\n      setScore($node, $, weight);\n    }\n\n    // drop node if its weight is < 0\n    if (weight < 0) {\n      $node.remove();\n    } else {\n      // deteremine if node seems like content\n      removeUnlessContent($node, $, weight);\n    }\n  });\n\n  return $;\n}\n","import { getWeight } from 'extractors/generic/content/scoring';\n\nimport { HEADER_TAG_LIST } from './constants';\nimport { normalizeSpaces } from '../text';\n\nexport default function cleanHeaders($article, $, title = '') {\n  $(HEADER_TAG_LIST, $article).each((index, header) => {\n    const $header = $(header);\n    // Remove any headers that appear before all other p tags in the\n    // document. This probably means that it was part of the title, a\n    // subtitle or something else extraneous like a datestamp or byline,\n    // all of which should be handled by other metadata handling.\n    if ($($header, $article).prevAll('p').length === 0) {\n      return $header.remove();\n    }\n\n    // Remove any headers that match the title exactly.\n    if (normalizeSpaces($(header).text()) === title) {\n      return $header.remove();\n    }\n\n    // If this header has a negative weight, it's probably junk.\n    // Get rid of it.\n    if (getWeight($(header)) < 0) {\n      return $header.remove();\n    }\n\n    return $header;\n  });\n\n  return $;\n}\n","import { convertNodeTo } from 'utils/dom';\n\n// Rewrite the tag name to div if it's a top level node like body or\n// html to avoid later complications with multiple body tags.\nexport default function rewriteTopLevel(article, $) {\n  // I'm not using context here because\n  // it's problematic when converting the\n  // top-level/root node - AP\n  $ = convertNodeTo($('html'), $, 'div');\n  $ = convertNodeTo($('body'), $, 'div');\n\n  return $;\n}\n","import URL from 'url';\n\nimport {\n  getAttrs,\n  setAttr,\n} from 'utils/dom';\n\nfunction absolutize($, rootUrl, attr, $content) {\n  $(`[${attr}]`, $content).each((_, node) => {\n    const attrs = getAttrs(node);\n    const url = attrs[attr];\n\n    if (url) {\n      const absoluteUrl = URL.resolve(rootUrl, url);\n      setAttr(node, attr, absoluteUrl);\n    }\n  });\n}\n\nexport default function makeLinksAbsolute($content, $, url) {\n  ['href', 'src'].forEach(attr => absolutize($, url, attr, $content));\n\n  return $content;\n}\n","export function textLength(text) {\n  return text.trim()\n             .replace(/\\s+/g, ' ')\n             .length;\n}\n\n// Determines what percentage of the text\n// in a node is link text\n// Takes a node, returns a float\nexport function linkDensity($node) {\n  const totalTextLength = textLength($node.text());\n\n  const linkText = $node.find('a').text();\n  const linkLength = textLength(linkText);\n\n  if (totalTextLength > 0) {\n    return linkLength / totalTextLength;\n  } else if (totalTextLength === 0 && linkLength > 0) {\n    return 1;\n  }\n\n  return 0;\n}\n","import { stripTags } from 'utils/dom';\n\n// Given a node type to search for, and a list of meta tag names to\n// search for, find a meta tag associated.\nexport default function extractFromMeta(\n  $,\n  metaNames,\n  cachedNames,\n  cleanTags = true\n) {\n  const foundNames = metaNames.filter(name => cachedNames.indexOf(name) !== -1);\n\n  for (const name of foundNames) {\n    const type = 'name';\n    const value = 'value';\n\n    const nodes = $(`meta[${type}=\"${name}\"]`);\n\n    // Get the unique value of every matching node, in case there\n    // are two meta tags with the same name and value.\n    // Remove empty values.\n    const values =\n      nodes.map((index, node) => $(node).attr(value))\n           .toArray()\n           .filter(text => text !== '');\n\n      // If we have more than one value for the same name, we have a\n      // conflict and can't trust any of them. Skip this name. If we have\n      // zero, that means our meta tags had no values. Skip this name\n      // also.\n    if (values.length === 1) {\n      let metaValue;\n        // Meta values that contain HTML should be stripped, as they\n        // weren't subject to cleaning previously.\n      if (cleanTags) {\n        metaValue = stripTags(values[0], $);\n      } else {\n        metaValue = values[0];\n      }\n\n      return metaValue;\n    }\n  }\n\n  // If nothing is found, return null\n  return null;\n}\n","import { withinComment } from 'utils/dom';\n\nfunction isGoodNode($node, maxChildren) {\n  // If it has a number of children, it's more likely a container\n  // element. Skip it.\n  if ($node.children().length > maxChildren) {\n    return false;\n  }\n  // If it looks to be within a comment, skip it.\n  if (withinComment($node)) {\n    return false;\n  }\n\n  return true;\n}\n\n// Given a a list of selectors find content that may\n// be extractable from the document. This is for flat\n// meta-information, like author, title, date published, etc.\nexport default function extractFromSelectors(\n  $,\n  selectors,\n  maxChildren = 1,\n  textOnly = true\n) {\n  for (const selector of selectors) {\n    const nodes = $(selector);\n\n    // If we didn't get exactly one of this selector, this may be\n    // a list of articles or comments. Skip it.\n    if (nodes.length === 1) {\n      const $node = $(nodes[0]);\n\n      if (isGoodNode($node, maxChildren)) {\n        let content;\n        if (textOnly) {\n          content = $node.text();\n        } else {\n          content = $node.html();\n        }\n\n        if (content) {\n          return content;\n        }\n      }\n    }\n  }\n\n  return null;\n}\n","// strips all tags from a string of text\nexport default function stripTags(text, $) {\n  // Wrapping text in html element prevents errors when text\n  // has no html\n  const cleanText = $(`<span>${text}</span>`).text();\n  return cleanText === '' ? text : cleanText;\n}\n","import { getAttrs } from 'utils/dom';\n\nexport default function withinComment($node) {\n  const parents = $node.parents().toArray();\n  const commentParent = parents.find((parent) => {\n    const attrs = getAttrs(parent);\n    const { class: nodeClass, id } = attrs;\n    const classAndId = `${nodeClass} ${id}`;\n    return classAndId.includes('comment');\n  });\n\n  return commentParent !== undefined;\n}\n","// Given a node, determine if it's article-like enough to return\n// param: node (a cheerio node)\n// return: boolean\n\nexport default function nodeIsSufficient($node) {\n  return $node.text().trim().length >= 100;\n}\n","import { IS_WP_SELECTOR } from './constants';\n\nexport default function isWordpress($) {\n  return $(IS_WP_SELECTOR).length > 0;\n}\n","export default function getAttrs(node) {\n  const { attribs, attributes } = node;\n\n  if (!attribs && attributes) {\n    const attrs = Reflect.ownKeys(attributes).reduce((acc, index) => {\n      const attr = attributes[index];\n\n      if (!attr.name || !attr.value) return acc;\n\n      acc[attr.name] = attr.value;\n      return acc;\n    }, {});\n    return attrs;\n  }\n\n  return attribs;\n}\n","export default function setAttr(node, attr, val) {\n  if (node.attribs) {\n    node.attribs[attr] = val;\n  } else if (node.attributes) {\n    node.setAttribute(attr, val);\n  }\n\n  return node;\n}\n","export default function setAttrs(node, attrs) {\n  if (node.attribs) {\n    node.attribs = attrs;\n  } else if (node.attributes) {\n    while (node.attributes.length > 0) {\n      node.removeAttribute(node.attributes[0].name);\n    }\n\n    Reflect.ownKeys(attrs).forEach((key) => {\n      node.setAttribute(key, attrs[key]);\n    });\n  }\n\n  return node;\n}\n","// DOM manipulation\nexport { default as stripUnlikelyCandidates } from './strip-unlikely-candidates';\nexport { default as brsToPs } from './brs-to-ps';\nexport { default as paragraphize } from './paragraphize';\nexport { default as convertToParagraphs } from './convert-to-paragraphs';\nexport { default as convertNodeTo } from './convert-node-to';\nexport { default as cleanImages } from './clean-images';\nexport { default as markToKeep } from './mark-to-keep';\nexport { default as stripJunkTags } from './strip-junk-tags';\nexport { default as cleanHOnes } from './clean-h-ones';\nexport { default as cleanAttributes } from './clean-attributes';\nexport { default as removeEmpty } from './remove-empty';\nexport { default as cleanTags } from './clean-tags';\nexport { default as cleanHeaders } from './clean-headers';\nexport { default as rewriteTopLevel } from './rewrite-top-level';\nexport { default as makeLinksAbsolute } from './make-links-absolute';\nexport { textLength, linkDensity } from './link-density';\nexport { default as extractFromMeta } from './extract-from-meta';\nexport { default as extractFromSelectors } from './extract-from-selectors';\nexport { default as stripTags } from './strip-tags';\nexport { default as withinComment } from './within-comment';\nexport { default as nodeIsSufficient } from './node-is-sufficient';\nexport { default as isWordpress } from './is-wordpress';\nexport { default as getAttrs } from './get-attrs';\nexport { default as setAttr } from './set-attr';\nexport { default as setAttrs } from './set-attrs';\n","export const IS_LINK = new RegExp('https?://', 'i');\nexport const IS_IMAGE = new RegExp('.(png|gif|jpe?g)', 'i');\n\nexport const TAGS_TO_REMOVE = [\n  'script',\n  'style',\n  'form',\n].join(',');\n","import { getAttrs } from 'utils/dom';\n\nimport {\n  IS_LINK,\n  IS_IMAGE,\n} from './constants';\n\n// Convert all instances of images with potentially\n// lazy loaded images into normal images.\n// Many sites will have img tags with no source, or an image tag with a src\n// attribute that a is a placeholer. We need to be able to properly fill in\n// the src attribute so the images are no longer lazy loaded.\nexport default function convertLazyLoadedImages($) {\n  $('img').each((_, img) => {\n    const attrs = getAttrs(img);\n\n    Reflect.ownKeys(attrs).forEach((attr) => {\n      const value = attrs[attr];\n\n      if (attr !== 'src' && IS_LINK.test(value) &&\n          IS_IMAGE.test(value)) {\n        $(img).attr('src', value);\n      }\n    });\n  });\n\n  return $;\n}\n","import { TAGS_TO_REMOVE } from './constants';\n\nfunction isComment(index, node) {\n  return node.type === 'comment';\n}\n\nfunction cleanComments($) {\n  $.root().find('*')\n          .contents()\n          .filter(isComment)\n          .remove();\n\n  return $;\n}\n\nexport default function clean($) {\n  $(TAGS_TO_REMOVE).remove();\n\n  $ = cleanComments($);\n  return $;\n}\n","import cheerio from 'cheerio';\n\nimport { fetchResource } from './utils';\nimport {\n  normalizeMetaTags,\n  convertLazyLoadedImages,\n  clean,\n} from './utils/dom';\n\nconst Resource = {\n\n  // Create a Resource.\n  //\n  // :param url: The URL for the document we should retrieve.\n  // :param response: If set, use as the response rather than\n  //                  attempting to fetch it ourselves. Expects a\n  //                  string.\n  async create(url, preparedResponse, parsedUrl) {\n    let result;\n\n    if (preparedResponse) {\n      const validResponse = {\n        statusMessage: 'OK',\n        statusCode: 200,\n        headers: {\n          'content-type': 'text/html',\n          'content-length': 500,\n        },\n      };\n\n      result = { body: preparedResponse, response: validResponse };\n    } else {\n      result = await fetchResource(url, parsedUrl);\n    }\n\n    if (result.error) {\n      result.failed = true;\n      return result;\n    }\n\n    return this.generateDoc(result);\n  },\n\n  generateDoc({ body: content, response }) {\n    const { 'content-type': contentType } = response.headers;\n\n    // TODO: Implement is_text function from\n    // https://github.com/ReadabilityHoldings/readability/blob/8dc89613241d04741ebd42fa9fa7df1b1d746303/readability/utils/text.py#L57\n    if (!contentType.includes('html') &&\n        !contentType.includes('text')) {\n      throw new Error('Content does not appear to be text.');\n    }\n\n    let $ = cheerio.load(content, { normalizeWhitespace: true });\n\n    if ($.root().children().length === 0) {\n      throw new Error('No children, likely a bad parse.');\n    }\n\n    $ = normalizeMetaTags($);\n    $ = convertLazyLoadedImages($);\n    $ = clean($);\n\n    return $;\n  },\n};\n\nexport default Resource;\n","const merge = (extractor, domains) => (\n  domains.reduce((acc, domain) => {\n    acc[domain] = extractor;\n    return acc;\n  }, {})\n);\n\nexport default function mergeSupportedDomains(extractor) {\n  return extractor.supportedDomains ?\n    merge(extractor, [extractor.domain, ...extractor.supportedDomains])\n    :\n    merge(extractor, [extractor.domain]);\n}\n","export const BloggerExtractor = {\n  domain: 'blogspot.com',\n  content: {\n    // Blogger is insane and does not load its content\n    // initially in the page, but it's all there\n    // in noscript\n    selectors: [\n      '.post-content noscript',\n    ],\n\n    // Selectors to remove from the extracted content\n    clean: [\n    ],\n\n    // Convert the noscript tag to a div\n    transforms: {\n      noscript: 'div',\n    },\n  },\n\n  author: {\n    selectors: [\n      '.post-author-name',\n    ],\n  },\n\n  title: {\n    selectors: [\n      '.post h2.title',\n    ],\n  },\n\n  date_published: {\n    selectors: [\n      'span.publishdate',\n    ],\n  },\n};\n","export const NYMagExtractor = {\n  domain: 'nymag.com',\n  content: {\n    // Order by most likely. Extractor will stop on first occurrence\n    selectors: [\n      'div.article-content',\n      'section.body',\n      'article.article',\n    ],\n\n    // Selectors to remove from the extracted content\n    clean: [\n      '.ad',\n      '.single-related-story',\n    ],\n\n    // Object of tranformations to make on matched elements\n    // Each key is the selector, each value is the tag to\n    // transform to.\n    // If a function is given, it should return a string\n    // to convert to or nothing (in which case it will not perform\n    // the transformation.\n    transforms: {\n      // Convert h1s to h2s\n      h1: 'h2',\n\n      // Convert lazy-loaded noscript images to figures\n      noscript: ($node, $) => {\n        const $children = $.browser ? $($node.text()) : $node.children();\n        if ($children.length === 1 && $children.get(0) !== undefined &&\n          $children.get(0).tagName.toLowerCase() === 'img') {\n          return 'figure';\n        }\n\n        return null;\n      },\n    },\n  },\n\n  title: {\n    selectors: [\n      'h1.lede-feature-title',\n      'h1.headline-primary',\n      'h1',\n    ],\n  },\n\n  author: {\n    selectors: [\n      '.by-authors',\n      '.lede-feature-author',\n    ],\n  },\n\n  dek: {\n    selectors: [\n      '.lede-feature-teaser',\n    ],\n  },\n\n  date_published: {\n    selectors: [\n      ['time.article-timestamp[datetime]', 'datetime'],\n      'time.article-timestamp',\n    ],\n  },\n};\n","export const WikipediaExtractor = {\n  domain: 'wikipedia.org',\n  content: {\n    selectors: [\n      '#mw-content-text',\n    ],\n\n    defaultCleaner: false,\n\n    // transform top infobox to an image with caption\n    transforms: {\n      '.infobox img': ($node) => {\n        const $parent = $node.parents('.infobox');\n        // Only prepend the first image in .infobox\n        if ($parent.children('img').length === 0) {\n          $parent.prepend($node);\n        }\n      },\n      '.infobox caption': 'figcaption',\n      '.infobox': 'figure',\n    },\n\n    // Selectors to remove from the extracted content\n    clean: [\n      '.mw-editsection',\n      'figure tr, figure td, figure tbody',\n      '#toc',\n      '.navbox',\n    ],\n\n  },\n\n  author: 'Wikipedia Contributors',\n\n  title: {\n    selectors: [\n      'h2.title',\n    ],\n  },\n\n  date_published: {\n    selectors: [\n      '#footer-info-lastmod',\n    ],\n  },\n\n};\n","export const TwitterExtractor = {\n  domain: 'twitter.com',\n\n  content: {\n    transforms: {\n      // We're transforming essentially the whole page here.\n      // Twitter doesn't have nice selectors, so our initial\n      // selector grabs the whole page, then we're re-writing\n      // it to fit our needs before we clean it up.\n      '.permalink[role=main]': ($node, $) => {\n        const tweets = $node.find('.tweet');\n        const $tweetContainer = $('<div id=\"TWEETS_GO_HERE\"></div>');\n        $tweetContainer.append(tweets);\n        $node.replaceWith($tweetContainer);\n      },\n\n      // Twitter wraps @ with s, which\n      // renders as a strikethrough\n      s: 'span',\n    },\n\n    selectors: [\n      '.permalink[role=main]',\n    ],\n\n    defaultCleaner: false,\n\n    clean: [\n      '.stream-item-footer',\n      'button',\n      '.tweet-details-fixer',\n    ],\n  },\n\n  author: {\n    selectors: [\n      '.tweet.permalink-tweet .username',\n    ],\n  },\n\n  date_published: {\n    selectors: [\n      ['.permalink-tweet ._timestamp[data-time-ms]', 'data-time-ms'],\n      // '.tweet.permalink-tweet .metadata',\n    ],\n  },\n\n};\n","export const NYTimesExtractor = {\n  domain: 'www.nytimes.com',\n\n  title: {\n    selectors: [\n      '.g-headline',\n      'h1.headline',\n    ],\n  },\n\n  author: {\n    selectors: [\n      ['meta[name=\"author\"]', 'value'],\n      '.g-byline',\n      '.byline',\n    ],\n  },\n\n  content: {\n    selectors: [\n      'div.g-blocks',\n      'article#story',\n    ],\n\n    transforms: {\n      'img.g-lazy': ($node) => {\n        let src = $node.attr('src');\n        // const widths = $node.attr('data-widths')\n        //                   .slice(1)\n        //                   .slice(0, -1)\n        //                   .split(',');\n        // if (widths.length) {\n        //   width = widths.slice(-1);\n        // } else {\n        //   width = '900';\n        // }\n        const width = 640;\n\n        src = src.replace('{{size}}', width);\n        $node.attr('src', src);\n      },\n    },\n\n    clean: [\n      '.ad',\n      'header#story-header',\n      '.story-body-1 .lede.video',\n      '.visually-hidden',\n      '#newsletter-promo',\n      '.promo',\n      '.comments-button',\n      '.hidden',\n      '.comments',\n    ],\n  },\n\n  date_published: null,\n\n  lead_image_url: null,\n\n  dek: null,\n\n  next_page_url: null,\n\n  excerpt: null,\n};\n","// Rename CustomExtractor\n// to fit your publication\nexport const TheAtlanticExtractor = {\n  domain: 'www.theatlantic.com',\n  title: {\n    selectors: [\n      'h1.hed',\n    ],\n  },\n\n  author: {\n    selectors: [\n      'article#article .article-cover-extra .metadata .byline a',\n    ],\n  },\n\n  content: {\n    selectors: [\n      '.article-body',\n    ],\n\n  // Is there anything in the content you selected that needs transformed\n  // before it's consumable content? E.g., unusual lazy loaded images\n    transforms: [\n    ],\n\n  // Is there anything that is in the result that shouldn't be?\n  // The clean selectors will remove anything that matches from\n  // the result\n    clean: [\n\n    ],\n  },\n\n  date_published: {\n    selectors: [\n      ['time[itemProp=\"datePublished\"]', 'datetime'],\n    ],\n  },\n\n  lead_image_url: null,\n\n  dek: null,\n\n  next_page_url: null,\n\n  excerpt: null,\n};\n","// Rename CustomExtractor\n// to fit your publication\n// (e.g., NYTimesExtractor)\nexport const NewYorkerExtractor = {\n  domain: 'www.newyorker.com',\n  title: {\n    selectors: [\n      'h1.title',\n    ],\n  },\n\n  author: {\n    selectors: [\n      '.contributors',\n    ],\n  },\n\n  content: {\n    selectors: [\n      'div#articleBody',\n      'div.articleBody',\n    ],\n\n    // Is there anything in the content you selected that needs transformed\n    // before it's consumable content? E.g., unusual lazy loaded images\n    transforms: [\n    ],\n\n    // Is there anything that is in the result that shouldn't be?\n    // The clean selectors will remove anything that matches from\n    // the result\n    clean: [\n\n    ],\n  },\n\n  date_published: {\n    selectors: [\n      ['meta[name=\"article:published_time\"]', 'value'],\n    ],\n  },\n\n  lead_image_url: {\n    selectors: [\n      ['meta[name=\"og:image\"]', 'value'],\n    ],\n  },\n\n  dek: {\n    selectors: [\n      ['meta[name=\"og:description\"]', 'value'],\n    ],\n  },\n\n  next_page_url: null,\n\n  excerpt: null,\n};\n","// Rename CustomExtractor\n// to fit your publication\n// (e.g., NYTimesExtractor)\nexport const WiredExtractor = {\n  domain: 'www.wired.com',\n  title: {\n    selectors: [\n      'h1.post-title',\n      // enter title selectors\n    ],\n  },\n\n  author: {\n    selectors: [\n      'a[rel=\"author\"]',\n      // enter author selectors\n    ],\n  },\n\n  content: {\n    selectors: [\n      'article.content',\n      // enter content selectors\n    ],\n\n    // Is there anything in the content you selected that needs transformed\n    // before it's consumable content? E.g., unusual lazy loaded images\n    transforms: [\n    ],\n\n    // Is there anything that is in the result that shouldn't be?\n    // The clean selectors will remove anything that matches from\n    // the result\n    clean: [\n      '.visually-hidden',\n\n    ],\n  },\n\n  date_published: {\n    selectors: [\n      ['meta[itemprop=\"datePublished\"]', 'value'],\n    ],\n  },\n\n  lead_image_url: {\n    selectors: [\n      ['meta[name=\"og:image\"]', 'value'],\n    ],\n  },\n\n  dek: {\n    selectors: [\n      ['meta[name=\"og:description\"]', 'value'],\n    ],\n  },\n\n  next_page_url: null,\n\n  excerpt: null,\n};\n","// Rename CustomExtractor\n// to fit your publication\n// (e.g., NYTimesExtractor)\nexport const MSNExtractor = {\n  domain: 'www.msn.com',\n  title: {\n    selectors: [\n      'h1',\n      // enter title selectors\n    ],\n  },\n\n  author: {\n    selectors: [\n      'span.authorname-txt',\n      // enter author selectors\n    ],\n  },\n\n  content: {\n    selectors: [\n      'div.richtext',\n      // enter content selectors\n    ],\n\n    // Is there anything in the content you selected that needs transformed\n    // before it's consumable content? E.g., unusual lazy loaded images\n    transforms: [\n    ],\n\n    // Is there anything that is in the result that shouldn't be?\n    // The clean selectors will remove anything that matches from\n    // the result\n    clean: [\n      'span.caption',\n\n    ],\n  },\n\n  date_published: {\n    selectors: [\n      'span.time',\n    ],\n  },\n\n  lead_image_url: {\n    selectors: [\n\n    ],\n  },\n\n  dek: {\n    selectors: [\n      ['meta[name=\"description\"]', 'value'],\n    ],\n  },\n\n  next_page_url: null,\n\n  excerpt: null,\n};\n","// Rename CustomExtractor\n// to fit your publication\n// (e.g., NYTimesExtractor)\nexport const YahooExtractor = {\n  domain: 'www.yahoo.com',\n  title: {\n    selectors: [\n      'header.canvas-header',\n      // enter title selectors\n    ],\n  },\n\n  author: {\n    selectors: [\n      'span.provider-name',\n      // enter author selectors\n    ],\n  },\n\n  content: {\n    selectors: [\n      // enter content selectors\n      '.content-canvas',\n    ],\n\n    // Is there anything in the content you selected that needs transformed\n    // before it's consumable content? E.g., unusual lazy loaded images\n    transforms: [\n    ],\n\n    // Is there anything that is in the result that shouldn't be?\n    // The clean selectors will remove anything that matches from\n    // the result\n    clean: [\n      '.figure-caption',\n\n    ],\n  },\n\n  date_published: {\n    selectors: [\n      ['time.date[datetime]', 'datetime'],\n    ],\n  },\n\n  lead_image_url: {\n    selectors: [\n      ['meta[name=\"og:image\"]', 'value'],\n    ],\n  },\n\n  dek: {\n    selectors: [\n      ['meta[name=\"og:description\"]', 'value'],\n    // enter dek selectors\n    ],\n  },\n\n  next_page_url: null,\n\n  excerpt: null,\n};\n","// Rename CustomExtractor\n// to fit your publication\n// (e.g., NYTimesExtractor)\nexport const BuzzfeedExtractor = {\n  domain: 'www.buzzfeed.com',\n  title: {\n    selectors: [\n      'h1[id=\"post-title\"]',\n      // enter title selectors\n    ],\n  },\n\n  author: {\n    selectors: [\n      'a[data-action=\"user/username\"]', 'byline__author',\n      // enter author selectors\n    ],\n  },\n\n  content: {\n    selectors: [\n      '#buzz_sub_buzz',\n      // enter content selectors\n    ],\n\n    defaultCleaner: false,\n\n    // Is there anything in the content you selected that needs transformed\n    // before it's consumable content? E.g., unusual lazy loaded images\n    transforms: {\n      h2: 'b',\n    },\n\n    // Is there anything that is in the result that shouldn't be?\n    // The clean selectors will remove anything that matches from\n    // the result\n    clean: [\n      '.instapaper_ignore',\n      '.suplist_list_hide .buzz_superlist_item .buzz_superlist_number_inline',\n      '.share-box',\n    ],\n  },\n\n  date_published: {\n    selectors: [\n      '.buzz-datetime',\n      // enter author selectors\n    ],\n  },\n\n  lead_image_url: {\n    selectors: [\n      ['meta[name=\"og:image\"]', 'value'],\n    ],\n  },\n\n  dek: {\n    selectors: [\n      ['meta[name=\"description\"]', 'value'],\n    ],\n  },\n\n  next_page_url: null,\n\n  excerpt: null,\n};\n","// Rename CustomExtractor\n// to fit your publication\n// (e.g., NYTimesExtractor)\nexport const WikiaExtractor = {\n  domain: 'fandom.wikia.com',\n  title: {\n    selectors: [\n      'h1.entry-title',\n      // enter title selectors\n    ],\n  },\n\n  author: {\n    selectors: [\n      '.author vcard', '.fn',\n      // enter author selectors\n    ],\n  },\n\n  content: {\n    selectors: [\n      '.grid-content',\n      '.entry-content',\n      // enter content selectors\n    ],\n\n    // Is there anything in the content you selected that needs transformed\n    // before it's consumable content? E.g., unusual lazy loaded images\n    transforms: [\n    ],\n\n    // Is there anything that is in the result that shouldn't be?\n    // The clean selectors will remove anything that matches from\n    // the result\n    clean: [\n\n    ],\n  },\n\n  date_published: {\n    selectors: [\n      ['meta[name=\"article:published_time\"]', 'value'],\n    ],\n  },\n\n  lead_image_url: {\n    selectors: [\n      ['meta[name=\"og:image\"]', 'value'],\n    ],\n  },\n\n  dek: {\n    selectors: [\n      ['meta[name=\"og:description\"]', 'value'],\n    ],\n  },\n\n  next_page_url: null,\n\n  excerpt: null,\n};\n","// Rename CustomExtractor\n// to fit your publication\n// (e.g., NYTimesExtractor)\nexport const LittleThingsExtractor = {\n  domain: 'www.littlethings.com',\n  title: {\n    selectors: [\n      'h1.post-title',\n      // enter title selectors\n    ],\n  },\n\n  author: {\n    selectors: [\n      ['meta[name=\"author\"]', 'value'],\n      // enter author selectors\n    ],\n  },\n\n  content: {\n    selectors: [\n      // enter content selectors\n      '.mainContentIntro',\n      '.content-wrapper',\n    ],\n\n    // Is there anything in the content you selected that needs transformed\n    // before it's consumable content? E.g., unusual lazy loaded images\n    transforms: [\n    ],\n\n    // Is there anything that is in the result that shouldn't be?\n    // The clean selectors will remove anything that matches from\n    // the result\n    clean: [\n\n    ],\n  },\n\n  lead_image_url: {\n    selectors: [\n      ['meta[name=\"og:image\"]', 'value'],\n    ],\n  },\n\n  next_page_url: null,\n\n  excerpt: null,\n};\n","// Rename CustomExtractor\n// to fit your publication\n// (e.g., NYTimesExtractor)\nexport const PoliticoExtractor = {\n  domain: 'www.politico.com',\n  title: {\n    selectors: [\n      // enter title selectors\n      ['meta[name=\"og:title\"]', 'value'],\n    ],\n  },\n\n  author: {\n    selectors: [\n      '.story-main-content .byline .vcard',\n    ],\n  },\n\n  content: {\n    selectors: [\n      // enter content selectors\n      '.story-main-content',\n      '.content-group', '.story-core',\n      '.story-text',\n    ],\n\n    // Is there anything in the content you selected that needs transformed\n    // before it's consumable content? E.g., unusual lazy loaded images\n    transforms: [\n    ],\n\n    // Is there anything that is in the result that shouldn't be?\n    // The clean selectors will remove anything that matches from\n    // the result\n    clean: [\n      'figcaption',\n    ],\n  },\n\n  date_published: {\n    selectors: [\n      ['.story-main-content .timestamp time[datetime]', 'datetime'],\n\n    ],\n  },\n\n  lead_image_url: {\n    selectors: [\n      // enter lead_image_url selectors\n      ['meta[name=\"og:image\"]', 'value'],\n\n    ],\n  },\n\n  dek: {\n    selectors: [\n      ['meta[name=\"description\"]', 'value'],\n    ],\n  },\n\n  next_page_url: null,\n\n  excerpt: null,\n};\n","export const DeadspinExtractor = {\n  domain: 'deadspin.com',\n\n  supportedDomains: [\n    'jezebel.com',\n    'lifehacker.com',\n    'kotaku.com',\n    'gizmodo.com',\n    'jalopnik.com',\n    'kinja.com',\n  ],\n\n  title: {\n    selectors: [\n      'h1.headline',\n    ],\n  },\n\n  author: {\n    selectors: [\n      '.author',\n    ],\n  },\n\n  content: {\n    selectors: [\n      '.post-content',\n      '.entry-content',\n    ],\n\n    // Is there anything in the content you selected that needs transformed\n    // before it's consumable content? E.g., unusual lazy loaded images\n    transforms: {\n      'iframe.lazyload[data-recommend-id^=\"youtube://\"]': ($node) => {\n        const youtubeId = $node.attr('id').split('youtube-')[1];\n        $node.attr('src', `https://www.youtube.com/embed/${youtubeId}`);\n      },\n    },\n\n    // Is there anything that is in the result that shouldn't be?\n    // The clean selectors will remove anything that matches from\n    // the result\n    clean: [\n    ],\n  },\n\n  date_published: {\n    selectors: [\n      ['time.updated[datetime]', 'datetime'],\n    ],\n  },\n\n  lead_image_url: {\n    selectors: [\n      ['meta[name=\"og:image\"]', 'value'],\n    ],\n  },\n\n  dek: {\n    selectors: [\n      // enter selectors\n    ],\n  },\n\n  next_page_url: {\n    selectors: [\n      // enter selectors\n    ],\n  },\n\n  excerpt: {\n    selectors: [\n      // enter selectors\n    ],\n  },\n};\n","// Rename CustomExtractor\n// to fit your publication\n// (e.g., NYTimesExtractor)\nexport const BroadwayWorldExtractor = {\n  domain: 'www.broadwayworld.com',\n  title: {\n    selectors: [\n      'h1.article-title',\n    ],\n  },\n\n  author: {\n    selectors: [\n      'span[itemprop=author]',\n    ],\n  },\n\n  content: {\n    selectors: [\n      'div[itemprop=articlebody]',\n    ],\n\n    // Is there anything in the content you selected that needs transformed\n    // before it's consumable content? E.g., unusual lazy loaded images\n    transforms: {\n    },\n\n    // Is there anything that is in the result that shouldn't be?\n    // The clean selectors will remove anything that matches from\n    // the result\n    clean: [\n\n    ],\n  },\n\n  date_published: {\n    selectors: [\n      ['meta[itemprop=datePublished]', 'value'],\n    ],\n  },\n\n  lead_image_url: {\n    selectors: [\n      ['meta[name=\"og:image\"]', 'value'],\n    ],\n  },\n\n  dek: {\n    selectors: [\n      ['meta[name=\"og:description\"]', 'value'],\n    ],\n  },\n\n  next_page_url: {\n    selectors: [\n      // enter selectors\n    ],\n  },\n\n  excerpt: {\n    selectors: [\n      // enter selectors\n    ],\n  },\n};\n","// Rename CustomExtractor\n// to fit your publication\n// (e.g., NYTimesExtractor)\nexport const ApartmentTherapyExtractor = {\n  domain: 'www.apartmenttherapy.com',\n  title: {\n    selectors: [\n      'h1.headline',\n    ],\n  },\n\n  author: {\n    selectors: [\n      '.PostByline__name',\n    ],\n  },\n\n  content: {\n    selectors: [\n      'div.post__content',\n    ],\n\n    // Is there anything in the content you selected that needs transformed\n    // before it's consumable content? E.g., unusual lazy loaded images\n    transforms: {\n      'div[data-render-react-id=\"images/LazyPicture\"]': ($node, $) => {\n        const data = JSON.parse($node.attr('data-props'));\n        const { src } = data.sources[0];\n        const $img = $('<img />').attr('src', src);\n        $node.replaceWith($img);\n      },\n    },\n\n    // Is there anything that is in the result that shouldn't be?\n    // The clean selectors will remove anything that matches from\n    // the result\n    clean: [\n\n    ],\n  },\n\n  date_published: {\n    selectors: [\n      ['.PostByline__timestamp[datetime]', 'datetime'],\n    ],\n  },\n\n  lead_image_url: {\n    selectors: [\n      ['meta[name=\"og:image\"]', 'value'],\n    ],\n  },\n\n  dek: {\n    selectors: [\n      ['meta[name=description]', 'value'],\n    ],\n  },\n\n  next_page_url: {\n    selectors: [\n      // enter selectors\n    ],\n  },\n\n  excerpt: {\n    selectors: [\n      // enter selectors\n    ],\n  },\n};\n","export const MediumExtractor = {\n  domain: 'medium.com',\n\n  supportedDomains: [\n    'trackchanges.postlight.com',\n  ],\n\n  title: {\n    selectors: [\n      'h1',\n    ],\n  },\n\n  author: {\n    selectors: [\n      ['meta[name=\"author\"]', 'value'],\n    ],\n  },\n\n  content: {\n    selectors: [\n      '.section-content',\n    ],\n\n    // Is there anything in the content you selected that needs transformed\n    // before it's consumable content? E.g., unusual lazy loaded images\n    transforms: {\n      // Re-write lazy-loaded youtube videos\n      iframe: ($node) => {\n        const ytRe =\n          /https:\\/\\/i.embed.ly\\/.+url=https:\\/\\/i\\.ytimg\\.com\\/vi\\/(\\w+)\\//;\n        const thumb = decodeURIComponent($node.attr('data-thumbnail'));\n\n        if (ytRe.test(thumb)) {\n          const [_, youtubeId] = thumb.match(ytRe) // eslint-disable-line\n          $node.attr('src', `https://www.youtube.com/embed/${youtubeId}`);\n          const $parent = $node.parents('figure');\n          $parent.prepend($node.clone());\n          $node.remove();\n        }\n      },\n    },\n\n    // Is there anything that is in the result that shouldn't be?\n    // The clean selectors will remove anything that matches from\n    // the result\n    clean: [\n\n    ],\n  },\n\n  date_published: {\n    selectors: [\n      ['time[datetime]', 'datetime'],\n    ],\n  },\n\n  lead_image_url: {\n    selectors: [\n      ['meta[name=\"og:image\"]', 'value'],\n    ],\n  },\n\n  dek: {\n    selectors: [\n      // enter selectors\n    ],\n  },\n\n  next_page_url: {\n    selectors: [\n      // enter selectors\n    ],\n  },\n\n  excerpt: {\n    selectors: [\n      // enter selectors\n    ],\n  },\n};\n","import mergeSupportedDomains from 'utils/merge-supported-domains';\nimport * as CustomExtractors from './custom/index';\n\nexport default Object.keys(CustomExtractors).reduce((acc, key) => {\n  const extractor = CustomExtractors[key];\n  return {\n    ...acc,\n    ...mergeSupportedDomains(extractor),\n  };\n}, {});\n","// CLEAN AUTHOR CONSTANTS\nexport const CLEAN_AUTHOR_RE = /^\\s*(posted |written )?by\\s*:?\\s*(.*)/i;\n    //     author = re.sub(r'^\\s*(posted |written )?by\\s*:?\\s*(.*)(?i)',\n\n// CLEAN DEK CONSTANTS\nexport const TEXT_LINK_RE = new RegExp('http(s)?://', 'i');\n// An ordered list of meta tag names that denote likely article deks.\n// From most distinct to least distinct.\n//\n// NOTE: There are currently no meta tags that seem to provide the right\n// content consistenty enough. Two options were:\n//  - og:description\n//  - dc.description\n// However, these tags often have SEO-specific junk in them that's not\n// header-worthy like a dek is. Excerpt material at best.\nexport const DEK_META_TAGS = [\n];\n\n// An ordered list of Selectors to find likely article deks. From\n// most explicit to least explicit.\n//\n// Should be more restrictive than not, as a failed dek can be pretty\n// detrimental to the aesthetics of an article.\nexport const DEK_SELECTORS = [\n  '.entry-summary',\n];\n\n// CLEAN DATE PUBLISHED CONSTANTS\nexport const MS_DATE_STRING = /^\\d{13}$/i;\nexport const SEC_DATE_STRING = /^\\d{10}$/i;\nexport const CLEAN_DATE_STRING_RE = /^\\s*published\\s*:?\\s*(.*)/i;\nexport const TIME_MERIDIAN_SPACE_RE = /(.*\\d)(am|pm)(.*)/i;\nexport const TIME_MERIDIAN_DOTS_RE = /\\.m\\./i;\nconst months = [\n  'jan',\n  'feb',\n  'mar',\n  'apr',\n  'may',\n  'jun',\n  'jul',\n  'aug',\n  'sep',\n  'oct',\n  'nov',\n  'dec',\n];\nconst allMonths = months.join('|');\nconst timestamp1 = '[0-9]{1,2}:[0-9]{2,2}( ?[ap].?m.?)?';\nconst timestamp2 = '[0-9]{1,2}[/-][0-9]{1,2}[/-][0-9]{2,4}';\nexport const SPLIT_DATE_STRING =\n  new RegExp(`(${timestamp1})|(${timestamp2})|([0-9]{1,4})|(${allMonths})`, 'ig');\n\n// CLEAN TITLE CONSTANTS\n// A regular expression that will match separating characters on a\n// title, that usually denote breadcrumbs or something similar.\nexport const TITLE_SPLITTERS_RE = /(: | - | \\| )/g;\n\nexport const DOMAIN_ENDINGS_RE =\n  new RegExp('.com$|.net$|.org$|.co.uk$', 'g');\n","import { CLEAN_AUTHOR_RE } from './constants';\n\n// Take an author string (like 'By David Smith ') and clean it to\n// just the name(s): 'David Smith'.\nexport default function cleanAuthor(author) {\n  return author.replace(CLEAN_AUTHOR_RE, '$2').trim();\n}\n","import validUrl from 'valid-url';\n\nexport default function clean(leadImageUrl) {\n  leadImageUrl = leadImageUrl.trim();\n  if (validUrl.isWebUri(leadImageUrl)) {\n    return leadImageUrl;\n  }\n\n  return null;\n}\n","import { stripTags } from 'utils/dom';\nimport { excerptContent } from 'utils/text';\n\nimport { TEXT_LINK_RE } from './constants';\n\n// Take a dek HTML fragment, and return the cleaned version of it.\n// Return None if the dek wasn't good enough.\nexport default function cleanDek(dek, { $, excerpt }) {\n  // Sanity check that we didn't get too short or long of a dek.\n  if (dek.length > 1000 || dek.length < 5) return null;\n\n  // Check that dek isn't the same as excerpt\n  if (excerpt && excerptContent(excerpt, 10) === excerptContent(dek, 10)) return null;\n\n  const dekText = stripTags(dek, $);\n\n  // Plain text links shouldn't exist in the dek. If we have some, it's\n  // not a good dek - bail.\n  if (TEXT_LINK_RE.test(dekText)) return null;\n\n  return dekText.trim();\n}\n","import moment from 'moment';\n// Is there a compelling reason to use moment here?\n// Mostly only being used for the isValid() method,\n// but could just check for 'Invalid Date' string.\n\nimport {\n  MS_DATE_STRING,\n  SEC_DATE_STRING,\n  CLEAN_DATE_STRING_RE,\n  SPLIT_DATE_STRING,\n  TIME_MERIDIAN_SPACE_RE,\n  TIME_MERIDIAN_DOTS_RE,\n} from './constants';\n\nexport function cleanDateString(dateString) {\n  return (dateString.match(SPLIT_DATE_STRING) || [])\n                   .join(' ')\n                   .replace(TIME_MERIDIAN_DOTS_RE, 'm')\n                   .replace(TIME_MERIDIAN_SPACE_RE, '$1 $2 $3')\n                   .replace(CLEAN_DATE_STRING_RE, '$1')\n                   .trim();\n}\n\n// Take a date published string, and hopefully return a date out of\n// it. Return none if we fail.\nexport default function cleanDatePublished(dateString) {\n  // If string is in milliseconds or seconds, convert to int\n  if (MS_DATE_STRING.test(dateString) || SEC_DATE_STRING.test(dateString)) {\n    dateString = parseInt(dateString, 10);\n  }\n\n  let date = moment(new Date(dateString));\n\n  if (!date.isValid()) {\n    dateString = cleanDateString(dateString);\n    date = moment(new Date(dateString));\n  }\n\n  return date.isValid() ? date.toISOString() : null;\n}\n","import {\n  cleanAttributes,\n  cleanHeaders,\n  cleanHOnes,\n  cleanImages,\n  cleanTags,\n  removeEmpty,\n  rewriteTopLevel,\n  markToKeep,\n  stripJunkTags,\n  makeLinksAbsolute,\n} from 'utils/dom';\n\n// Clean our article content, returning a new, cleaned node.\nexport default function extractCleanNode(\n  article,\n  {\n    $,\n    cleanConditionally = true,\n    title = '',\n    url = '',\n    defaultCleaner = true,\n  }\n) {\n  // Rewrite the tag name to div if it's a top level node like body or\n  // html to avoid later complications with multiple body tags.\n  rewriteTopLevel(article, $);\n\n  // Drop small images and spacer images\n  // Only do this is defaultCleaner is set to true;\n  // this can sometimes be too aggressive.\n  if (defaultCleaner) cleanImages(article, $);\n\n  // Mark elements to keep that would normally be removed.\n  // E.g., stripJunkTags will remove iframes, so we're going to mark\n  // YouTube/Vimeo videos as elements we want to keep.\n  markToKeep(article, $, url);\n\n  // Drop certain tags like <title>, etc\n  // This is -mostly- for cleanliness, not security.\n  stripJunkTags(article, $);\n\n  // H1 tags are typically the article title, which should be extracted\n  // by the title extractor instead. If there's less than 3 of them (<3),\n  // strip them. Otherwise, turn 'em into H2s.\n  cleanHOnes(article, $);\n\n  // Clean headers\n  cleanHeaders(article, $, title);\n\n  // Make links absolute\n  makeLinksAbsolute(article, $, url);\n\n  // We used to clean UL's and OL's here, but it was leading to\n  // too many in-article lists being removed. Consider a better\n  // way to detect menus particularly and remove them.\n  // Also optionally running, since it can be overly aggressive.\n  if (defaultCleaner) cleanTags(article, $, cleanConditionally);\n\n  // Remove empty paragraph nodes\n  removeEmpty(article, $);\n\n  // Remove unnecessary attributes\n  cleanAttributes(article, $);\n\n  return article;\n}\n","import { stripTags } from 'utils/dom';\n\nimport { TITLE_SPLITTERS_RE } from './constants';\nimport { resolveSplitTitle } from './index';\n\nexport default function cleanTitle(title, { url, $ }) {\n  // If title has |, :, or - in it, see if\n  // we can clean it up.\n  if (TITLE_SPLITTERS_RE.test(title)) {\n    title = resolveSplitTitle(title, url);\n  }\n\n  // Final sanity check that we didn't get a crazy title.\n  // if (title.length > 150 || title.length < 15) {\n  if (title.length > 150) {\n    // If we did, return h1 from the document if it exists\n    const h1 = $('h1');\n    if (h1.length === 1) {\n      title = h1.text();\n    }\n  }\n\n  // strip any html tags in the title text\n  return stripTags(title, $).trim();\n}\n","import URL from 'url';\nimport wuzzy from 'wuzzy';\n\nimport {\n  TITLE_SPLITTERS_RE,\n  DOMAIN_ENDINGS_RE,\n} from './constants';\n\nfunction extractBreadcrumbTitle(splitTitle, text) {\n  // This must be a very breadcrumbed title, like:\n  // The Best Gadgets on Earth : Bits : Blogs : NYTimes.com\n  // NYTimes - Blogs - Bits - The Best Gadgets on Earth\n  if (splitTitle.length >= 6) {\n    // Look to see if we can find a breadcrumb splitter that happens\n    // more than once. If we can, we'll be able to better pull out\n    // the title.\n    const termCounts = splitTitle.reduce((acc, titleText) => {\n      acc[titleText] = acc[titleText] ? acc[titleText] + 1 : 1;\n      return acc;\n    }, {});\n\n    const [maxTerm, termCount] =\n      Reflect.ownKeys(termCounts)\n             .reduce((acc, key) => {\n               if (acc[1] < termCounts[key]) {\n                 return [key, termCounts[key]];\n               }\n\n               return acc;\n             }, [0, 0]);\n\n    // We found a splitter that was used more than once, so it\n    // is probably the breadcrumber. Split our title on that instead.\n    // Note: max_term should be <= 4 characters, so that \" >> \"\n    // will match, but nothing longer than that.\n    if (termCount >= 2 && maxTerm.length <= 4) {\n      splitTitle = text.split(maxTerm);\n    }\n\n    const splitEnds = [splitTitle[0], splitTitle.slice(-1)];\n    const longestEnd = splitEnds.reduce((acc, end) => acc.length > end.length ? acc : end, '');\n\n    if (longestEnd.length > 10) {\n      return longestEnd;\n    }\n\n    return text;\n  }\n\n  return null;\n}\n\nfunction cleanDomainFromTitle(splitTitle, url) {\n  // Search the ends of the title, looking for bits that fuzzy match\n  // the URL too closely. If one is found, discard it and return the\n  // rest.\n  //\n  // Strip out the big TLDs - it just makes the matching a bit more\n  // accurate. Not the end of the world if it doesn't strip right.\n  const { host } = URL.parse(url);\n  const nakedDomain = host.replace(DOMAIN_ENDINGS_RE, '');\n\n  const startSlug = splitTitle[0].toLowerCase().replace(' ', '');\n  const startSlugRatio = wuzzy.levenshtein(startSlug, nakedDomain);\n\n  if (startSlugRatio > 0.4 && startSlug.length > 5) {\n    return splitTitle.slice(2).join('');\n  }\n\n  const endSlug = splitTitle.slice(-1)[0].toLowerCase().replace(' ', '');\n  const endSlugRatio = wuzzy.levenshtein(endSlug, nakedDomain);\n\n  if (endSlugRatio > 0.4 && endSlug.length >= 5) {\n    return splitTitle.slice(0, -2).join('');\n  }\n\n  return null;\n}\n\n// Given a title with separators in it (colons, dashes, etc),\n// resolve whether any of the segments should be removed.\nexport default function resolveSplitTitle(title, url = '') {\n  // Splits while preserving splitters, like:\n  // ['The New New York', ' - ', 'The Washington Post']\n  const splitTitle = title.split(TITLE_SPLITTERS_RE);\n  if (splitTitle.length === 1) {\n    return title;\n  }\n\n  let newTitle = extractBreadcrumbTitle(splitTitle, title);\n  if (newTitle) return newTitle;\n\n  newTitle = cleanDomainFromTitle(splitTitle, url);\n  if (newTitle) return newTitle;\n\n  // Fuzzy ratio didn't find anything, so this title is probably legit.\n  // Just return it all.\n  return title;\n}\n","import cleanAuthor from './author';\nimport cleanImage from './lead-image-url';\nimport cleanDek from './dek';\nimport cleanDatePublished from './date-published';\nimport cleanContent from './content';\nimport cleanTitle from './title';\n\nconst Cleaners = {\n  author: cleanAuthor,\n  lead_image_url: cleanImage,\n  dek: cleanDek,\n  date_published: cleanDatePublished,\n  content: cleanContent,\n  title: cleanTitle,\n};\n\nexport default Cleaners;\n\nexport { cleanAuthor };\nexport { cleanImage };\nexport { cleanDek };\nexport { cleanDatePublished };\nexport { cleanContent };\nexport { cleanTitle };\nexport { default as resolveSplitTitle } from './resolve-split-title';\n","import {\n  stripUnlikelyCandidates,\n  convertToParagraphs,\n} from 'utils/dom';\n\nimport {\n  scoreContent,\n  findTopCandidate,\n} from './scoring';\n\n// Using a variety of scoring techniques, extract the content most\n// likely to be article text.\n//\n// If strip_unlikely_candidates is True, remove any elements that\n// match certain criteria first. (Like, does this element have a\n// classname of \"comment\")\n//\n// If weight_nodes is True, use classNames and IDs to determine the\n// worthiness of nodes.\n//\n// Returns a cheerio object $\nexport default function extractBestNode($, opts) {\n  // clone the node so we can get back to our\n  // initial parsed state if needed\n  // TODO Do I need this? – AP\n  // let $root = $.root().clone()\n\n  if (opts.stripUnlikelyCandidates) {\n    $ = stripUnlikelyCandidates($);\n  }\n\n  $ = convertToParagraphs($);\n  $ = scoreContent($, opts.weightNodes);\n  const $topCandidate = findTopCandidate($);\n\n  return $topCandidate;\n}\n","import cheerio from 'cheerio';\n\nimport { nodeIsSufficient } from 'utils/dom';\nimport { cleanContent } from 'cleaners';\nimport { normalizeSpaces } from 'utils/text';\n\nimport extractBestNode from './extract-best-node';\n\nconst GenericContentExtractor = {\n  defaultOpts: {\n    stripUnlikelyCandidates: true,\n    weightNodes: true,\n    cleanConditionally: true,\n  },\n\n  // Extract the content for this resource - initially, pass in our\n  // most restrictive opts which will return the highest quality\n  // content. On each failure, retry with slightly more lax opts.\n  //\n  // :param return_type: string. If \"node\", should return the content\n  // as a cheerio node rather than as an HTML string.\n  //\n  // Opts:\n  // stripUnlikelyCandidates: Remove any elements that match\n  // non-article-like criteria first.(Like, does this element\n  //   have a classname of \"comment\")\n  //\n  // weightNodes: Modify an elements score based on whether it has\n  // certain classNames or IDs. Examples: Subtract if a node has\n  // a className of 'comment', Add if a node has an ID of\n  // 'entry-content'.\n  //\n  // cleanConditionally: Clean the node to return of some\n  // superfluous content. Things like forms, ads, etc.\n  extract({ $, html, title, url }, opts) {\n    opts = { ...this.defaultOpts, ...opts };\n\n    $ = $ || cheerio.load(html);\n\n    // Cascade through our extraction-specific opts in an ordered fashion,\n    // turning them off as we try to extract content.\n    let node = this.getContentNode($, title, url, opts);\n\n    if (nodeIsSufficient(node)) {\n      return this.cleanAndReturnNode(node, $);\n    }\n\n    // We didn't succeed on first pass, one by one disable our\n    // extraction opts and try again.\n    for (const key of Reflect.ownKeys(opts).filter(k => opts[k] === true)) {\n      opts[key] = false;\n      $ = cheerio.load(html);\n\n      node = this.getContentNode($, title, url, opts);\n\n      if (nodeIsSufficient(node)) {\n        break;\n      }\n    }\n\n    return this.cleanAndReturnNode(node, $);\n  },\n\n  // Get node given current options\n  getContentNode($, title, url, opts) {\n    return cleanContent(\n              extractBestNode($, opts),\n      {\n        $,\n        cleanConditionally: opts.cleanConditionally,\n        title,\n        url,\n      });\n  },\n\n  // Once we got here, either we're at our last-resort node, or\n  // we broke early. Make sure we at least have -something- before we\n  // move forward.\n  cleanAndReturnNode(node, $) {\n    if (!node) {\n      return null;\n    }\n\n    return normalizeSpaces($.html(node));\n\n    // if return_type == \"html\":\n    //     return normalize_spaces(node_to_html(node))\n    // else:\n    //     return node\n  },\n\n};\n\nexport default GenericContentExtractor;\n","// TODO: It would be great if we could merge the meta and selector lists into\n// a list of objects, because we could then rank them better. For example,\n// .hentry .entry-title is far better suited than <meta title>.\n\n// An ordered list of meta tag names that denote likely article titles. All\n// attributes should be lowercase for faster case-insensitive matching. From\n// most distinct to least distinct.\nexport const STRONG_TITLE_META_TAGS = [\n  'tweetmeme-title',\n  'dc.title',\n  'rbtitle',\n  'headline',\n  'title',\n];\n\n// og:title is weak because it typically contains context that we don't like,\n// for example the source site's name. Gotta get that brand into facebook!\nexport const WEAK_TITLE_META_TAGS = [\n  'og:title',\n];\n\n// An ordered list of XPath Selectors to find likely article titles. From\n// most explicit to least explicit.\n//\n// Note - this does not use classes like CSS. This checks to see if the string\n// exists in the className, which is not as accurate as .className (which\n// splits on spaces/endlines), but for our purposes it's close enough. The\n// speed tradeoff is worth the accuracy hit.\nexport const STRONG_TITLE_SELECTORS = [\n  '.hentry .entry-title',\n  'h1#articleHeader',\n  'h1.articleHeader',\n  'h1.article',\n  '.instapaper_title',\n  '#meebo-title',\n];\n\nexport const WEAK_TITLE_SELECTORS = [\n  'article h1',\n  '#entry-title',\n  '.entry-title',\n  '#entryTitle',\n  '#entrytitle',\n  '.entryTitle',\n  '.entrytitle',\n  '#articleTitle',\n  '.articleTitle',\n  'post post-title',\n  'h1.title',\n  'h2.article',\n  'h1',\n  'html head title',\n  'title',\n];\n","import { cleanTitle } from 'cleaners';\nimport {\n  extractFromMeta,\n  extractFromSelectors,\n} from 'utils/dom';\n\nimport {\n  STRONG_TITLE_META_TAGS,\n  WEAK_TITLE_META_TAGS,\n  STRONG_TITLE_SELECTORS,\n  WEAK_TITLE_SELECTORS,\n} from './constants';\n\nconst GenericTitleExtractor = {\n  extract({ $, url, metaCache }) {\n    // First, check to see if we have a matching meta tag that we can make\n    // use of that is strongly associated with the headline.\n    let title;\n\n    title = extractFromMeta($, STRONG_TITLE_META_TAGS, metaCache);\n    if (title) return cleanTitle(title, { url, $ });\n\n    // Second, look through our content selectors for the most likely\n    // article title that is strongly associated with the headline.\n    title = extractFromSelectors($, STRONG_TITLE_SELECTORS);\n    if (title) return cleanTitle(title, { url, $ });\n\n    // Third, check for weaker meta tags that may match.\n    title = extractFromMeta($, WEAK_TITLE_META_TAGS, metaCache);\n    if (title) return cleanTitle(title, { url, $ });\n\n    // Last, look for weaker selector tags that may match.\n    title = extractFromSelectors($, WEAK_TITLE_SELECTORS);\n    if (title) return cleanTitle(title, { url, $ });\n\n    // If no matches, return an empty string\n    return '';\n  },\n};\n\nexport default GenericTitleExtractor;\n","// An ordered list of meta tag names that denote likely article authors. All\n// attributes should be lowercase for faster case-insensitive matching. From\n// most distinct to least distinct.\n//\n// Note: \"author\" is too often the -developer- of the page, so it is not\n// added here.\nexport const AUTHOR_META_TAGS = [\n  'byl',\n  'clmst',\n  'dc.author',\n  'dcsext.author',\n  'dc.creator',\n  'rbauthors',\n  'authors',\n];\n\nexport const AUTHOR_MAX_LENGTH = 300;\n\n// An ordered list of XPath Selectors to find likely article authors. From\n// most explicit to least explicit.\n//\n// Note - this does not use classes like CSS. This checks to see if the string\n// exists in the className, which is not as accurate as .className (which\n// splits on spaces/endlines), but for our purposes it's close enough. The\n// speed tradeoff is worth the accuracy hit.\nexport const AUTHOR_SELECTORS = [\n  '.entry .entry-author',\n  '.author.vcard .fn',\n  '.author .vcard .fn',\n  '.byline.vcard .fn',\n  '.byline .vcard .fn',\n  '.byline .by .author',\n  '.byline .by',\n  '.byline .author',\n  '.post-author.vcard',\n  '.post-author .vcard',\n  'a[rel=author]',\n  '#by_author',\n  '.by_author',\n  '#entryAuthor',\n  '.entryAuthor',\n  '.byline a[href*=author]',\n  '#author .authorname',\n  '.author .authorname',\n  '#author',\n  '.author',\n  '.articleauthor',\n  '.ArticleAuthor',\n  '.byline',\n];\n\n// An ordered list of Selectors to find likely article authors, with\n// regular expression for content.\nconst bylineRe = /^[\\n\\s]*By/i;\nexport const BYLINE_SELECTORS_RE = [\n  ['#byline', bylineRe],\n  ['.byline', bylineRe],\n];\n","import { cleanAuthor } from 'cleaners';\nimport {\n  extractFromMeta,\n  extractFromSelectors,\n} from 'utils/dom';\n\nimport {\n  AUTHOR_META_TAGS,\n  AUTHOR_MAX_LENGTH,\n  AUTHOR_SELECTORS,\n  BYLINE_SELECTORS_RE,\n} from './constants';\n\nconst GenericAuthorExtractor = {\n  extract({ $, metaCache }) {\n    let author;\n\n    // First, check to see if we have a matching\n    // meta tag that we can make use of.\n    author = extractFromMeta($, AUTHOR_META_TAGS, metaCache);\n    if (author && author.length < AUTHOR_MAX_LENGTH) {\n      return cleanAuthor(author);\n    }\n\n    // Second, look through our selectors looking for potential authors.\n    author = extractFromSelectors($, AUTHOR_SELECTORS, 2);\n    if (author && author.length < AUTHOR_MAX_LENGTH) {\n      return cleanAuthor(author);\n    }\n\n    // Last, use our looser regular-expression based selectors for\n    // potential authors.\n    for (const [selector, regex] of BYLINE_SELECTORS_RE) {\n      const node = $(selector);\n      if (node.length === 1) {\n        const text = node.text();\n        if (regex.test(text)) {\n          return cleanAuthor(text);\n        }\n      }\n    }\n\n    return null;\n  },\n};\n\nexport default GenericAuthorExtractor;\n","// An ordered list of meta tag names that denote\n// likely date published dates. All attributes\n// should be lowercase for faster case-insensitive matching.\n// From most distinct to least distinct.\nexport const DATE_PUBLISHED_META_TAGS = [\n  'article:published_time',\n  'displaydate',\n  'dc.date',\n  'dc.date.issued',\n  'rbpubdate',\n  'publish_date',\n  'pub_date',\n  'pagedate',\n  'pubdate',\n  'revision_date',\n  'doc_date',\n  'date_created',\n  'content_create_date',\n  'lastmodified',\n  'created',\n  'date',\n];\n\n// An ordered list of XPath Selectors to find\n// likely date published dates. From most explicit\n// to least explicit.\nexport const DATE_PUBLISHED_SELECTORS = [\n  '.hentry .dtstamp.published',\n  '.hentry .published',\n  '.hentry .dtstamp.updated',\n  '.hentry .updated',\n  '.single .published',\n  '.meta .published',\n  '.meta .postDate',\n  '.entry-date',\n  '.byline .date',\n  '.postmetadata .date',\n  '.article_datetime',\n  '.date-header',\n  '.story-date',\n  '.dateStamp',\n  '#story .datetime',\n  '.dateline',\n  '.pubdate',\n];\n\n// An ordered list of compiled regular expressions to find likely date\n// published dates from the URL. These should always have the first\n// reference be a date string that is parseable by dateutil.parser.parse\nconst abbrevMonthsStr = '(jan|feb|mar|apr|may|jun|jul|aug|sep|oct|nov|dec)';\nexport const DATE_PUBLISHED_URL_RES = [\n    // /2012/01/27/ but not /2012/01/293\n  new RegExp('/(20\\\\d{2}/\\\\d{2}/\\\\d{2})/', 'i'),\n    // 20120127 or 20120127T but not 2012012733 or 8201201733\n    // /[^0-9](20\\d{2}[01]\\d[0-3]\\d)([^0-9]|$)/i,\n    // 2012-01-27\n  new RegExp('(20\\\\d{2}-[01]\\\\d-[0-3]\\\\d)', 'i'),\n    // /2012/jan/27/\n  new RegExp(`/(20\\\\d{2}/${abbrevMonthsStr}/[0-3]\\\\d)/`, 'i'),\n];\n","import { cleanDatePublished } from 'cleaners';\nimport {\n  extractFromMeta,\n  extractFromSelectors,\n} from 'utils/dom';\nimport { extractFromUrl } from 'utils/text';\n\nimport {\n  DATE_PUBLISHED_META_TAGS,\n  DATE_PUBLISHED_SELECTORS,\n  DATE_PUBLISHED_URL_RES,\n} from './constants';\n\nconst GenericDatePublishedExtractor = {\n  extract({ $, url, metaCache }) {\n    let datePublished;\n    // First, check to see if we have a matching meta tag\n    // that we can make use of.\n    // Don't try cleaning tags from this string\n    datePublished = extractFromMeta($, DATE_PUBLISHED_META_TAGS, metaCache, false);\n    if (datePublished) return cleanDatePublished(datePublished);\n\n    // Second, look through our selectors looking for potential\n    // date_published's.\n    datePublished = extractFromSelectors($, DATE_PUBLISHED_SELECTORS);\n    if (datePublished) return cleanDatePublished(datePublished);\n\n    // Lastly, look to see if a dately string exists in the URL\n    datePublished = extractFromUrl(url, DATE_PUBLISHED_URL_RES);\n    if (datePublished) return cleanDatePublished(datePublished);\n\n    return null;\n  },\n};\n\nexport default GenericDatePublishedExtractor;\n","// import {\n//   DEK_META_TAGS,\n//   DEK_SELECTORS,\n//   DEK_URL_RES,\n// } from './constants';\n\n// import { cleanDek } from 'cleaners';\n\n// import {\n//   extractFromMeta,\n//   extractFromSelectors,\n// } from 'utils/dom';\n\n// Currently there is only one selector for\n// deks. We should simply return null here\n// until we have a more robust generic option.\n// Below is the original source for this, for reference.\nconst GenericDekExtractor = {\n  // extract({ $, content, metaCache }) {\n  extract() {\n    return null;\n  },\n};\n\nexport default GenericDekExtractor;\n\n// def extract_dek(self):\n//     # First, check to see if we have a matching meta tag that we can make\n//     # use of.\n//     dek = self.extract_from_meta('dek', constants.DEK_META_TAGS)\n//     if not dek:\n//         # Second, look through our CSS/XPath selectors. This may return\n//         # an HTML fragment.\n//         dek = self.extract_from_selectors('dek',\n//                                            constants.DEK_SELECTORS,\n//                                            text_only=False)\n//\n//     if dek:\n//         # Make sure our dek isn't in the first few thousand characters\n//         # of the content, otherwise it's just the start of the article\n//         # and not a true dek.\n//         content = self.extract_content()\n//         content_chunk = normalize_spaces(strip_tags(content[:2000]))\n//         dek_chunk = normalize_spaces(dek[:100]) # Already has no tags.\n//\n//         # 80% or greater similarity means the dek was very similar to some\n//         # of the starting content, so we skip it.\n//         if fuzz.partial_ratio(content_chunk, dek_chunk) < 80:\n//             return dek\n//\n//     return None\n","// An ordered list of meta tag names that denote likely article leading images.\n// All attributes should be lowercase for faster case-insensitive matching.\n// From most distinct to least distinct.\nexport const LEAD_IMAGE_URL_META_TAGS = [\n  'og:image',\n  'twitter:image',\n  'image_src',\n];\n\nexport const LEAD_IMAGE_URL_SELECTORS = [\n  'link[rel=image_src]',\n];\n\nexport const POSITIVE_LEAD_IMAGE_URL_HINTS = [\n  'upload',\n  'wp-content',\n  'large',\n  'photo',\n  'wp-image',\n];\nexport const POSITIVE_LEAD_IMAGE_URL_HINTS_RE = new RegExp(POSITIVE_LEAD_IMAGE_URL_HINTS.join('|'), 'i');\n\nexport const NEGATIVE_LEAD_IMAGE_URL_HINTS = [\n  'spacer',\n  'sprite',\n  'blank',\n  'throbber',\n  'gradient',\n  'tile',\n  'bg',\n  'background',\n  'icon',\n  'social',\n  'header',\n  'hdr',\n  'advert',\n  'spinner',\n  'loader',\n  'loading',\n  'default',\n  'rating',\n  'share',\n  'facebook',\n  'twitter',\n  'theme',\n  'promo',\n  'ads',\n  'wp-includes',\n];\nexport const NEGATIVE_LEAD_IMAGE_URL_HINTS_RE = new RegExp(NEGATIVE_LEAD_IMAGE_URL_HINTS.join('|'), 'i');\n\nexport const GIF_RE = /\\.gif(\\?.*)?$/i;\nexport const JPG_RE = /\\.jpe?g(\\?.*)?$/i;\n","import {\n  POSITIVE_LEAD_IMAGE_URL_HINTS_RE,\n  NEGATIVE_LEAD_IMAGE_URL_HINTS_RE,\n  GIF_RE,\n  JPG_RE,\n} from './constants';\n\nimport { PHOTO_HINTS_RE } from '../content/scoring/constants';\n\nfunction getSig($node) {\n  return `${$node.attr('class') || ''} ${$node.attr('id') || ''}`;\n}\n\n// Scores image urls based on a variety of heuristics.\nexport function scoreImageUrl(url) {\n  url = url.trim();\n  let score = 0;\n\n  if (POSITIVE_LEAD_IMAGE_URL_HINTS_RE.test(url)) {\n    score += 20;\n  }\n\n  if (NEGATIVE_LEAD_IMAGE_URL_HINTS_RE.test(url)) {\n    score -= 20;\n  }\n\n  // TODO: We might want to consider removing this as\n  // gifs are much more common/popular than they once were\n  if (GIF_RE.test(url)) {\n    score -= 10;\n  }\n\n  if (JPG_RE.test(url)) {\n    score += 10;\n  }\n\n  // PNGs are neutral.\n\n  return score;\n}\n\n// Alt attribute usually means non-presentational image.\nexport function scoreAttr($img) {\n  if ($img.attr('alt')) {\n    return 5;\n  }\n\n  return 0;\n}\n\n// Look through our parent and grandparent for figure-like\n// container elements, give a bonus if we find them\nexport function scoreByParents($img) {\n  let score = 0;\n  const $figParent = $img.parents('figure').first();\n\n  if ($figParent.length === 1) {\n    score += 25;\n  }\n\n  const $parent = $img.parent();\n  let $gParent;\n  if ($parent.length === 1) {\n    $gParent = $parent.parent();\n  }\n\n  [$parent, $gParent].forEach(($node) => {\n    if (PHOTO_HINTS_RE.test(getSig($node))) {\n      score += 15;\n    }\n  });\n\n  return score;\n}\n\n// Look at our immediate sibling and see if it looks like it's a\n// caption. Bonus if so.\nexport function scoreBySibling($img) {\n  let score = 0;\n  const $sibling = $img.next();\n  const sibling = $sibling.get(0);\n\n  if (sibling && sibling.tagName.toLowerCase() === 'figcaption') {\n    score += 25;\n  }\n\n  if (PHOTO_HINTS_RE.test(getSig($sibling))) {\n    score += 15;\n  }\n\n  return score;\n}\n\nexport function scoreByDimensions($img) {\n  let score = 0;\n\n  const width = parseFloat($img.attr('width'));\n  const height = parseFloat($img.attr('height'));\n  const src = $img.attr('src');\n\n  // Penalty for skinny images\n  if (width && width <= 50) {\n    score -= 50;\n  }\n\n  // Penalty for short images\n  if (height && height <= 50) {\n    score -= 50;\n  }\n\n  if (width && height && !src.includes('sprite')) {\n    const area = width * height;\n    if (area < 5000) { // Smaller than 50 x 100\n      score -= 100;\n    } else {\n      score += Math.round(area / 1000);\n    }\n  }\n\n  return score;\n}\n\nexport function scoreByPosition($imgs, index) {\n  return ($imgs.length / 2) - index;\n}\n","import { extractFromMeta } from 'utils/dom';\nimport { cleanImage } from 'cleaners';\n\nimport {\n  LEAD_IMAGE_URL_META_TAGS,\n  LEAD_IMAGE_URL_SELECTORS,\n} from './constants';\n\nimport {\n  scoreImageUrl,\n  scoreAttr,\n  scoreByParents,\n  scoreBySibling,\n  scoreByDimensions,\n  scoreByPosition,\n} from './score-image';\n\n// Given a resource, try to find the lead image URL from within\n// it. Like content and next page extraction, uses a scoring system\n// to determine what the most likely image may be. Short circuits\n// on really probable things like og:image meta tags.\n//\n// Potential signals to still take advantage of:\n//   * domain\n//   * weird aspect ratio\nconst GenericLeadImageUrlExtractor = {\n  extract({ $, content, metaCache, html }) {\n    let cleanUrl;\n    if (!$.browser && $('head').length === 0) {\n      $('*').first().prepend(html);\n    }\n\n    // Check to see if we have a matching meta tag that we can make use of.\n    // Moving this higher because common practice is now to use large\n    // images on things like Open Graph or Twitter cards.\n    // images usually have for things like Open Graph.\n    const imageUrl =\n      extractFromMeta(\n        $,\n        LEAD_IMAGE_URL_META_TAGS,\n        metaCache,\n        false\n      );\n\n    if (imageUrl) {\n      cleanUrl = cleanImage(imageUrl);\n\n      if (cleanUrl) return cleanUrl;\n    }\n\n    // Next, try to find the \"best\" image via the content.\n    // We'd rather not have to fetch each image and check dimensions,\n    // so try to do some analysis and determine them instead.\n    const $content = $(content);\n    const imgs = $('img', $content).toArray();\n    const imgScores = {};\n\n    imgs.forEach((img, index) => {\n      const $img = $(img);\n      const src = $img.attr('src');\n\n      if (!src) return;\n\n      let score = scoreImageUrl(src);\n      score += scoreAttr($img);\n      score += scoreByParents($img);\n      score += scoreBySibling($img);\n      score += scoreByDimensions($img);\n      score += scoreByPosition(imgs, index);\n\n      imgScores[src] = score;\n    });\n\n    const [topUrl, topScore] =\n      Reflect.ownKeys(imgScores).reduce((acc, key) =>\n        imgScores[key] > acc[1] ? [key, imgScores[key]] : acc\n      , [null, 0]);\n\n    if (topScore > 0) {\n      cleanUrl = cleanImage(topUrl);\n\n      if (cleanUrl) return cleanUrl;\n    }\n\n    // If nothing else worked, check to see if there are any really\n    // probable nodes in the doc, like <link rel=\"image_src\" />.\n    for (const selector of LEAD_IMAGE_URL_SELECTORS) {\n      const $node = $(selector).first();\n      const src = $node.attr('src');\n      if (src) {\n        cleanUrl = cleanImage(src);\n        if (cleanUrl) return cleanUrl;\n      }\n\n      const href = $node.attr('href');\n      if (href) {\n        cleanUrl = cleanImage(href);\n        if (cleanUrl) return cleanUrl;\n      }\n\n      const value = $node.attr('value');\n      if (value) {\n        cleanUrl = cleanImage(value);\n        if (cleanUrl) return cleanUrl;\n      }\n    }\n\n    return null;\n  },\n};\n\nexport default GenericLeadImageUrlExtractor;\n\n// def extract(self):\n//     \"\"\"\n//     # First, try to find the \"best\" image via the content.\n//     # We'd rather not have to fetch each image and check dimensions,\n//     # so try to do some analysis and determine them instead.\n//     content = self.extractor.extract_content(return_type=\"node\")\n//     imgs = content.xpath('.//img')\n//     img_scores = defaultdict(int)\n//     logger.debug('Scoring %d images from content', len(imgs))\n//     for (i, img) in enumerate(imgs):\n//         img_score = 0\n//\n//         if not 'src' in img.attrib:\n//             logger.debug('No src attribute found')\n//             continue\n//\n//         try:\n//             parsed_img = urlparse(img.attrib['src'])\n//             img_path = parsed_img.path.lower()\n//         except ValueError:\n//             logger.debug('ValueError getting img path.')\n//             continue\n//         logger.debug('Image path is %s', img_path)\n//\n//         if constants.POSITIVE_LEAD_IMAGE_URL_HINTS_RE.match(img_path):\n//             logger.debug('Positive URL hints match. Adding 20.')\n//             img_score += 20\n//\n//         if constants.NEGATIVE_LEAD_IMAGE_URL_HINTS_RE.match(img_path):\n//             logger.debug('Negative URL hints match. Subtracting 20.')\n//             img_score -= 20\n//\n//         # Gifs are more often structure than photos\n//         if img_path.endswith('gif'):\n//             logger.debug('gif found. Subtracting 10.')\n//             img_score -= 10\n//\n//         # JPGs are more often photographs\n//         if img_path.endswith('jpg'):\n//             logger.debug('jpg found. Adding 10.')\n//             img_score += 10\n//\n//         # PNGs are neutral.\n//\n//         # Alt attribute usually means non-presentational image.\n//         if 'alt' in img.attrib and len(img.attrib['alt']) > 5:\n//             logger.debug('alt attribute found. Adding 5.')\n//             img_score += 5\n//\n//         # Look through our parent and grandparent for figure-like\n//         # container elements, give a bonus if we find them\n//         parents = [img.getparent()]\n//         if parents[0] is not None and parents[0].getparent() is not None:\n//             parents.append(parents[0].getparent())\n//         for p in parents:\n//             if p.tag == 'figure':\n//                 logger.debug('Parent with <figure> tag found. Adding 25.')\n//                 img_score += 25\n//\n//             p_sig = ' '.join([p.get('id', ''), p.get('class', '')])\n//             if constants.PHOTO_HINTS_RE.search(p_sig):\n//                 logger.debug('Photo hints regex match. Adding 15.')\n//                 img_score += 15\n//\n//         # Look at our immediate sibling and see if it looks like it's a\n//         # caption. Bonus if so.\n//         sibling = img.getnext()\n//         if sibling is not None:\n//             if sibling.tag == 'figcaption':\n//                 img_score += 25\n//\n//             sib_sig = ' '.join([sibling.get('id', ''),\n//                                 sibling.get('class', '')]).lower()\n//             if 'caption' in sib_sig:\n//                 img_score += 15\n//\n//         # Pull out width/height if they were set.\n//         img_width = None\n//         img_height = None\n//         if 'width' in img.attrib:\n//             try:\n//                 img_width = float(img.get('width'))\n//             except ValueError:\n//                 pass\n//         if 'height' in img.attrib:\n//             try:\n//                 img_height = float(img.get('height'))\n//             except ValueError:\n//                 pass\n//\n//         # Penalty for skinny images\n//         if img_width and img_width <= 50:\n//             logger.debug('Skinny image found. Subtracting 50.')\n//             img_score -= 50\n//\n//         # Penalty for short images\n//         if img_height and img_height <= 50:\n//             # Wide, short images are more common than narrow, tall ones\n//             logger.debug('Short image found. Subtracting 25.')\n//             img_score -= 25\n//\n//         if img_width and img_height and not 'sprite' in img_path:\n//             area = img_width * img_height\n//\n//             if area < 5000: # Smaller than 50x100\n//                 logger.debug('Image with small area found. Subtracting 100.')\n//                 img_score -= 100\n//             else:\n//                 img_score += round(area/1000.0)\n//\n//         # If the image is higher on the page than other images,\n//         # it gets a bonus. Penalty if lower.\n//         logger.debug('Adding page placement bonus of %d.', len(imgs)/2 - i)\n//         img_score += len(imgs)/2 - i\n//\n//         # Use the raw src here because we munged img_path for case\n//         # insensitivity\n//         logger.debug('Final score is %d.', img_score)\n//         img_scores[img.attrib['src']] += img_score\n//\n//     top_score = 0\n//     top_url = None\n//     for (url, score) in img_scores.items():\n//         if score > top_score:\n//             top_url = url\n//             top_score = score\n//\n//     if top_score > 0:\n//         logger.debug('Using top score image from content. Score was %d', top_score)\n//         return top_url\n//\n//\n//     # If nothing else worked, check to see if there are any really\n//     # probable nodes in the doc, like <link rel=\"image_src\" />.\n//     logger.debug('Trying to find lead image in probable nodes')\n//     for selector in constants.LEAD_IMAGE_URL_SELECTORS:\n//         nodes = self.resource.extract_by_selector(selector)\n//         for node in nodes:\n//             clean_value = None\n//             if node.attrib.get('src'):\n//                 clean_value = self.clean(node.attrib['src'])\n//\n//             if not clean_value and node.attrib.get('href'):\n//                 clean_value = self.clean(node.attrib['href'])\n//\n//             if not clean_value and node.attrib.get('value'):\n//                 clean_value = self.clean(node.attrib['value'])\n//\n//             if clean_value:\n//                 logger.debug('Found lead image in probable nodes.')\n//                 logger.debug('Node was: %s', node)\n//                 return clean_value\n//\n//     return None\n","import difflib from 'difflib';\n\nexport default function scoreSimilarity(score, articleUrl, href) {\n  // Do this last and only if we have a real candidate, because it's\n  // potentially expensive computationally. Compare the link to this\n  // URL using difflib to get the % similarity of these URLs. On a\n  // sliding scale, subtract points from this link based on\n  // similarity.\n  if (score > 0) {\n    const similarity = new difflib.SequenceMatcher(null, articleUrl, href).ratio();\n    // Subtract .1 from diff_percent when calculating modifier,\n    // which means that if it's less than 10% different, we give a\n    // bonus instead. Ex:\n    //  3% different = +17.5 points\n    // 10% different = 0 points\n    // 20% different = -25 points\n    const diffPercent = 1.0 - similarity;\n    const diffModifier = -(250 * (diffPercent - 0.2));\n    return score + diffModifier;\n  }\n\n  return 0;\n}\n","import { IS_DIGIT_RE } from 'utils/text/constants';\n\nexport default function scoreLinkText(linkText, pageNum) {\n  // If the link text can be parsed as a number, give it a minor\n  // bonus, with a slight bias towards lower numbered pages. This is\n  // so that pages that might not have 'next' in their text can still\n  // get scored, and sorted properly by score.\n  let score = 0;\n\n  if (IS_DIGIT_RE.test(linkText.trim())) {\n    const linkTextAsNum = parseInt(linkText, 10);\n    // If it's the first page, we already got it on the first call.\n    // Give it a negative score. Otherwise, up to page 10, give a\n    // small bonus.\n    if (linkTextAsNum < 2) {\n      score = -30;\n    } else {\n      score = Math.max(0, 10 - linkTextAsNum);\n    }\n\n    // If it appears that the current page number is greater than\n    // this links page number, it's a very bad sign. Give it a big\n    // penalty.\n    if (pageNum && pageNum >= linkTextAsNum) {\n      score -= 50;\n    }\n  }\n\n  return score;\n}\n","export default function scorePageInLink(pageNum, isWp) {\n  // page in the link = bonus. Intentionally ignore wordpress because\n  // their ?p=123 link style gets caught by this even though it means\n  // separate documents entirely.\n  if (pageNum && !isWp) {\n    return 50;\n  }\n\n  return 0;\n}\n","export const DIGIT_RE = /\\d/;\n\n// A list of words that, if found in link text or URLs, likely mean that\n// this link is not a next page link.\nexport const EXTRANEOUS_LINK_HINTS = [\n  'print',\n  'archive',\n  'comment',\n  'discuss',\n  'e-mail',\n  'email',\n  'share',\n  'reply',\n  'all',\n  'login',\n  'sign',\n  'single',\n  'adx',\n  'entry-unrelated',\n];\nexport const EXTRANEOUS_LINK_HINTS_RE = new RegExp(EXTRANEOUS_LINK_HINTS.join('|'), 'i');\n\n// Match any link text/classname/id that looks like it could mean the next\n// page. Things like: next, continue, >, >>, » but not >|, »| as those can\n// mean last page.\nexport const NEXT_LINK_TEXT_RE = new RegExp('(next|weiter|continue|>([^|]|$)|»([^|]|$))', 'i');\n\n// Match any link text/classname/id that looks like it is an end link: things\n// like \"first\", \"last\", \"end\", etc.\nexport const CAP_LINK_TEXT_RE = new RegExp('(first|last|end)', 'i');\n\n// Match any link text/classname/id that looks like it means the previous\n// page.\nexport const PREV_LINK_TEXT_RE = new RegExp('(prev|earl|old|new|<|«)', 'i');\n\n// Match any phrase that looks like it could be page, or paging, or pagination\nexport const PAGE_RE = new RegExp('pag(e|ing|inat)', 'i');\n","import { EXTRANEOUS_LINK_HINTS_RE } from '../constants';\n\nexport default function scoreExtraneousLinks(href) {\n  // If the URL itself contains extraneous values, give a penalty.\n  if (EXTRANEOUS_LINK_HINTS_RE.test(href)) {\n    return -25;\n  }\n\n  return 0;\n}\n","import { range } from 'utils';\nimport {\n  NEGATIVE_SCORE_RE,\n  POSITIVE_SCORE_RE,\n  PAGE_RE,\n} from 'utils/dom/constants';\nimport { EXTRANEOUS_LINK_HINTS_RE } from '../constants';\n\nfunction makeSig($link) {\n  return `${$link.attr('class') || ''} ${$link.attr('id') || ''}`;\n}\n\nexport default function scoreByParents($link) {\n  // If a parent node contains paging-like classname or id, give a\n  // bonus. Additionally, if a parent_node contains bad content\n  // (like 'sponsor'), give a penalty.\n  let $parent = $link.parent();\n  let positiveMatch = false;\n  let negativeMatch = false;\n  let score = 0;\n\n  Array.from(range(0, 4)).forEach(() => {\n    if ($parent.length === 0) {\n      return;\n    }\n\n    const parentData = makeSig($parent, ' ');\n\n    // If we have 'page' or 'paging' in our data, that's a good\n    // sign. Add a bonus.\n    if (!positiveMatch && PAGE_RE.test(parentData)) {\n      positiveMatch = true;\n      score += 25;\n    }\n\n    // If we have 'comment' or something in our data, and\n    // we don't have something like 'content' as well, that's\n    // a bad sign. Give a penalty.\n    if (!negativeMatch && NEGATIVE_SCORE_RE.test(parentData)\n       && EXTRANEOUS_LINK_HINTS_RE.test(parentData)) {\n      if (!POSITIVE_SCORE_RE.test(parentData)) {\n        negativeMatch = true;\n        score -= 25;\n      }\n    }\n\n    $parent = $parent.parent();\n  });\n\n  return score;\n}\n","import { PREV_LINK_TEXT_RE } from '../constants';\n\nexport default function scorePrevLink(linkData) {\n  // If the link has something like \"previous\", its definitely\n  // an old link, skip it.\n  if (PREV_LINK_TEXT_RE.test(linkData)) {\n    return -200;\n  }\n\n  return 0;\n}\n","import URL from 'url';\n\nimport {\n  DIGIT_RE,\n  EXTRANEOUS_LINK_HINTS_RE,\n} from '../constants';\n\nexport default function shouldScore(\n  href,\n  articleUrl,\n  baseUrl,\n  parsedUrl,\n  linkText,\n  previousUrls\n) {\n  // skip if we've already fetched this url\n  if (previousUrls.find(url => href === url) !== undefined) {\n    return false;\n  }\n\n  // If we've already parsed this URL, or the URL matches the base\n  // URL, or is empty, skip it.\n  if (!href || href === articleUrl || href === baseUrl) {\n    return false;\n  }\n\n  const { hostname } = parsedUrl;\n  const { hostname: linkHost } = URL.parse(href);\n\n  // Domain mismatch.\n  if (linkHost !== hostname) {\n    return false;\n  }\n\n  // If href doesn't contain a digit after removing the base URL,\n  // it's certainly not the next page.\n  const fragment = href.replace(baseUrl, '');\n  if (!DIGIT_RE.test(fragment)) {\n    return false;\n  }\n\n  // This link has extraneous content (like \"comment\") in its link\n  // text, so we skip it.\n  if (EXTRANEOUS_LINK_HINTS_RE.test(linkText)) {\n    return false;\n  }\n\n  // Next page link text is never long, skip if it is too long.\n  if (linkText.length > 25) {\n    return false;\n  }\n\n  return true;\n}\n","export default function scoreBaseUrl(href, baseRegex) {\n  // If the baseUrl isn't part of this URL, penalize this\n  // link. It could still be the link, but the odds are lower.\n  // Example:\n  // http://www.actionscript.org/resources/articles/745/1/JavaScript-and-VBScript-Injection-in-ActionScript-3/Page1.html\n  if (!baseRegex.test(href)) {\n    return -25;\n  }\n\n  return 0;\n}\n","import { NEXT_LINK_TEXT_RE } from '../constants';\n\nexport default function scoreNextLinkText(linkData) {\n  // Things like \"next\", \">>\", etc.\n  if (NEXT_LINK_TEXT_RE.test(linkData)) {\n    return 50;\n  }\n\n  return 0;\n}\n","import {\n  NEXT_LINK_TEXT_RE,\n  CAP_LINK_TEXT_RE,\n} from '../constants';\n\nexport default function scoreCapLinks(linkData) {\n  // Cap links are links like \"last\", etc.\n  if (CAP_LINK_TEXT_RE.test(linkData)) {\n    // If we found a link like \"last\", but we've already seen that\n    // this link is also \"next\", it's fine. If it's not been\n    // previously marked as \"next\", then it's probably bad.\n    // Penalize.\n    if (NEXT_LINK_TEXT_RE.test(linkData)) {\n      return -65;\n    }\n  }\n\n  return 0;\n}\n","import URL from 'url';\n\nimport {\n  getAttrs,\n  isWordpress,\n} from 'utils/dom';\nimport {\n  removeAnchor,\n  pageNumFromUrl,\n} from 'utils/text';\n\nimport {\n  scoreSimilarity,\n  scoreLinkText,\n  scorePageInLink,\n  scoreExtraneousLinks,\n  scoreByParents,\n  scorePrevLink,\n  shouldScore,\n  scoreBaseUrl,\n  scoreCapLinks,\n  scoreNextLinkText,\n} from './utils';\n\nexport function makeBaseRegex(baseUrl) {\n  return new RegExp(`^${baseUrl}`, 'i');\n}\n\nfunction makeSig($link, linkText) {\n  return `${linkText || $link.text()} ${$link.attr('class') || ''} ${$link.attr('id') || ''}`;\n}\n\nexport default function scoreLinks({\n  links,\n  articleUrl,\n  baseUrl,\n  parsedUrl,\n  $,\n  previousUrls = [],\n}) {\n  parsedUrl = parsedUrl || URL.parse(articleUrl);\n  const baseRegex = makeBaseRegex(baseUrl);\n  const isWp = isWordpress($);\n\n  // Loop through all links, looking for hints that they may be next-page\n  // links. Things like having \"page\" in their textContent, className or\n  // id, or being a child of a node with a page-y className or id.\n  //\n  // After we do that, assign each page a score, and pick the one that\n  // looks most like the next page link, as long as its score is strong\n  // enough to have decent confidence.\n  const scoredPages = links.reduce((possiblePages, link) => {\n    // Remove any anchor data since we don't do a good job\n    // standardizing URLs (it's hard), we're going to do\n    // some checking with and without a trailing slash\n    const attrs = getAttrs(link);\n\n    // if href is undefined, return\n    if (!attrs.href) return possiblePages;\n\n    const href = removeAnchor(attrs.href);\n    const $link = $(link);\n    const linkText = $link.text();\n\n    if (!shouldScore(href, articleUrl, baseUrl, parsedUrl, linkText, previousUrls)) {\n      return possiblePages;\n    }\n\n    // ## PASSED THE FIRST-PASS TESTS. Start scoring. ##\n    if (!possiblePages[href]) {\n      possiblePages[href] = {\n        score: 0,\n        linkText,\n        href,\n      };\n    } else {\n      possiblePages[href].linkText = `${possiblePages[href].linkText}|${linkText}`;\n    }\n\n    const possiblePage = possiblePages[href];\n    const linkData = makeSig($link, linkText);\n    const pageNum = pageNumFromUrl(href);\n\n    let score = scoreBaseUrl(href, baseRegex);\n    score += scoreNextLinkText(linkData);\n    score += scoreCapLinks(linkData);\n    score += scorePrevLink(linkData);\n    score += scoreByParents($link);\n    score += scoreExtraneousLinks(href);\n    score += scorePageInLink(pageNum, isWp);\n    score += scoreLinkText(linkText, pageNum);\n    score += scoreSimilarity(score, articleUrl, href);\n\n    possiblePage.score = score;\n\n    return possiblePages;\n  }, {});\n\n  return Reflect.ownKeys(scoredPages).length === 0 ? null : scoredPages;\n}\n","import URL from 'url';\n\nimport {\n  articleBaseUrl,\n  removeAnchor,\n} from 'utils/text';\nimport scoreLinks from './scoring/score-links';\n\n// Looks for and returns next page url\n// for multi-page articles\nconst GenericNextPageUrlExtractor = {\n  extract({ $, url, parsedUrl, previousUrls = [] }) {\n    parsedUrl = parsedUrl || URL.parse(url);\n\n    const articleUrl = removeAnchor(url);\n    const baseUrl = articleBaseUrl(url, parsedUrl);\n\n    const links = $('a[href]').toArray();\n\n    const scoredLinks = scoreLinks({\n      links,\n      articleUrl,\n      baseUrl,\n      parsedUrl,\n      $,\n      previousUrls,\n    });\n\n    // If no links were scored, return null\n    if (!scoredLinks) return null;\n\n    // now that we've scored all possible pages,\n    // find the biggest one.\n    const topPage = Reflect.ownKeys(scoredLinks).reduce((acc, link) => {\n      const scoredLink = scoredLinks[link];\n      return scoredLink.score > acc.score ? scoredLink : acc;\n    }, { score: -100 });\n\n    // If the score is less than 50, we're not confident enough to use it,\n    // so we fail.\n    if (topPage.score >= 50) {\n      return topPage.href;\n    }\n\n    return null;\n  },\n};\n\nexport default GenericNextPageUrlExtractor;\n","export const CANONICAL_META_SELECTORS = [\n  'og:url',\n];\n","import URL from 'url';\nimport { extractFromMeta } from 'utils/dom';\n\nimport { CANONICAL_META_SELECTORS } from './constants';\n\nfunction parseDomain(url) {\n  const parsedUrl = URL.parse(url);\n  const { hostname } = parsedUrl;\n  return hostname;\n}\n\nfunction result(url) {\n  return {\n    url,\n    domain: parseDomain(url),\n  };\n}\n\nconst GenericUrlExtractor = {\n  extract({ $, url, metaCache }) {\n    const $canonical = $('link[rel=canonical]');\n    if ($canonical.length !== 0) {\n      const href = $canonical.attr('href');\n      if (href) {\n        return result(href);\n      }\n    }\n\n    const metaUrl = extractFromMeta($, CANONICAL_META_SELECTORS, metaCache);\n    if (metaUrl) {\n      return result(metaUrl);\n    }\n\n    return result(url);\n  },\n\n};\n\nexport default GenericUrlExtractor;\n","export const EXCERPT_META_SELECTORS = [\n  'og:description',\n  'twitter:description',\n];\n","import ellipsize from 'ellipsize';\n\nimport {\n  extractFromMeta,\n  stripTags,\n} from 'utils/dom';\n\nimport { EXCERPT_META_SELECTORS } from './constants';\n\nexport function clean(content, $, maxLength = 200) {\n  content = content.replace(/[\\s\\n]+/g, ' ').trim();\n  return ellipsize(content, maxLength, { ellipse: '&hellip;' });\n}\n\nconst GenericExcerptExtractor = {\n  extract({ $, content, metaCache }) {\n    const excerpt = extractFromMeta($, EXCERPT_META_SELECTORS, metaCache);\n    if (excerpt) {\n      return clean(stripTags(excerpt, $));\n    }\n    // Fall back to excerpting from the extracted content\n    const maxLength = 200;\n    const shortContent = content.slice(0, maxLength * 5);\n    return clean($(shortContent).text(), $, maxLength);\n  },\n};\n\nexport default GenericExcerptExtractor;\n","import cheerio from 'cheerio';\n\nimport { normalizeSpaces } from 'utils/text';\n\nconst GenericWordCountExtractor = {\n  extract({ content }) {\n    const $ = cheerio.load(content);\n    const $content = $('div').first();\n\n    const text = normalizeSpaces($content.text());\n    return text.split(/\\s/).length;\n  },\n};\n\nexport default GenericWordCountExtractor;\n","import cheerio from 'cheerio';\nimport stringDirection from 'string-direction';\n\nimport GenericContentExtractor from './content/extractor';\nimport GenericTitleExtractor from './title/extractor';\nimport GenericAuthorExtractor from './author/extractor';\nimport GenericDatePublishedExtractor from './date-published/extractor';\nimport GenericDekExtractor from './dek/extractor';\nimport GenericLeadImageUrlExtractor from './lead-image-url/extractor';\nimport GenericNextPageUrlExtractor from './next-page-url/extractor';\nimport GenericUrlExtractor from './url/extractor';\nimport GenericExcerptExtractor from './excerpt/extractor';\nimport GenericWordCountExtractor from './word-count/extractor';\n\nconst GenericExtractor = {\n  // This extractor is the default for all domains\n  domain: '*',\n  title: GenericTitleExtractor.extract,\n  date_published: GenericDatePublishedExtractor.extract,\n  author: GenericAuthorExtractor.extract,\n  content: GenericContentExtractor.extract.bind(GenericContentExtractor),\n  lead_image_url: GenericLeadImageUrlExtractor.extract,\n  dek: GenericDekExtractor.extract,\n  next_page_url: GenericNextPageUrlExtractor.extract,\n  url_and_domain: GenericUrlExtractor.extract,\n  excerpt: GenericExcerptExtractor.extract,\n  word_count: GenericWordCountExtractor.extract,\n  direction: ({ title }) => stringDirection.getDirection(title),\n\n  extract(options) {\n    const { html, $ } = options;\n\n    if (html && !$) {\n      const loaded = cheerio.load(html);\n      options.$ = loaded;\n    }\n\n    const title = this.title(options);\n    const date_published = this.date_published(options);\n    const author = this.author(options);\n    const content = this.content({ ...options, title });\n    const lead_image_url = this.lead_image_url({ ...options, content });\n    const dek = this.dek({ ...options, content });\n    const next_page_url = this.next_page_url(options);\n    const excerpt = this.excerpt({ ...options, content });\n    const word_count = this.word_count({ ...options, content });\n    const direction = this.direction({ title });\n    const { url, domain } = this.url_and_domain(options);\n\n    return {\n      title,\n      author,\n      date_published: date_published || null,\n      dek,\n      lead_image_url,\n      content,\n      next_page_url,\n      url,\n      domain,\n      excerpt,\n      word_count,\n      direction,\n    };\n  },\n};\n\nexport default GenericExtractor;\n","import URL from 'url';\n\nimport Extractors from './all';\nimport GenericExtractor from './generic';\n\nexport default function getExtractor(url, parsedUrl) {\n  parsedUrl = parsedUrl || URL.parse(url);\n  const { hostname } = parsedUrl;\n  const baseDomain = hostname.split('.').slice(-2).join('.');\n\n  return Extractors[hostname] || Extractors[baseDomain] || GenericExtractor;\n}\n","import Cleaners from 'cleaners';\nimport { convertNodeTo } from 'utils/dom';\nimport GenericExtractor from './generic';\n\n// Remove elements by an array of selectors\nexport function cleanBySelectors($content, $, { clean }) {\n  if (!clean) return $content;\n\n  $(clean.join(','), $content).remove();\n\n  return $content;\n}\n\n// Transform matching elements\nexport function transformElements($content, $, { transforms }) {\n  if (!transforms) return $content;\n\n  Reflect.ownKeys(transforms).forEach((key) => {\n    const $matches = $(key, $content);\n    const value = transforms[key];\n\n    // If value is a string, convert directly\n    if (typeof value === 'string') {\n      $matches.each((index, node) => {\n        convertNodeTo($(node), $, transforms[key]);\n      });\n    } else if (typeof value === 'function') {\n      // If value is function, apply function to node\n      $matches.each((index, node) => {\n        const result = value($(node), $);\n        // If function returns a string, convert node to that value\n        if (typeof result === 'string') {\n          convertNodeTo($(node), $, result);\n        }\n      });\n    }\n  });\n\n  return $content;\n}\n\nfunction findMatchingSelector($, selectors) {\n  return selectors.find((selector) => {\n    if (Array.isArray(selector)) {\n      const [s, attr] = selector;\n      return $(s).length === 1 && $(s).attr(attr) && $(s).attr(attr).trim() !== '';\n    }\n\n    return $(selector).length === 1 && $(selector).text().trim() !== '';\n  });\n}\n\nexport function select(opts) {\n  const { $, type, extractionOpts, extractHtml = false } = opts;\n  // Skip if there's not extraction for this type\n  if (!extractionOpts) return null;\n\n  // If a string is hardcoded for a type (e.g., Wikipedia\n  // contributors), return the string\n  if (typeof extractionOpts === 'string') return extractionOpts;\n\n  const { selectors, defaultCleaner = true } = extractionOpts;\n\n  const matchingSelector = findMatchingSelector($, selectors);\n\n  if (!matchingSelector) return null;\n\n  // Declaring result; will contain either\n  // text or html, which will be cleaned\n  // by the appropriate cleaner type\n\n  // If the selector type requests html as its return type\n  // transform and clean the element with provided selectors\n  if (extractHtml) {\n    let $content = $(matchingSelector);\n\n    // Wrap in div so transformation can take place on root element\n    $content.wrap($('<div></div>'));\n    $content = $content.parent();\n\n    $content = transformElements($content, $, extractionOpts);\n    $content = cleanBySelectors($content, $, extractionOpts);\n\n    $content = Cleaners[type]($content, { ...opts, defaultCleaner });\n\n    return $.html($content);\n  }\n\n  let result;\n\n  // if selector is an array (e.g., ['img', 'src']),\n  // extract the attr\n  if (Array.isArray(matchingSelector)) {\n    const [selector, attr] = matchingSelector;\n    result = $(selector).attr(attr).trim();\n  } else {\n    result = $(matchingSelector).text().trim();\n  }\n\n  // Allow custom extractor to skip default cleaner\n  // for this type; defaults to true\n  if (defaultCleaner) {\n    return Cleaners[type](result, opts);\n  }\n\n  return result;\n}\n\nfunction extractResult(opts) {\n  const { type, extractor, fallback = true } = opts;\n\n  const result = select({ ...opts, extractionOpts: extractor[type] });\n\n  // If custom parser succeeds, return the result\n  if (result) {\n    return result;\n  }\n\n  // If nothing matches the selector, and fallback is enabled,\n  // run the Generic extraction\n  if (fallback) return GenericExtractor[type](opts);\n\n  return null;\n}\n\nconst RootExtractor = {\n  extract(extractor = GenericExtractor, opts) {\n    const { contentOnly, extractedTitle } = opts;\n    // This is the generic extractor. Run its extract method\n    if (extractor.domain === '*') return extractor.extract(opts);\n\n    opts = {\n      ...opts,\n      extractor,\n    };\n\n    if (contentOnly) {\n      const content = extractResult({\n        ...opts, type: 'content', extractHtml: true, title: extractedTitle,\n      });\n      return {\n        content,\n      };\n    }\n    const title = extractResult({ ...opts, type: 'title' });\n    const date_published = extractResult({ ...opts, type: 'date_published' });\n    const author = extractResult({ ...opts, type: 'author' });\n    const next_page_url = extractResult({ ...opts, type: 'next_page_url' });\n    const content = extractResult({\n      ...opts, type: 'content', extractHtml: true, title,\n    });\n    const lead_image_url = extractResult({ ...opts, type: 'lead_image_url', content });\n    const excerpt = extractResult({ ...opts, type: 'excerpt', content });\n    const dek = extractResult({ ...opts, type: 'dek', content, excerpt });\n    const word_count = extractResult({ ...opts, type: 'word_count', content });\n    const direction = extractResult({ ...opts, type: 'direction', title });\n    const { url, domain } =\n      extractResult({ ...opts, type: 'url_and_domain' }) || { url: null, domain: null };\n\n    return {\n      title,\n      content,\n      author,\n      date_published,\n      lead_image_url,\n      dek,\n      next_page_url,\n      url,\n      domain,\n      excerpt,\n      word_count,\n      direction,\n    };\n  },\n};\n\nexport default RootExtractor;\n","import { removeAnchor } from 'utils/text';\nimport RootExtractor from 'extractors/root-extractor';\nimport GenericExtractor from 'extractors/generic';\nimport Resource from 'resource';\n\nexport default async function collectAllPages(\n  {\n    next_page_url,\n    html,\n    $,\n    metaCache,\n    result,\n    Extractor,\n    title,\n    url,\n  }\n) {\n  // At this point, we've fetched just the first page\n  let pages = 1;\n  const previousUrls = [removeAnchor(url)];\n\n  // If we've gone over 26 pages, something has\n  // likely gone wrong.\n  while (next_page_url && pages < 26) {\n    pages += 1;\n    $ = await Resource.create(next_page_url);\n    html = $.html();\n\n    const extractorOpts = {\n      url: next_page_url,\n      html,\n      $,\n      metaCache,\n      contentOnly: true,\n      extractedTitle: title,\n      previousUrls,\n    };\n\n    const nextPageResult = RootExtractor.extract(Extractor, extractorOpts);\n\n    previousUrls.push(next_page_url);\n    result = {\n      ...result,\n      content: `${result.content}<hr><h4>Page ${pages}</h4>${nextPageResult.content}`,\n    };\n\n    next_page_url = nextPageResult.next_page_url;\n  }\n\n  const word_count = GenericExtractor.word_count({ content: `<div>${result.content}</div>` });\n  return {\n    ...result,\n    total_pages: pages,\n    pages_rendered: pages,\n    word_count,\n  };\n}\n","import URL from 'url';\nimport cheerio from 'cheerio';\n\nimport Resource from 'resource';\nimport {\n  validateUrl,\n  Errors,\n} from 'utils';\nimport getExtractor from 'extractors/get-extractor';\nimport RootExtractor from 'extractors/root-extractor';\nimport collectAllPages from 'extractors/collect-all-pages';\n\nconst Mercury = {\n  async parse(url, html, opts = {}) {\n    const {\n      fetchAllPages = true,\n      fallback = true,\n    } = opts;\n\n    // if no url was passed and this is the browser version,\n    // set url to window.location.href and load the html\n    // from the current page\n    if (!url && cheerio.browser) {\n      url = window.location.href; // eslint-disable-line no-undef\n      html = html || cheerio.html();\n    }\n\n    const parsedUrl = URL.parse(url);\n\n    if (!validateUrl(parsedUrl)) {\n      return Errors.badUrl;\n    }\n\n    const Extractor = getExtractor(url, parsedUrl);\n    // console.log(`Using extractor for ${Extractor.domain}`);\n\n    const $ = await Resource.create(url, html, parsedUrl);\n\n    // If we found an error creating the resource, return that error\n    if ($.failed) {\n      return $;\n    }\n\n    // if html still has not been set (i.e., url passed to Mercury.parse),\n    // set html from the response of Resource.create\n    if (!html) {\n      html = $.html();\n    }\n\n    // Cached value of every meta name in our document.\n    // Used when extracting title/author/date_published/dek\n    const metaCache = $('meta').map((_, node) => $(node).attr('name')).toArray();\n\n    let result = RootExtractor.extract(\n      Extractor,\n      {\n        url,\n        html,\n        $,\n        metaCache,\n        parsedUrl,\n        fallback,\n      });\n\n    const { title, next_page_url } = result;\n\n    // Fetch more pages if next_page_url found\n    if (fetchAllPages && next_page_url) {\n      result = await collectAllPages(\n        {\n          Extractor,\n          next_page_url,\n          html,\n          $,\n          metaCache,\n          result,\n          title,\n          url,\n        }\n      );\n    } else {\n      result = {\n        ...result,\n        total_pages: 1,\n        rendered_pages: 1,\n      };\n    }\n\n    return result;\n  },\n\n  browser: !!cheerio.browser,\n\n  // A convenience method for getting a resource\n  // to work with, e.g., for custom extractor generator\n  async fetchResource(url) {\n    return await Resource.create(url);\n  },\n\n};\n\nexport default Mercury;\n"],"names":["range","start","end","validateUrl","hostname","Errors","REQUEST_HEADERS","cheerio","browser","FETCH_TIMEOUT","BAD_CONTENT_TYPES","BAD_CONTENT_TYPES_RE","RegExp","join","MAX_CONTENT_LENGTH","get","options","resolve","reject","err","response","body","validateResponse","parseNon2xx","statusMessage","statusCode","Error","error","headers","contentType","contentLength","test","url","parsedUrl","URL","parse","encodeURI","href","badUrl","fetchResource","convertMetaProp","$","from","to","each","_","node","$node","value","attr","removeAttr","normalizeMetaTags","SPACER_RE","KEEP_CLASS","KEEP_SELECTORS","STRIP_OUTPUT_TAGS","REMOVE_ATTRS","REMOVE_ATTR_SELECTORS","map","selector","REMOVE_ATTR_LIST","WHITELIST_ATTRS","WHITELIST_ATTRS_RE","REMOVE_EMPTY_TAGS","REMOVE_EMPTY_SELECTORS","tag","CLEAN_CONDITIONALLY_TAGS","HEADER_TAGS","HEADER_TAG_LIST","UNLIKELY_CANDIDATES_BLACKLIST","UNLIKELY_CANDIDATES_WHITELIST","DIV_TO_P_BLOCK_TAGS","POSITIVE_SCORE_HINTS","POSITIVE_SCORE_RE","NEGATIVE_SCORE_HINTS","NEGATIVE_SCORE_RE","IS_WP_SELECTOR","PAGE_RE","BLOCK_LEVEL_TAGS","BLOCK_LEVEL_TAGS_RE","candidatesBlacklist","CANDIDATES_BLACKLIST","candidatesWhitelist","CANDIDATES_WHITELIST","stripUnlikelyCandidates","not","index","classes","id","classAndId","remove","brsToPs","collapsing","element","$element","nextElement","next","tagName","toLowerCase","paragraphize","br","sibling","nextSibling","p","appendTo","replaceWith","convertDivs","div","$div","convertable","children","length","convertSpans","span","$span","parents","convertToParagraphs","convertNodeTo","attrs","getAttrs","attribString","key","html","text","contents","cleanForHeight","$img","height","parseInt","width","removeSpacers","cleanImages","$article","find","img","markToKeep","article","tags","protocol","addClass","stripJunkTags","removeClass","cleanHOnes","$hOnes","removeAllButWhitelist","reduce","acc","cleanAttributes","parent","removeEmpty","$p","trim","NON_TOP_CANDIDATE_TAGS","NON_TOP_CANDIDATE_TAGS_RE","HNEWS_CONTENT_SELECTORS","PHOTO_HINTS","PHOTO_HINTS_RE","READABILITY_ASSET","DIGIT_RE","BR_TAGS_RE","BR_TAG_RE","UNLIKELY_RE","PARAGRAPH_SCORE_TAGS","CHILD_CONTENT_TAGS","BAD_TAGS","HTML_OR_BODY_RE","getWeight","score","getScore","parseFloat","scoreCommas","match","idkRe","scoreLength","textLength","chunks","lengthBonus","Math","min","max","scoreParagraph","slice","setScore","addScore","amount","getOrInitScore","e","addToParent","weightNodes","scoreNode","addScoreTo","scorePs","$parent","rawScore","scoreContent","forEach","parentSelector","childSelector","NORMALIZE_RE","normalizeSpaces","replace","extractFromUrl","regexList","matchRe","re","exec","PAGE_IN_HREF_RE","HAS_ALPHA_RE","IS_ALPHA_RE","IS_DIGIT_RE","pageNumFromUrl","matches","pageNum","removeAnchor","split","isGoodSegment","segment","firstSegmentHasLetters","goodSegment","articleBaseUrl","parsed","host","path","cleanedSegments","reverse","rawSegment","includes","possibleSegment","fileExt","push","SENTENCE_END_RE","hasSentenceEnd","excerptContent","content","words","mergeSiblings","$candidate","topScore","siblingScoreThreshold","wrappingDiv","$sibling","siblingScore","append","contentBonus","density","linkDensity","newScore","siblingContent","siblingContentLength","first","findTopCandidate","removeUnlessContent","weight","hasClass","pCount","inputCount","imgCount","nodeIsList","previousNode","prev","scriptCount","cleanTags","cleanHeaders","title","header","$header","prevAll","rewriteTopLevel","absolutize","rootUrl","$content","absoluteUrl","makeLinksAbsolute","totalTextLength","linkText","linkLength","extractFromMeta","metaNames","cachedNames","foundNames","filter","indexOf","name","type","nodes","values","toArray","metaValue","stripTags","isGoodNode","maxChildren","withinComment","extractFromSelectors","selectors","textOnly","cleanText","commentParent","nodeClass","class","undefined","nodeIsSufficient","isWordpress","attribs","attributes","setAttr","val","setAttribute","setAttrs","removeAttribute","IS_LINK","IS_IMAGE","TAGS_TO_REMOVE","convertLazyLoadedImages","isComment","cleanComments","root","clean","Resource","preparedResponse","validResponse","result","failed","generateDoc","load","normalizeWhitespace","merge","extractor","domains","domain","mergeSupportedDomains","supportedDomains","BloggerExtractor","NYMagExtractor","$children","WikipediaExtractor","prepend","TwitterExtractor","tweets","$tweetContainer","NYTimesExtractor","src","TheAtlanticExtractor","NewYorkerExtractor","WiredExtractor","MSNExtractor","YahooExtractor","BuzzfeedExtractor","WikiaExtractor","LittleThingsExtractor","PoliticoExtractor","DeadspinExtractor","youtubeId","BroadwayWorldExtractor","ApartmentTherapyExtractor","data","JSON","sources","MediumExtractor","ytRe","thumb","decodeURIComponent","clone","CustomExtractors","CLEAN_AUTHOR_RE","TEXT_LINK_RE","MS_DATE_STRING","SEC_DATE_STRING","CLEAN_DATE_STRING_RE","TIME_MERIDIAN_SPACE_RE","TIME_MERIDIAN_DOTS_RE","months","allMonths","timestamp1","timestamp2","SPLIT_DATE_STRING","TITLE_SPLITTERS_RE","DOMAIN_ENDINGS_RE","cleanAuthor","author","leadImageUrl","validUrl","isWebUri","cleanDek","dek","excerpt","dekText","cleanDateString","dateString","cleanDatePublished","date","moment","Date","isValid","toISOString","extractCleanNode","cleanConditionally","defaultCleaner","cleanTitle","resolveSplitTitle","h1","extractBreadcrumbTitle","splitTitle","termCounts","titleText","maxTerm","termCount","splitEnds","longestEnd","cleanDomainFromTitle","nakedDomain","startSlug","startSlugRatio","wuzzy","levenshtein","endSlug","endSlugRatio","newTitle","Cleaners","cleanImage","cleanContent","extractBestNode","opts","$topCandidate","GenericContentExtractor","defaultOpts","getContentNode","cleanAndReturnNode","k","STRONG_TITLE_META_TAGS","WEAK_TITLE_META_TAGS","STRONG_TITLE_SELECTORS","WEAK_TITLE_SELECTORS","GenericTitleExtractor","metaCache","AUTHOR_META_TAGS","AUTHOR_MAX_LENGTH","AUTHOR_SELECTORS","bylineRe","BYLINE_SELECTORS_RE","GenericAuthorExtractor","regex","DATE_PUBLISHED_META_TAGS","DATE_PUBLISHED_SELECTORS","abbrevMonthsStr","DATE_PUBLISHED_URL_RES","GenericDatePublishedExtractor","datePublished","GenericDekExtractor","LEAD_IMAGE_URL_META_TAGS","LEAD_IMAGE_URL_SELECTORS","POSITIVE_LEAD_IMAGE_URL_HINTS","POSITIVE_LEAD_IMAGE_URL_HINTS_RE","NEGATIVE_LEAD_IMAGE_URL_HINTS","NEGATIVE_LEAD_IMAGE_URL_HINTS_RE","GIF_RE","JPG_RE","getSig","scoreImageUrl","scoreAttr","scoreByParents","$figParent","$gParent","scoreBySibling","scoreByDimensions","area","round","scoreByPosition","$imgs","GenericLeadImageUrlExtractor","cleanUrl","imageUrl","imgs","imgScores","topUrl","scoreSimilarity","articleUrl","similarity","difflib","SequenceMatcher","ratio","diffPercent","diffModifier","scoreLinkText","linkTextAsNum","scorePageInLink","isWp","EXTRANEOUS_LINK_HINTS","EXTRANEOUS_LINK_HINTS_RE","NEXT_LINK_TEXT_RE","CAP_LINK_TEXT_RE","PREV_LINK_TEXT_RE","scoreExtraneousLinks","makeSig","$link","positiveMatch","negativeMatch","parentData","scorePrevLink","linkData","shouldScore","baseUrl","previousUrls","linkHost","fragment","scoreBaseUrl","baseRegex","scoreNextLinkText","scoreCapLinks","makeBaseRegex","scoreLinks","links","scoredPages","possiblePages","link","possiblePage","GenericNextPageUrlExtractor","scoredLinks","topPage","scoredLink","CANONICAL_META_SELECTORS","parseDomain","GenericUrlExtractor","$canonical","metaUrl","EXCERPT_META_SELECTORS","maxLength","ellipsize","ellipse","GenericExcerptExtractor","shortContent","GenericWordCountExtractor","GenericExtractor","extract","bind","stringDirection","getDirection","loaded","date_published","lead_image_url","next_page_url","word_count","direction","url_and_domain","getExtractor","baseDomain","Extractors","cleanBySelectors","transformElements","transforms","$matches","findMatchingSelector","Array","isArray","s","select","extractionOpts","extractHtml","matchingSelector","wrap","extractResult","fallback","RootExtractor","contentOnly","extractedTitle","Extractor","pages","create","extractorOpts","nextPageResult","collectAllPages","Mercury","fetchAllPages","window","location"],"mappings":";;;;;;;;;;;;;;;;;;;;;;;;;;eAAyBA;;AAAzB,AAAe,SAAUA,KAAV;MAAgBC,KAAhB,uEAAwB,CAAxB;MAA2BC,GAA3B,uEAAiC,CAAjC;;;;;gBACND,SAASC,GADH;;;;;;iBAELD,SAAS,CAFJ;;;;;;;;;;;;;;ACAf;AACA,AAAe,SAASE,WAAT,OAAmC;MAAZC,QAAY,QAAZA,QAAY;;;SAEzC,CAAC,CAACA,QAAT;;;ACHF,IAAMC,SAAS;UACL;WACC,IADD;cAEI;;CAHd,CAOA;;ACLA;AACA,AAAO,IAAMC,kBAAkBC,QAAQC,OAAR,GAAkB,EAAlB,GAAuB;gBACtC;CADT;;;AAKP,AAAO,IAAMC,gBAAgB,KAAtB;;;AAGP,IAAMC,oBAAoB,CACxB,YADwB,EAExB,WAFwB,EAGxB,YAHwB,EAIxB,WAJwB,CAA1B;;AAOA,AAAO,IAAMC,uBAAuB,IAAIC,MAAJ,QAAgBF,kBAAkBG,IAAlB,CAAuB,GAAvB,CAAhB,SAAiD,GAAjD,CAA7B;;;;AAIP,AAAO,IAAMC,qBAAqB,OAA3B;;;;qCAKP,AAAO,AACP,AAAO,AAKP,AAAO;;ACtBP,SAASC,GAAT,CAAaC,OAAb,EAAsB;SACb,aAAY,UAACC,OAAD,EAAUC,MAAV,EAAqB;YAC9BF,OAAR,EAAiB,UAACG,GAAD,EAAMC,QAAN,EAAgBC,IAAhB,EAAyB;UACpCF,GAAJ,EAAS;eACAA,GAAP;OADF,MAEO;gBACG,EAAEE,UAAF,EAAQD,kBAAR,EAAR;;KAJJ;GADK,CAAP;;;;;;;;AAgBF,AAAO,SAASE,gBAAT,CAA0BF,QAA1B,EAAyD;MAArBG,WAAqB,uEAAP,KAAO;;;;;;;;MAQ3DH,SAASI,aAAT,IAA0BJ,SAASI,aAAT,KAA2B,IAAtD,IACEJ,SAASK,UAAT,KAAwB,GAF5B,EAGE;QACI,CAACL,SAASK,UAAd,EAA0B;YAClB,IAAIC,KAAJ,sDAC+CN,SAASO,KADxD,CAAN;KADF,MAIO,IAAI,CAACJ,WAAL,EAAkB;YACjB,IAAIG,KAAJ,kDAC2CN,SAASK,UADpD,wEAAN;;;;0BASAL,SAASQ,OAzBiD;MAuB5CC,WAvB4C,qBAuB5D,cAvB4D;MAwB1CC,aAxB0C,qBAwB5D,gBAxB4D;;;;MA4B1DnB,qBAAqBoB,IAArB,CAA0BF,WAA1B,CAAJ,EAA4C;UACpC,IAAIH,KAAJ,yCACkCG,WADlC,0BAAN;;;;MAMEC,gBAAgBhB,kBAApB,EAAwC;UAChC,IAAIY,KAAJ,yEACkEZ,kBADlE,OAAN;;;SAKK,IAAP;;;;;AAKF,AAAO;;;;;;;;AAUP;yDAAe,iBAA6BkB,GAA7B,EAAkCC,SAAlC;;;;;;;wBACDA,aAAaC,IAAIC,KAAJ,CAAUC,UAAUJ,GAAV,CAAV,CAAzB;;mBADa,GAGG;mBACTC,UAAUI,IADD;oCAEA/B,eAAd,CAFc;uBAGLG,aAHK;;;wBAMJ,IANI;;mBAQT,IARS;;oBAUR,IAVQ;;kCAYM;aAfT;;mBAkBoBM,IAAIC,OAAJ,CAlBpB;;;;oBAAA,SAkBLI,QAlBK;gBAAA,SAkBKC,IAlBL;;;6BAqBMD,QAAjB;6CACO;wBAAA;;aAtBI;;;;;6CA2BJf,OAAOiC,MA3BH;;;;;;;;GAAf;;WAA8BC,aAA9B;;;;SAA8BA,aAA9B;;;ACpFA,SAASC,eAAT,CAAyBC,CAAzB,EAA4BC,IAA5B,EAAkCC,EAAlC,EAAsC;cAC1BD,IAAV,QAAmBE,IAAnB,CAAwB,UAACC,CAAD,EAAIC,IAAJ,EAAa;QAC7BC,QAAQN,EAAEK,IAAF,CAAd;;QAEME,QAAQD,MAAME,IAAN,CAAWP,IAAX,CAAd;UACMO,IAAN,CAAWN,EAAX,EAAeK,KAAf;UACME,UAAN,CAAiBR,IAAjB;GALF;;SAQOD,CAAP;;;;;;;;;;AAUF,AAAe,SAASU,iBAAT,CAA2BV,CAA3B,EAA8B;MACvCD,gBAAgBC,CAAhB,EAAmB,SAAnB,EAA8B,OAA9B,CAAJ;MACID,gBAAgBC,CAAhB,EAAmB,UAAnB,EAA+B,MAA/B,CAAJ;SACOA,CAAP;;;ACtBF;AACA,AAAO,IAAMW,YAAY,IAAIxC,MAAJ,CAAW,gCAAX,EAA6C,GAA7C,CAAlB;;;;AAIP,AAAO,IAAMyC,aAAa,qBAAnB;;AAEP,AAAO,IAAMC,iBAAiB,CAC5B,wCAD4B,EAE5B,uCAF4B,EAG5B,qCAH4B,EAI5B,oCAJ4B,CAAvB;;;AAQP,AAAO,IAAMC,oBAAoB,CAC/B,OAD+B,EAE/B,QAF+B,EAG/B,UAH+B,EAI/B,MAJ+B,EAK/B,OAL+B,EAM/B,IAN+B,EAO/B,OAP+B,EAQ/B,QAR+B,EAS/B,QAT+B,CAA1B;;;AAaP,AAAO,IAAMC,eAAe,CAAC,OAAD,EAAU,OAAV,CAArB;AACP,AAAO,IAAMC,wBAAwBD,aAAaE,GAAb,CAAiB;eAAgBC,QAAhB;CAAjB,CAA9B;AACP,AAAO,IAAMC,mBAAmBJ,aAAa3C,IAAb,CAAkB,GAAlB,CAAzB;AACP,AAAO,IAAMgD,kBAAkB,CAAC,KAAD,EAAQ,QAAR,EAAkB,MAAlB,EAA0B,OAA1B,EAAmC,IAAnC,EAAyC,KAAzC,CAAxB;AACP,AAAO,IAAMC,qBAAqB,IAAIlD,MAAJ,QAAgBiD,gBAAgBhD,IAAhB,CAAqB,GAArB,CAAhB,SAA+C,GAA/C,CAA3B;;;AAGP,AAAO,IAAMkD,oBAAoB,CAAC,GAAD,CAA1B;AACP,AAAO,IAAMC,yBAAyBD,kBAAkBL,GAAlB,CAAsB;SAAUO,GAAV;CAAtB,EAA6CpD,IAA7C,CAAkD,GAAlD,CAA/B;;;AAGP,AAAO,IAAMqD,2BAA2B,CAAC,IAAD,EAAO,IAAP,EAAa,OAAb,EAAsB,KAAtB,EAA6B,QAA7B,EAAuC,MAAvC,EAA+CrD,IAA/C,CAAoD,GAApD,CAAjC;;;AAGP,IAAMsD,cAAc,CAAC,IAAD,EAAO,IAAP,EAAa,IAAb,EAAmB,IAAnB,EAAyB,IAAzB,CAApB;AACA,AAAO,IAAMC,kBAAkBD,YAAYtD,IAAZ,CAAiB,GAAjB,CAAxB;;;;;;;;AAQP,AAAO,IAAMwD,gCAAgC,CAC3C,UAD2C,EAE3C,OAF2C,EAG3C,QAH2C,EAI3C,SAJ2C,EAK3C,SAL2C,EAM3C,KAN2C,EAO3C,gBAP2C,EAQ3C,OAR2C,EAS3C,SAT2C,EAU3C,cAV2C,EAW3C,QAX2C,EAY3C,iBAZ2C,EAa3C,OAb2C,EAc3C,MAd2C;;AAgB3C,QAhB2C,EAiB3C,QAjB2C,EAkB3C,QAlB2C,EAmB3C,OAnB2C;AAoB3C,MApB2C,EAqB3C,MArB2C,EAsB3C,KAtB2C,EAuB3C,UAvB2C,EAwB3C,OAxB2C,EAyB3C,YAzB2C,EA0B3C,UA1B2C;AA2B3C,2BA3B2C;AA4B3C,OA5B2C,EA6B3C,eA7B2C,EA8B3C,SA9B2C,EA+B3C,QA/B2C,EAgC3C,QAhC2C,EAiC3C,KAjC2C,EAkC3C,OAlC2C,EAmC3C,UAnC2C,EAoC3C,SApC2C,EAqC3C,UArC2C,EAsC3C,SAtC2C,EAuC3C,SAvC2C,EAwC3C,OAxC2C,CAAtC;;;;;;;;;;;;;AAsDP,AAAO,IAAMC,gCAAgC,CAC3C,KAD2C,EAE3C,SAF2C,EAG3C,MAH2C,EAI3C,WAJ2C,EAK3C,QAL2C,EAM3C,SAN2C,EAO3C,qBAP2C,EAQ3C,QAR2C;AAS3C,OAT2C,EAU3C,QAV2C,EAW3C,OAX2C,EAY3C,MAZ2C,EAa3C,MAb2C,EAc3C,OAd2C,EAe3C,QAf2C,CAAtC;;;;;AAqBP,AAAO,IAAMC,sBAAsB,CACjC,GADiC,EAEjC,YAFiC,EAGjC,IAHiC,EAIjC,KAJiC,EAKjC,KALiC,EAMjC,GANiC,EAOjC,KAPiC,EAQjC,OARiC,EASjC1D,IATiC,CAS5B,GAT4B,CAA5B;;;;AAaP,AAAO;;AAeP,AAAO;;;;;AAMP,AAAO;;AASP,AAAO;AAMP,AAAO;;;;;;AAMP,AAAO,IAAM2D,uBAAuB,CAClC,SADkC,EAElC,gBAFkC,EAGlC,iBAHkC,EAIlC,MAJkC,EAKlC,MALkC,EAMlC,SANkC,EAOlC,qBAPkC,EAQlC,OARkC,EASlC,QATkC,EAUlC,MAVkC,EAWlC,QAXkC,EAYlC,MAZkC,EAalC,YAbkC,EAclC,WAdkC,EAelC,MAfkC,EAgBlC,OAhBkC,EAiBlC,MAjBkC,EAkBlC,UAlBkC;AAmBlC,SAnBkC,CAA7B;;;AAuBP,AAAO,IAAMC,oBAAoB,IAAI7D,MAAJ,CAAW4D,qBAAqB3D,IAArB,CAA0B,GAA1B,CAAX,EAA2C,GAA3C,CAA1B;;;AAGP,AAAO;;;;;;AAMP,AAAO,IAAM6D,uBAAuB,CAClC,OADkC,EAElC,QAFkC,EAGlC,QAHkC,EAIlC,KAJkC,EAKlC,UALkC,EAMlC,QANkC,EAOlC,QAPkC,EAQlC,OARkC,EASlC,MATkC,EAUlC,OAVkC,EAWlC,SAXkC,EAYlC,YAZkC,EAalC,SAbkC,EAclC,MAdkC,EAelC,QAfkC,EAgBlC,OAhBkC,EAiBlC,MAjBkC,EAkBlC,MAlBkC,EAmBlC,SAnBkC,EAoBlC,UApBkC;AAqBlC,MArBkC,EAsBlC,QAtBkC,EAuBlC,UAvBkC,EAwBlC,MAxBkC,EAyBlC,MAzBkC,EA0BlC,MA1BkC,EA2BlC,UA3BkC;AA4BlC,mBA5BkC,EA6BlC,MA7BkC,EA8BlC,WA9BkC,EA+BlC,MA/BkC,EAgClC,UAhCkC,EAiClC,OAjCkC,EAkClC,MAlCkC,EAmClC,OAnCkC,EAoClC,UApCkC;AAqClC,OArCkC,EAsClC,KAtCkC;AAuClC,SAvCkC,EAwClC,SAxCkC,EAyClC,cAzCkC;AA0ClC,QA1CkC,EA2ClC,WA3CkC,EA4ClC,OA5CkC,EA6ClC,UA7CkC,EA8ClC,UA9CkC,EA+ClC,MA/CkC,EAgDlC,SAhDkC,EAiDlC,SAjDkC,EAkDlC,OAlDkC,EAmDlC,KAnDkC,EAoDlC,SApDkC,EAqDlC,MArDkC,EAsDlC,OAtDkC,EAuDlC,QAvDkC,CAA7B;;AA0DP,AAAO,IAAMC,oBAAoB,IAAI/D,MAAJ,CAAW8D,qBAAqB7D,IAArB,CAA0B,GAA1B,CAAX,EAA2C,GAA3C,CAA1B;;;AAGP,AAAO,IAAM+D,iBAAiB,wCAAvB;;;AAGP,AAAO;;;;AAIP,AAAO;AAgBP,AAAO;;;AAGP,AAAO,IAAMC,UAAU,IAAIjE,MAAJ,CAAW,iBAAX,EAA8B,GAA9B,CAAhB;;;;;;AAMP,AAAO;;;;AAIP,AAAO;;;;AAIP,AAAO;;;AAGP,AAAO;;;AAGP,AAAO;;;;AAIP,AAAO,IAAMkE,mBAAmB,CAC9B,SAD8B,EAE9B,OAF8B,EAG9B,YAH8B,EAI9B,MAJ8B,EAK9B,IAL8B,EAM9B,QAN8B,EAO9B,QAP8B,EAQ9B,SAR8B,EAS9B,KAT8B,EAU9B,UAV8B,EAW9B,IAX8B,EAY9B,KAZ8B,EAa9B,IAb8B,EAc9B,IAd8B,EAe9B,OAf8B,EAgB9B,UAhB8B,EAiB9B,YAjB8B,EAkB9B,QAlB8B,EAmB9B,QAnB8B,EAoB9B,MApB8B,EAqB9B,IArB8B,EAsB9B,IAtB8B,EAuB9B,IAvB8B,EAwB9B,IAxB8B,EAyB9B,IAzB8B,EA0B9B,IA1B8B,EA2B9B,QA3B8B,EA4B9B,QA5B8B,EA6B9B,IA7B8B,EA8B9B,IA9B8B,EA+B9B,KA/B8B,EAgC9B,QAhC8B,EAiC9B,IAjC8B,EAkC9B,QAlC8B,EAmC9B,GAnC8B,EAoC9B,KApC8B,EAqC9B,UArC8B,EAsC9B,SAtC8B,EAuC9B,OAvC8B,EAwC9B,OAxC8B,EAyC9B,UAzC8B,EA0C9B,OA1C8B,EA2C9B,IA3C8B,EA4C9B,OA5C8B,EA6C9B,IA7C8B,EA8C9B,IA9C8B,EA+C9B,OA/C8B,CAAzB;AAiDP,AAAO,IAAMC,sBAAsB,IAAInE,MAAJ,QAAgBkE,iBAAiBjE,IAAjB,CAAsB,GAAtB,CAAhB,SAAgD,GAAhD,CAA5B;;;;;;AAMP,IAAMmE,sBAAsBX,8BAA8BxD,IAA9B,CAAmC,GAAnC,CAA5B;AACA,AAAO,IAAMoE,uBAAuB,IAAIrE,MAAJ,CAAWoE,mBAAX,EAAgC,GAAhC,CAA7B;;AAEP,IAAME,sBAAsBZ,8BAA8BzD,IAA9B,CAAmC,GAAnC,CAA5B;AACA,AAAO,IAAMsE,uBAAuB,IAAIvE,MAAJ,CAAWsE,mBAAX,EAAgC,GAAhC,CAA7B,CAEP,AAAO,AAEP,AAAO,AACP,AAAO,AACP,AAAO,AAEP,AAAO;;AClYQ,SAASE,uBAAT,CAAiC3C,CAAjC,EAAoC;;;;;;;;;;IAU/C,GAAF,EAAO4C,GAAP,CAAW,GAAX,EAAgBzC,IAAhB,CAAqB,UAAC0C,KAAD,EAAQxC,IAAR,EAAiB;QAC9BC,QAAQN,EAAEK,IAAF,CAAd;QACMyC,UAAUxC,MAAME,IAAN,CAAW,OAAX,CAAhB;QACMuC,KAAKzC,MAAME,IAAN,CAAW,IAAX,CAAX;QACI,CAACuC,EAAD,IAAO,CAACD,OAAZ,EAAqB;;QAEfE,cAAgBF,WAAW,EAA3B,WAAiCC,MAAM,EAAvC,CAAN;QACIL,qBAAqBpD,IAArB,CAA0B0D,UAA1B,CAAJ,EAA2C;;KAA3C,MAEO,IAAIR,qBAAqBlD,IAArB,CAA0B0D,UAA1B,CAAJ,EAA2C;YAC1CC,MAAN;;GAVJ;;SAcOjD,CAAP;;;AC3BF;;;;;;;;;AASA,AAAe,SAASkD,UAAT,CAAiBlD,CAAjB,EAAoB;MAC7BmD,aAAa,KAAjB;IACE,IAAF,EAAQhD,IAAR,CAAa,UAAC0C,KAAD,EAAQO,OAAR,EAAoB;QACzBC,WAAWrD,EAAEoD,OAAF,CAAjB;QACME,cAAcD,SAASE,IAAT,GAAgBjF,GAAhB,CAAoB,CAApB,CAApB;;QAEIgF,eAAeA,YAAYE,OAAZ,CAAoBC,WAApB,OAAsC,IAAzD,EAA+D;mBAChD,IAAb;eACSR,MAAT;KAFF,MAGO,IAAIE,UAAJ,EAAgB;mBACR,KAAb;;mBAEaC,OAAb,EAAsBpD,CAAtB,EAAyB,IAAzB;;GAVJ;;SAcOA,CAAP;;;ACzBF;;;;;;;;;;;AAWA,AAAe,SAAS0D,YAAT,CAAsBrD,IAAtB,EAA4BL,CAA5B,EAA2C;MAAZ2D,EAAY,uEAAP,KAAO;;MAClDrD,QAAQN,EAAEK,IAAF,CAAd;;MAEIsD,EAAJ,EAAQ;QACFC,UAAUvD,KAAKwD,WAAnB;QACMC,IAAI9D,EAAE,SAAF,CAAV;;;;WAIO4D,WAAW,EAAEA,QAAQJ,OAAR,IAAmBlB,oBAAoBhD,IAApB,CAAyBsE,QAAQJ,OAAjC,CAArB,CAAlB,EAAmF;UAC3EK,cAAcD,QAAQC,WAA5B;QACED,OAAF,EAAWG,QAAX,CAAoBD,CAApB;gBACUD,WAAV;;;UAGIG,WAAN,CAAkBF,CAAlB;UACMb,MAAN;WACOjD,CAAP;;;SAGKA,CAAP;;;AC7BF,SAASiE,WAAT,CAAqBjE,CAArB,EAAwB;IACpB,KAAF,EAASG,IAAT,CAAc,UAAC0C,KAAD,EAAQqB,GAAR,EAAgB;QACtBC,OAAOnE,EAAEkE,GAAF,CAAb;QACME,cAAcD,KAAKE,QAAL,CAAcvC,mBAAd,EAAmCwC,MAAnC,KAA8C,CAAlE;;QAEIF,WAAJ,EAAiB;uBACDD,IAAd,EAAoBnE,CAApB,EAAuB,GAAvB;;GALJ;;SASOA,CAAP;;;AAGF,SAASuE,YAAT,CAAsBvE,CAAtB,EAAyB;IACrB,MAAF,EAAUG,IAAV,CAAe,UAAC0C,KAAD,EAAQ2B,IAAR,EAAiB;QACxBC,QAAQzE,EAAEwE,IAAF,CAAd;QACMJ,cAAcK,MAAMC,OAAN,CAAc,QAAd,EAAwBJ,MAAxB,KAAmC,CAAvD;QACIF,WAAJ,EAAiB;uBACDK,KAAd,EAAqBzE,CAArB,EAAwB,GAAxB;;GAJJ;;SAQOA,CAAP;;;;;;;;;;;;;;;AAeF,AAAe,SAAS2E,sBAAT,CAA6B3E,CAA7B,EAAgC;MACzCkD,WAAQlD,CAAR,CAAJ;MACIiE,YAAYjE,CAAZ,CAAJ;MACIuE,aAAavE,CAAb,CAAJ;;SAEOA,CAAP;;;AC5Ca,SAAS4E,gBAAT,CAAuBtE,KAAvB,EAA8BN,CAA9B,EAA4C;MAAXwB,GAAW,uEAAL,GAAK;;MACnDnB,OAAOC,MAAMhC,GAAN,CAAU,CAAV,CAAb;MACI,CAAC+B,IAAL,EAAW;WACFL,CAAP;;MAEI6E,QAAQC,SAASzE,IAAT,KAAkB,EAAhC;;;MAGM0E,eAAe,iBAAgBF,KAAhB,EACQ5D,GADR,CACY;WAAU+D,GAAV,SAAiBH,MAAMG,GAAN,CAAjB;GADZ,EAEQ5G,IAFR,CAEa,GAFb,CAArB;MAGI6G,aAAJ;;MAEIjF,EAAEjC,OAAN,EAAe;;;;WAINsC,KAAKmD,OAAL,CAAaC,WAAb,OAA+B,UAA/B,GAA4CnD,MAAM4E,IAAN,EAA5C,GAA2D5E,MAAM2E,IAAN,EAAlE;GAJF,MAKO;WACE3E,MAAM6E,QAAN,EAAP;;QAEInB,WAAN,OACMxC,GADN,SACauD,YADb,SAC6BE,IAD7B,UACsCzD,GADtC;SAGOxB,CAAP;;;ACxBF,SAASoF,cAAT,CAAwBC,IAAxB,EAA8BrF,CAA9B,EAAiC;MACzBsF,SAASC,SAASF,KAAK7E,IAAL,CAAU,QAAV,CAAT,EAA8B,EAA9B,CAAf;MACMgF,QAAQD,SAASF,KAAK7E,IAAL,CAAU,OAAV,CAAT,EAA6B,EAA7B,KAAoC,EAAlD;;;;;MAKI,CAAC8E,UAAU,EAAX,IAAiB,EAAjB,IAAuBE,QAAQ,EAAnC,EAAuC;SAChCvC,MAAL;GADF,MAEO,IAAIqC,MAAJ,EAAY;;;;SAIZ7E,UAAL,CAAgB,QAAhB;;;SAGKT,CAAP;;;;;AAKF,SAASyF,aAAT,CAAuBJ,IAAvB,EAA6BrF,CAA7B,EAAgC;MAC1BW,UAAUrB,IAAV,CAAe+F,KAAK7E,IAAL,CAAU,KAAV,CAAf,CAAJ,EAAsC;SAC/ByC,MAAL;;;SAGKjD,CAAP;;;AAGF,AAAe,SAAS0F,WAAT,CAAqBC,QAArB,EAA+B3F,CAA/B,EAAkC;WACtC4F,IAAT,CAAc,KAAd,EAAqBzF,IAArB,CAA0B,UAAC0C,KAAD,EAAQgD,GAAR,EAAgB;QAClCR,OAAOrF,EAAE6F,GAAF,CAAb;;mBAEeR,IAAf,EAAqBrF,CAArB;kBACcqF,IAAd,EAAoBrF,CAApB;GAJF;;SAOOA,CAAP;;;AChCa,SAAS8F,UAAT,CAAoBC,OAApB,EAA6B/F,CAA7B,EAAgCT,GAAhC,EAAgD;MAAXyG,IAAW,uEAAJ,EAAI;;MACzDA,KAAK1B,MAAL,KAAgB,CAApB,EAAuB;WACdzD,cAAP;;;MAGEtB,GAAJ,EAAS;qBACwBE,IAAIC,KAAJ,CAAUH,GAAV,CADxB;QACC0G,QADD,cACCA,QADD;QACWtI,QADX,cACWA,QADX;;wCAEIqI,IAAX,sBAAiCC,QAAjC,UAA8CtI,QAA9C;;;IAGAqI,KAAK5H,IAAL,CAAU,GAAV,CAAF,EAAkB2H,OAAlB,EAA2BG,QAA3B,CAAoCtF,UAApC;;SAEOZ,CAAP;;;ACda,SAASmG,aAAT,CAAuBJ,OAAvB,EAAgC/F,CAAhC,EAA8C;MAAXgG,IAAW,uEAAJ,EAAI;;MACvDA,KAAK1B,MAAL,KAAgB,CAApB,EAAuB;WACdxD,iBAAP;;;;;IAKAkF,KAAK5H,IAAL,CAAU,GAAV,CAAF,EAAkB2H,OAAlB,EAA2BnD,GAA3B,OAAmChC,UAAnC,EAAiDqC,MAAjD;;;UAGMrC,UAAN,EAAoBmF,OAApB,EAA6BK,WAA7B,CAAyCxF,UAAzC;;SAEOZ,CAAP;;;ACfF;;;AAGA,AAAe,SAASqG,aAAT,CAAoBN,OAApB,EAA6B/F,CAA7B,EAAgC;MACvCsG,SAAStG,EAAE,IAAF,EAAQ+F,OAAR,CAAf;;MAEIO,OAAOhC,MAAP,GAAgB,CAApB,EAAuB;WACdnE,IAAP,CAAY,UAAC0C,KAAD,EAAQxC,IAAR;aAAiBL,EAAEK,IAAF,EAAQ4C,MAAR,EAAjB;KAAZ;GADF,MAEO;WACE9C,IAAP,CAAY,UAAC0C,KAAD,EAAQxC,IAAR,EAAiB;uBACbL,EAAEK,IAAF,CAAd,EAAuBL,CAAvB,EAA0B,IAA1B;KADF;;;SAKKA,CAAP;;;ACTF,SAASuG,qBAAT,CAA+BZ,QAA/B,EAAyC;WAC9BC,IAAT,CAAc,GAAd,EAAmBzF,IAAnB,CAAwB,UAAC0C,KAAD,EAAQxC,IAAR,EAAiB;QACjCwE,QAAQC,SAASzE,IAAT,CAAd;;aAESA,IAAT,EAAe,iBAAgBwE,KAAhB,EAAuB2B,MAAvB,CAA8B,UAACC,GAAD,EAAMjG,IAAN,EAAe;UACtDa,mBAAmB/B,IAAnB,CAAwBkB,IAAxB,CAAJ,EAAmC;4BACrBiG,GAAZ,sBAAkBjG,IAAlB,EAAyBqE,MAAMrE,IAAN,CAAzB;;;aAGKiG,GAAP;KALa,EAMZ,EANY,CAAf;GAHF;;SAYOd,QAAP;;;;;;;;;;AAUF,AAAe,SAASe,kBAAT,CAAyBf,QAAzB,EAAmC;;;;SAIzCY,sBACLZ,SAASgB,MAAT,GAAkBrC,MAAlB,GACEqB,SAASgB,MAAT,EADF,GACsBhB,QAFjB,CAAP;;;AClCa,SAASiB,WAAT,CAAqBjB,QAArB,EAA+B3F,CAA/B,EAAkC;WACtC4F,IAAT,CAAc,GAAd,EAAmBzF,IAAnB,CAAwB,UAAC0C,KAAD,EAAQiB,CAAR,EAAc;QAC9B+C,KAAK7G,EAAE8D,CAAF,CAAX;QACI+C,GAAGjB,IAAH,CAAQ,aAAR,EAAuBtB,MAAvB,KAAkC,CAAlC,IAAuCuC,GAAG3B,IAAH,GAAU4B,IAAV,OAAqB,EAAhE,EAAoED,GAAG5D,MAAH;GAFtE;;SAKOjD,CAAP;;;ACNF;;;;;;AAMA,AAAO,IAAM4B,kCAAgC,CAC3C,UAD2C,EAE3C,OAF2C,EAG3C,QAH2C,EAI3C,SAJ2C,EAK3C,SAL2C,EAM3C,KAN2C,EAO3C,gBAP2C,EAQ3C,OAR2C,EAS3C,SAT2C,EAU3C,cAV2C,EAW3C,QAX2C,EAY3C,iBAZ2C,EAa3C,OAb2C,EAc3C,MAd2C,EAe3C,MAf2C,EAgB3C,QAhB2C,EAiB3C,QAjB2C,EAkB3C,QAlB2C,EAmB3C,OAnB2C;AAoB3C,MApB2C,EAqB3C,MArB2C,EAsB3C,KAtB2C,EAuB3C,OAvB2C,EAwB3C,YAxB2C,EAyB3C,UAzB2C;AA0B3C,2BA1B2C;AA2B3C,OA3B2C,EA4B3C,eA5B2C,EA6B3C,SA7B2C,EA8B3C,QA9B2C,EA+B3C,QA/B2C,EAgC3C,KAhC2C,EAiC3C,OAjC2C,EAkC3C,UAlC2C,EAmC3C,SAnC2C,EAoC3C,UApC2C,EAqC3C,SArC2C,EAsC3C,OAtC2C,CAAtC;;;;;;;;;;;;;AAoDP,AAAO,IAAMC,kCAAgC,CAC3C,KAD2C,EAE3C,SAF2C,EAG3C,MAH2C,EAI3C,WAJ2C,EAK3C,QAL2C,EAM3C,SAN2C,EAO3C,qBAP2C,EAQ3C,QAR2C;AAS3C,OAT2C,EAU3C,QAV2C,EAW3C,OAX2C,EAY3C,MAZ2C,EAa3C,MAb2C,EAc3C,OAd2C,EAe3C,QAf2C,CAAtC;;;;;AAqBP,AAAO,IAAMC,wBAAsB,CACjC,GADiC,EAEjC,YAFiC,EAGjC,IAHiC,EAIjC,KAJiC,EAKjC,KALiC,EAMjC,GANiC,EAOjC,KAPiC,EAQjC,OARiC,EASjC1D,IATiC,CAS5B,GAT4B,CAA5B;;;;AAaP,AAAO,IAAM2I,2BAAyB,CACpC,IADoC,EAEpC,GAFoC,EAGpC,GAHoC,EAIpC,OAJoC,EAKpC,IALoC,EAMpC,MANoC,EAOpC,MAPoC,EAQpC,UARoC,EASpC,OAToC,EAUpC,KAVoC,EAWpC,MAXoC,EAYpC,MAZoC,CAA/B;;AAeP,AAAO,IAAMC,8BACX,IAAI7I,MAAJ,QAAgB4I,yBAAuB3I,IAAvB,CAA4B,GAA5B,CAAhB,SAAsD,GAAtD,CADK;;;;;AAMP,AAAO,IAAM6I,4BAA0B,CACrC,CAAC,SAAD,EAAY,gBAAZ,CADqC,EAErC,CAAC,OAAD,EAAU,gBAAV,CAFqC,EAGrC,CAAC,QAAD,EAAW,gBAAX,CAHqC,EAIrC,CAAC,OAAD,EAAU,WAAV,CAJqC,EAKrC,CAAC,OAAD,EAAU,YAAV,CALqC,EAMrC,CAAC,OAAD,EAAU,YAAV,CANqC,CAAhC;;AASP,AAAO,IAAMC,gBAAc,CACzB,QADyB,EAEzB,OAFyB,EAGzB,OAHyB,EAIzB,SAJyB,CAApB;AAMP,AAAO,IAAMC,mBAAiB,IAAIhJ,MAAJ,CAAW+I,cAAY9I,IAAZ,CAAiB,GAAjB,CAAX,EAAkC,GAAlC,CAAvB;;;;;;AAMP,AAAO,IAAM2D,yBAAuB,CAClC,SADkC,EAElC,gBAFkC,EAGlC,iBAHkC,EAIlC,MAJkC,EAKlC,MALkC,EAMlC,SANkC,EAOlC,qBAPkC,EAQlC,OARkC,EASlC,QATkC,EAUlC,MAVkC,EAWlC,QAXkC,EAYlC,MAZkC,EAalC,YAbkC,EAclC,WAdkC,EAelC,MAfkC,EAgBlC,OAhBkC,EAiBlC,MAjBkC,EAkBlC,UAlBkC;AAmBlC,SAnBkC,CAA7B;;;AAuBP,AAAO,IAAMC,sBAAoB,IAAI7D,MAAJ,CAAW4D,uBAAqB3D,IAArB,CAA0B,GAA1B,CAAX,EAA2C,GAA3C,CAA1B;;;AAGP,AAAO,IAAMgJ,sBAAoB,IAAIjJ,MAAJ,CAAW,qBAAX,EAAkC,GAAlC,CAA1B;;;;;;AAMP,AAAO,IAAM8D,yBAAuB,CAClC,OADkC,EAElC,QAFkC,EAGlC,QAHkC,EAIlC,KAJkC,EAKlC,UALkC,EAMlC,QANkC,EAOlC,QAPkC,EAQlC,OARkC,EASlC,MATkC,EAUlC,OAVkC,EAWlC,SAXkC,EAYlC,YAZkC,EAalC,SAbkC,EAclC,MAdkC,EAelC,QAfkC,EAgBlC,OAhBkC,EAiBlC,MAjBkC,EAkBlC,MAlBkC,EAmBlC,SAnBkC,EAoBlC,UApBkC;AAqBlC,MArBkC,EAsBlC,QAtBkC,EAuBlC,UAvBkC,EAwBlC,MAxBkC,EAyBlC,MAzBkC,EA0BlC,MA1BkC,EA2BlC,UA3BkC;AA4BlC,mBA5BkC,EA6BlC,MA7BkC,EA8BlC,WA9BkC,EA+BlC,MA/BkC,EAgClC,UAhCkC,EAiClC,OAjCkC,EAkClC,MAlCkC,EAmClC,OAnCkC,EAoClC,UApCkC;AAqClC,OArCkC,EAsClC,KAtCkC;AAuClC,SAvCkC,EAwClC,SAxCkC,EAyClC,cAzCkC;AA0ClC,QA1CkC,EA2ClC,WA3CkC,EA4ClC,OA5CkC,EA6ClC,UA7CkC,EA8ClC,UA9CkC,EA+ClC,MA/CkC,EAgDlC,SAhDkC,EAiDlC,SAjDkC,EAkDlC,OAlDkC,EAmDlC,KAnDkC,EAoDlC,SApDkC,EAqDlC,MArDkC,EAsDlC,OAtDkC,EAuDlC,QAvDkC,CAA7B;;AA0DP,AAAO,IAAMC,sBAAoB,IAAI/D,MAAJ,CAAW8D,uBAAqB7D,IAArB,CAA0B,GAA1B,CAAX,EAA2C,GAA3C,CAA1B;;;AAGP,AAAO,AAAMiJ;;;AAGb,AAAO,AAAMC;;;AAGb,AAAO,AAAMC;;;;AAIb,AAAO,AAAMlF;AAiDb,AAAO,AAAMC,AAAsCD;;;;;;AAMnD,IAAME,wBAAsBX,gCAA8BxD,IAA9B,CAAmC,GAAnC,CAA5B;AACA,AAAO,AAAMoE,AAAkCD,AAAX;;AAEpC,IAAME,wBAAsBZ,gCAA8BzD,IAA9B,CAAmC,GAAnC,CAA5B;AACA,AAAO,AAAMsE,AAAkCD,AAAX;;AAEpC,AAAO,AAAM+E,AAA8B/E,AAAhB,AAAyCF,AAAzC;;AAE3B,AAAO,IAAMkF,yBAAuB,IAAItJ,MAAJ,CAAW,mBAAX,EAAgC,GAAhC,CAA7B;AACP,AAAO,IAAMuJ,uBAAqB,IAAIvJ,MAAJ,CAAW,4BAAX,EAAyC,GAAzC,CAA3B;AACP,AAAO,IAAMwJ,aAAW,IAAIxJ,MAAJ,CAAW,kBAAX,EAA+B,GAA/B,CAAjB,CAEP,AAAO,AAAMyJ;;ACzSb;AACA,AAAe,SAASC,SAAT,CAAmBxH,IAAnB,EAAyB;MAChCyC,UAAUzC,KAAKG,IAAL,CAAU,OAAV,CAAhB;MACMuC,KAAK1C,KAAKG,IAAL,CAAU,IAAV,CAAX;MACIsH,QAAQ,CAAZ;;MAEI/E,EAAJ,EAAQ;;QAEFf,oBAAkB1C,IAAlB,CAAuByD,EAAvB,CAAJ,EAAgC;eACrB,EAAT;;QAEEb,oBAAkB5C,IAAlB,CAAuByD,EAAvB,CAAJ,EAAgC;eACrB,EAAT;;;;MAIAD,OAAJ,EAAa;QACPgF,UAAU,CAAd,EAAiB;;;UAGX9F,oBAAkB1C,IAAlB,CAAuBwD,OAAvB,CAAJ,EAAqC;iBAC1B,EAAT;;UAEEZ,oBAAkB5C,IAAlB,CAAuBwD,OAAvB,CAAJ,EAAqC;iBAC1B,EAAT;;;;;;;QAOAqE,iBAAe7H,IAAf,CAAoBwD,OAApB,CAAJ,EAAkC;eACvB,EAAT;;;;;;;QAOEsE,oBAAkB9H,IAAlB,CAAuBwD,OAAvB,CAAJ,EAAqC;eAC1B,EAAT;;;;SAIGgF,KAAP;;;ACnDF;;;AAGA,AAAe,SAASC,QAAT,CAAkBzH,KAAlB,EAAyB;SAC/B0H,WAAW1H,MAAME,IAAN,CAAW,OAAX,CAAX,KAAmC,IAA1C;;;ACJF;AACA,AAAe,SAASyH,WAAT,CAAqB/C,IAArB,EAA2B;SACjC,CAACA,KAAKgD,KAAL,CAAW,IAAX,KAAoB,EAArB,EAAyB5D,MAAhC;;;ACFF,IAAM6D,QAAQ,IAAIhK,MAAJ,CAAW,WAAX,EAAwB,GAAxB,CAAd;;AAEA,AAAe,SAASiK,WAAT,CAAqBC,UAArB,EAAgD;MAAf7E,OAAe,uEAAL,GAAK;;MACvD8E,SAASD,aAAa,EAA5B;;MAEIC,SAAS,CAAb,EAAgB;QACVC,oBAAJ;;;;;;;QAOIJ,MAAM7I,IAAN,CAAWkE,OAAX,CAAJ,EAAyB;oBACT8E,SAAS,CAAvB;KADF,MAEO;oBACSA,SAAS,IAAvB;;;WAGKE,KAAKC,GAAL,CAASD,KAAKE,GAAL,CAASH,WAAT,EAAsB,CAAtB,CAAT,EAAmC,CAAnC,CAAP;;;SAGK,CAAP;;;ACjBF;;AAEA,AAAe,SAASI,iBAAT,CAAwBtI,IAAxB,EAA8B;MACvCyH,QAAQ,CAAZ;MACM5C,OAAO7E,KAAK6E,IAAL,GAAY4B,IAAZ,EAAb;MACMuB,aAAanD,KAAKZ,MAAxB;;;MAGI+D,aAAa,EAAjB,EAAqB;WACZ,CAAP;;;;WAIOJ,YAAY/C,IAAZ,CAAT;;;;WAISkD,YAAYC,UAAZ,CAAT;;;;;;MAMInD,KAAK0D,KAAL,CAAW,CAAC,CAAZ,MAAmB,GAAvB,EAA4B;aACjB,CAAT;;;SAGKd,KAAP;;;AChCa,SAASe,QAAT,CAAkBvI,KAAlB,EAAyBN,CAAzB,EAA4B8H,KAA5B,EAAmC;QAC1CtH,IAAN,CAAW,OAAX,EAAoBsH,KAApB;SACOxH,KAAP;;;ACGa,SAASwI,WAAT,CAAkBxI,KAAlB,EAAyBN,CAAzB,EAA4B+I,MAA5B,EAAoC;MAC7C;QACIjB,QAAQkB,kBAAe1I,KAAf,EAAsBN,CAAtB,IAA2B+I,MAAzC;aACSzI,KAAT,EAAgBN,CAAhB,EAAmB8H,KAAnB;GAFF,CAGE,OAAOmB,CAAP,EAAU;;;;SAIL3I,KAAP;;;ACXF;AACA,AAAe,SAAS4I,cAAT,CAAqB7I,IAArB,EAA2BL,CAA3B,EAA8B8H,KAA9B,EAAqC;MAC5CnB,SAAStG,KAAKsG,MAAL,EAAf;MACIA,MAAJ,EAAY;gBACDA,MAAT,EAAiB3G,CAAjB,EAAoB8H,QAAQ,IAA5B;;;SAGKzH,IAAP;;;ACFF;;;AAGA,AAAe,SAAS2I,iBAAT,CAAwB1I,KAAxB,EAA+BN,CAA/B,EAAsD;MAApBmJ,WAAoB,uEAAN,IAAM;;MAC/DrB,QAAQC,SAASzH,KAAT,CAAZ;;MAEIwH,KAAJ,EAAW;WACFA,KAAP;;;UAGMsB,aAAU9I,KAAV,CAAR;;MAEI6I,WAAJ,EAAiB;aACNtB,UAAUvH,KAAV,CAAT;;;iBAGUA,KAAZ,EAAmBN,CAAnB,EAAsB8H,KAAtB;;SAEOA,KAAP;;;AClBF;;AAEA,AAAe,SAASsB,YAAT,CAAmB9I,KAAnB,EAA0B;mBACnBA,MAAMhC,GAAN,CAAU,CAAV,CADmB;MAC/BkF,OAD+B,cAC/BA,OAD+B;;;;;;;MAMnCiE,uBAAqBnI,IAArB,CAA0BkE,OAA1B,CAAJ,EAAwC;WAC/BmF,kBAAerI,KAAf,CAAP;GADF,MAEO,IAAIkD,QAAQC,WAAR,OAA0B,KAA9B,EAAqC;WACnC,CAAP;GADK,MAEA,IAAIiE,qBAAmBpI,IAAnB,CAAwBkE,OAAxB,CAAJ,EAAsC;WACpC,CAAP;GADK,MAEA,IAAImE,WAASrI,IAAT,CAAckE,OAAd,CAAJ,EAA4B;WAC1B,CAAC,CAAR;GADK,MAEA,IAAIA,QAAQC,WAAR,OAA0B,IAA9B,EAAoC;WAClC,CAAC,CAAR;;;SAGK,CAAP;;;ACjBF,SAASc,cAAT,CAAsBjE,KAAtB,EAA6BN,CAA7B,EAAgC;MAC1BM,MAAMhC,GAAN,CAAU,CAAV,CAAJ,EAAkB;qBACIgC,MAAMhC,GAAN,CAAU,CAAV,CADJ;QACRkF,OADQ,cACRA,OADQ;;QAGZA,YAAY,MAAhB,EAAwB;;uBAERlD,KAAd,EAAqBN,CAArB,EAAwB,KAAxB;;;;;AAKN,SAASqJ,UAAT,CAAoB/I,KAApB,EAA2BN,CAA3B,EAA8B8H,KAA9B,EAAqC;MAC/BxH,KAAJ,EAAW;mBACIA,KAAb,EAAoBN,CAApB;gBACSM,KAAT,EAAgBN,CAAhB,EAAmB8H,KAAnB;;;;AAIJ,SAASwB,OAAT,CAAiBtJ,CAAjB,EAAoBmJ,WAApB,EAAiC;IAC7B,QAAF,EAAYvG,GAAZ,CAAgB,SAAhB,EAA2BzC,IAA3B,CAAgC,UAAC0C,KAAD,EAAQxC,IAAR,EAAiB;;;QAG3CC,QAAQN,EAAEK,IAAF,CAAZ;YACQwI,SAASvI,KAAT,EAAgBN,CAAhB,EAAmBgJ,kBAAe1I,KAAf,EAAsBN,CAAtB,EAAyBmJ,WAAzB,CAAnB,CAAR;;QAEMI,UAAUjJ,MAAMqG,MAAN,EAAhB;QACM6C,WAAWJ,aAAU9I,KAAV,CAAjB;;eAEWiJ,OAAX,EAAoBvJ,CAApB,EAAuBwJ,QAAvB,EAAiCL,WAAjC;QACII,OAAJ,EAAa;;;iBAGAA,QAAQ5C,MAAR,EAAX,EAA6B3G,CAA7B,EAAgCwJ,WAAW,CAA3C,EAA8CL,WAA9C;;GAbJ;;SAiBOnJ,CAAP;;;;;AAKF,AAAe,SAASyJ,eAAT,CAAsBzJ,CAAtB,EAA6C;MAApBmJ,WAAoB,uEAAN,IAAM;;;;4BAGlCO,OAAxB,CAAgC,gBAAqC;;QAAnCC,cAAmC;QAAnBC,aAAmB;;MAC9DD,cAAL,SAAuBC,aAAvB,EAAwCzJ,IAAxC,CAA6C,UAAC0C,KAAD,EAAQxC,IAAR,EAAiB;kBACnDL,EAAEK,IAAF,EAAQsG,MAAR,CAAegD,cAAf,CAAT,EAAyC3J,CAAzC,EAA4C,EAA5C;KADF;GADF;;;;;;;UAWQA,CAAR,EAAWmJ,WAAX;UACQnJ,CAAR,EAAWmJ,WAAX;;SAEOnJ,CAAP;;;ACpEF,IAAM6J,eAAe,SAArB;;AAEA,AAAe,SAASC,eAAT,CAAyB5E,IAAzB,EAA+B;SACrCA,KAAK6E,OAAL,CAAaF,YAAb,EAA2B,GAA3B,EAAgC/C,IAAhC,EAAP;;;ACHF;;;;;AAKA,AAAe,SAASkD,cAAT,CAAwBzK,GAAxB,EAA6B0K,SAA7B,EAAwC;MAC/CC,UAAUD,UAAUrE,IAAV,CAAe;WAAMuE,GAAG7K,IAAH,CAAQC,GAAR,CAAN;GAAf,CAAhB;MACI2K,OAAJ,EAAa;WACJA,QAAQE,IAAR,CAAa7K,GAAb,EAAkB,CAAlB,CAAP;;;SAGK,IAAP;;;ACXF;;;;;;;;;;;;;;;;AAgBA,AAAO,IAAM8K,kBAAkB,IAAIlM,MAAJ,CAAW,0EAAX,EAAuF,GAAvF,CAAxB;;AAEP,AAAO,IAAMmM,eAAe,QAArB;;AAEP,AAAO,IAAMC,cAAc,WAApB;AACP,AAAO,IAAMC,cAAc,WAApB;;ACnBQ,SAASC,cAAT,CAAwBlL,GAAxB,EAA6B;MACpCmL,UAAUnL,IAAI2I,KAAJ,CAAUmC,eAAV,CAAhB;MACI,CAACK,OAAL,EAAc,OAAO,IAAP;;MAERC,UAAUpF,SAASmF,QAAQ,CAAR,CAAT,EAAqB,EAArB,CAAhB;;;;SAIOC,UAAU,GAAV,GAAgBA,OAAhB,GAA0B,IAAjC;;;ACVa,SAASC,YAAT,CAAsBrL,GAAtB,EAA2B;SACjCA,IAAIsL,KAAJ,CAAU,GAAV,EAAe,CAAf,EAAkBd,OAAlB,CAA0B,KAA1B,EAAiC,EAAjC,CAAP;;;ACQF,SAASe,aAAT,CAAuBC,OAAvB,EAAgClI,KAAhC,EAAuCmI,sBAAvC,EAA+D;MACzDC,cAAc,IAAlB;;;;MAIIpI,QAAQ,CAAR,IAAa2H,YAAYlL,IAAZ,CAAiByL,OAAjB,CAAb,IAA0CA,QAAQzG,MAAR,GAAiB,CAA/D,EAAkE;kBAClD,IAAd;;;;;MAKEzB,UAAU,CAAV,IAAekI,QAAQtH,WAAR,OAA0B,OAA7C,EAAsD;kBACtC,KAAd;;;;;MAKEZ,QAAQ,CAAR,IAAakI,QAAQzG,MAAR,GAAiB,CAA9B,IAAmC,CAAC0G,sBAAxC,EAAgE;kBAChD,KAAd;;;SAGKC,WAAP;;;;;;AAMF,AAAe,SAASC,cAAT,CAAwB3L,GAAxB,EAA6B4L,MAA7B,EAAqC;MAC5C3L,YAAY2L,UAAU1L,IAAIC,KAAJ,CAAUH,GAAV,CAA5B;MACQ0G,QAF0C,GAEjBzG,SAFiB,CAE1CyG,QAF0C;MAEhCmF,IAFgC,GAEjB5L,SAFiB,CAEhC4L,IAFgC;MAE1BC,IAF0B,GAEjB7L,SAFiB,CAE1B6L,IAF0B;;;MAI9CL,yBAAyB,KAA7B;MACMM,kBAAkBD,KAAKR,KAAL,CAAW,GAAX,EACvBU,OADuB,GAEvB/E,MAFuB,CAEhB,UAACC,GAAD,EAAM+E,UAAN,EAAkB3I,KAAlB,EAA4B;QAC9BkI,UAAUS,UAAd;;;QAGIT,QAAQU,QAAR,CAAiB,GAAjB,CAAJ,EAA2B;2BACUV,QAAQF,KAAR,CAAc,GAAd,CADV;;UAClBa,eADkB;UACDC,OADC;;UAErBpB,YAAYjL,IAAZ,CAAiBqM,OAAjB,CAAJ,EAA+B;kBACnBD,eAAV;;;;;;QAMArB,gBAAgB/K,IAAhB,CAAqByL,OAArB,KAAiClI,QAAQ,CAA7C,EAAgD;gBACpCkI,QAAQhB,OAAR,CAAgBM,eAAhB,EAAiC,EAAjC,CAAV;;;;;;;QAOExH,UAAU,CAAd,EAAiB;+BACUyH,aAAahL,IAAb,CAAkByL,OAAlB,CAAzB;;;;QAIED,cAAcC,OAAd,EAAuBlI,KAAvB,EAA8BmI,sBAA9B,CAAJ,EAA2D;UACrDY,IAAJ,CAASb,OAAT;;;WAGKtE,GAAP;GAhCsB,EAiCrB,EAjCqB,CAAxB;;SAmCUR,QAAV,UAAuBmF,IAAvB,GAA8BE,gBAAgBC,OAAhB,GAA0BnN,IAA1B,CAA+B,GAA/B,CAA9B;;;AC5EF;;AAEA,IAAMyN,kBAAkB,IAAI1N,MAAJ,CAAW,QAAX,CAAxB;AACA,AAAe,SAAS2N,cAAT,CAAwB5G,IAAxB,EAA8B;SACpC2G,gBAAgBvM,IAAhB,CAAqB4F,IAArB,CAAP;;;ACJa,SAAS6G,cAAT,CAAwBC,OAAxB,EAA6C;kBAAZC,KAAY,uEAAJ,EAAI;;qBACnDD,QAAQlF,IAAR,GACQ+D,KADR,CACc,KADd,EAEQjC,KAFR,CAEc,CAFd,EAEiBqD,KAFjB,EAGQ7N,IAHR,CAGa,GAHb,CAAP;;;ACQF;;;;;AAKA,AAAe,SAAS8N,aAAT,CAAuBC,UAAvB,EAAmCC,QAAnC,EAA6CpM,CAA7C,EAAgD;MACzD,CAACmM,WAAWxF,MAAX,GAAoBrC,MAAzB,EAAiC;WACxB6H,UAAP;;;MAGIE,wBAAwB7D,KAAKE,GAAL,CAAS,EAAT,EAAa0D,WAAW,IAAxB,CAA9B;MACME,cAActM,EAAE,aAAF,CAApB;;aAEW2G,MAAX,GAAoBtC,QAApB,GAA+BlE,IAA/B,CAAoC,UAAC0C,KAAD,EAAQe,OAAR,EAAoB;QAChD2I,WAAWvM,EAAE4D,OAAF,CAAjB;;QAEIoD,4BAA0B1H,IAA1B,CAA+BsE,QAAQJ,OAAvC,CAAJ,EAAqD;aAC5C,IAAP;;;QAGIgJ,eAAezE,SAASwE,QAAT,CAArB;QACIC,YAAJ,EAAkB;UACZD,SAASjO,GAAT,CAAa,CAAb,MAAoB6N,WAAW7N,GAAX,CAAe,CAAf,CAAxB,EAA2C;oBAC7BmO,MAAZ,CAAmBF,QAAnB;OADF,MAEO;YACDG,eAAe,CAAnB;YACMC,UAAUC,YAAYL,QAAZ,CAAhB;;;;YAIII,UAAU,IAAd,EAAoB;0BACF,EAAhB;;;;;YAKEA,WAAW,GAAf,EAAoB;0BACF,EAAhB;;;;;YAKEJ,SAAS/L,IAAT,CAAc,OAAd,MAA2B2L,WAAW3L,IAAX,CAAgB,OAAhB,CAA/B,EAAyD;0BACvC4L,WAAW,GAA3B;;;YAGIS,WAAWL,eAAeE,YAAhC;;YAEIG,YAAYR,qBAAhB,EAAuC;iBAC9BC,YAAYG,MAAZ,CAAmBF,QAAnB,CAAP;SADF,MAEO,IAAI3I,QAAQJ,OAAR,KAAoB,GAAxB,EAA6B;cAC5BsJ,iBAAiBP,SAASrH,IAAT,EAAvB;cACM6H,uBAAuB1E,WAAWyE,cAAX,CAA7B;;cAEIC,uBAAuB,EAAvB,IAA6BJ,UAAU,IAA3C,EAAiD;mBACxCL,YAAYG,MAAZ,CAAmBF,QAAnB,CAAP;WADF,MAEO,IAAIQ,wBAAwB,EAAxB,IAA8BJ,YAAY,CAA1C,IACDb,eAAegB,cAAf,CADH,EACmC;mBACjCR,YAAYG,MAAZ,CAAmBF,QAAnB,CAAP;;;;;;WAMD,IAAP;GAnDF;;MAsDID,YAAYjI,QAAZ,GAAuBC,MAAvB,KAAkC,CAAlC,IACFgI,YAAYjI,QAAZ,GAAuB2I,KAAvB,GAA+B1O,GAA/B,CAAmC,CAAnC,MAA0C6N,WAAW7N,GAAX,CAAe,CAAf,CAD5C,EAC+D;WACtD6N,UAAP;;;SAGKG,WAAP;;;AC7EF;;AAEA,AAAe,SAASW,mBAAT,CAA0BjN,CAA1B,EAA6B;MACtCmM,mBAAJ;MACIC,WAAW,CAAf;;IAEE,SAAF,EAAajM,IAAb,CAAkB,UAAC0C,KAAD,EAAQxC,IAAR,EAAiB;;QAE7B2G,4BAA0B1H,IAA1B,CAA+Be,KAAKmD,OAApC,CAAJ,EAAkD;;;;QAI5ClD,QAAQN,EAAEK,IAAF,CAAd;QACMyH,QAAQC,SAASzH,KAAT,CAAd;;QAEIwH,QAAQsE,QAAZ,EAAsB;iBACTtE,KAAX;mBACaxH,KAAb;;GAXJ;;;;MAiBI,CAAC6L,UAAL,EAAiB;WACRnM,EAAE,MAAF,KAAaA,EAAE,GAAF,EAAOgN,KAAP,EAApB;;;eAGWd,cAAcC,UAAd,EAA0BC,QAA1B,EAAoCpM,CAApC,CAAb;;SAEOmM,UAAP;;;ACjCF,UACA,AACA,AACA,AACA,AACA,AACA,AACA,AACA,AACA,AACA,AACA,AACA;;ACDA,SAASe,mBAAT,CAA6B5M,KAA7B,EAAoCN,CAApC,EAAuCmN,MAAvC,EAA+C;;;;;MAKzC7M,MAAM8M,QAAN,CAAe,qBAAf,CAAJ,EAA2C;;;;MAIrCpB,UAAUlC,gBAAgBxJ,MAAM4E,IAAN,EAAhB,CAAhB;;MAEI+C,YAAY+D,OAAZ,IAAuB,EAA3B,EAA+B;QACvBqB,SAASrN,EAAE,GAAF,EAAOM,KAAP,EAAcgE,MAA7B;QACMgJ,aAAatN,EAAE,OAAF,EAAWM,KAAX,EAAkBgE,MAArC;;;QAGIgJ,aAAcD,SAAS,CAA3B,EAA+B;YACvBpK,MAAN;;;;QAII5D,gBAAgB2M,QAAQ1H,MAA9B;QACMiJ,WAAWvN,EAAE,KAAF,EAASM,KAAT,EAAgBgE,MAAjC;;;;QAIIjF,gBAAgB,EAAhB,IAAsBkO,aAAa,CAAvC,EAA0C;YAClCtK,MAAN;;;;QAII0J,UAAUC,YAAYtM,KAAZ,CAAhB;;;;;QAKI6M,SAAS,EAAT,IAAeR,UAAU,GAAzB,IAAgCtN,gBAAgB,EAApD,EAAwD;YAChD4D,MAAN;;;;;;QAMEkK,UAAU,EAAV,IAAgBR,UAAU,GAA9B,EAAmC;;;;UAI3BnJ,UAAUlD,MAAMhC,GAAN,CAAU,CAAV,EAAakF,OAAb,CAAqBC,WAArB,EAAhB;UACM+J,aAAahK,YAAY,IAAZ,IAAoBA,YAAY,IAAnD;UACIgK,UAAJ,EAAgB;YACRC,eAAenN,MAAMoN,IAAN,EAArB;YACID,gBAAgB3D,gBAAgB2D,aAAavI,IAAb,EAAhB,EAAqC0D,KAArC,CAA2C,CAAC,CAA5C,MAAmD,GAAvE,EAA4E;;;;;YAKxE3F,MAAN;;;;QAII0K,cAAc3N,EAAE,QAAF,EAAYM,KAAZ,EAAmBgE,MAAvC;;;QAGIqJ,cAAc,CAAd,IAAmBtO,gBAAgB,GAAvC,EAA4C;YACpC4D,MAAN;;;;;;;;;;;;;AAaN,AAAe,SAAS2K,YAAT,CAAmBjI,QAAnB,EAA6B3F,CAA7B,EAAgC;IAC3CyB,wBAAF,EAA4BkE,QAA5B,EAAsCxF,IAAtC,CAA2C,UAAC0C,KAAD,EAAQxC,IAAR,EAAiB;QACpDC,QAAQN,EAAEK,IAAF,CAAd;QACI8M,SAASpF,SAASzH,KAAT,CAAb;QACI,CAAC6M,MAAL,EAAa;eACFnE,kBAAe1I,KAAf,EAAsBN,CAAtB,CAAT;eACSM,KAAT,EAAgBN,CAAhB,EAAmBmN,MAAnB;;;;QAIEA,SAAS,CAAb,EAAgB;YACRlK,MAAN;KADF,MAEO;;0BAEe3C,KAApB,EAA2BN,CAA3B,EAA8BmN,MAA9B;;GAbJ;;SAiBOnN,CAAP;;;ACrGa,SAAS6N,YAAT,CAAsBlI,QAAtB,EAAgC3F,CAAhC,EAA+C;MAAZ8N,KAAY,uEAAJ,EAAI;;IAC1DnM,eAAF,EAAmBgE,QAAnB,EAA6BxF,IAA7B,CAAkC,UAAC0C,KAAD,EAAQkL,MAAR,EAAmB;QAC7CC,UAAUhO,EAAE+N,MAAF,CAAhB;;;;;QAKI/N,EAAEgO,OAAF,EAAWrI,QAAX,EAAqBsI,OAArB,CAA6B,GAA7B,EAAkC3J,MAAlC,KAA6C,CAAjD,EAAoD;aAC3C0J,QAAQ/K,MAAR,EAAP;;;;QAIE6G,gBAAgB9J,EAAE+N,MAAF,EAAU7I,IAAV,EAAhB,MAAsC4I,KAA1C,EAAiD;aACxCE,QAAQ/K,MAAR,EAAP;;;;;QAKE4E,UAAU7H,EAAE+N,MAAF,CAAV,IAAuB,CAA3B,EAA8B;aACrBC,QAAQ/K,MAAR,EAAP;;;WAGK+K,OAAP;GArBF;;SAwBOhO,CAAP;;;AC5BF;;AAEA,AAAe,SAASkO,kBAAT,CAAyBnI,OAAzB,EAAkC/F,CAAlC,EAAqC;;;;MAI9C4E,iBAAc5E,EAAE,MAAF,CAAd,EAAyBA,CAAzB,EAA4B,KAA5B,CAAJ;MACI4E,iBAAc5E,EAAE,MAAF,CAAd,EAAyBA,CAAzB,EAA4B,KAA5B,CAAJ;;SAEOA,CAAP;;;ACJF,SAASmO,UAAT,CAAoBnO,CAApB,EAAuBoO,OAAvB,EAAgC5N,IAAhC,EAAsC6N,QAAtC,EAAgD;UACxC7N,IAAN,QAAe6N,QAAf,EAAyBlO,IAAzB,CAA8B,UAACC,CAAD,EAAIC,IAAJ,EAAa;QACnCwE,QAAQC,SAASzE,IAAT,CAAd;QACMd,MAAMsF,MAAMrE,IAAN,CAAZ;;QAEIjB,GAAJ,EAAS;UACD+O,cAAc7O,IAAIjB,OAAJ,CAAY4P,OAAZ,EAAqB7O,GAArB,CAApB;cACQc,IAAR,EAAcG,IAAd,EAAoB8N,WAApB;;GANJ;;;AAWF,AAAe,SAASC,oBAAT,CAA2BF,QAA3B,EAAqCrO,CAArC,EAAwCT,GAAxC,EAA6C;GACzD,MAAD,EAAS,KAAT,EAAgBmK,OAAhB,CAAwB;WAAQyE,WAAWnO,CAAX,EAAcT,GAAd,EAAmBiB,IAAnB,EAAyB6N,QAAzB,CAAR;GAAxB;;SAEOA,QAAP;;;ACtBK,SAAShG,UAAT,CAAoBnD,IAApB,EAA0B;SACxBA,KAAK4B,IAAL,GACKiD,OADL,CACa,MADb,EACqB,GADrB,EAEKzF,MAFZ;;;;;;AAQF,AAAO,SAASsI,WAAT,CAAqBtM,KAArB,EAA4B;MAC3BkO,kBAAkBnG,WAAW/H,MAAM4E,IAAN,EAAX,CAAxB;;MAEMuJ,WAAWnO,MAAMsF,IAAN,CAAW,GAAX,EAAgBV,IAAhB,EAAjB;MACMwJ,aAAarG,WAAWoG,QAAX,CAAnB;;MAEID,kBAAkB,CAAtB,EAAyB;WAChBE,aAAaF,eAApB;GADF,MAEO,IAAIA,oBAAoB,CAApB,IAAyBE,aAAa,CAA1C,EAA6C;WAC3C,CAAP;;;SAGK,CAAP;;;ACnBF;;AAEA,AAAe,SAASC,kBAAT,CACb3O,CADa,EAEb4O,SAFa,EAGbC,WAHa,EAKb;MADAjB,YACA,uEADY,IACZ;;MACMkB,aAAaF,UAAUG,MAAV,CAAiB;WAAQF,YAAYG,OAAZ,CAAoBC,IAApB,MAA8B,CAAC,CAAvC;GAAjB,CAAnB;;;;;;;;UAEWA,IAHX;;UAIQC,OAAO,MAAb;UACM3O,QAAQ,OAAd;;UAEM4O,QAAQnP,YAAUkP,IAAV,UAAmBD,IAAnB,QAAd;;;;;UAKMG,SACJD,MAAMlO,GAAN,CAAU,UAAC4B,KAAD,EAAQxC,IAAR;eAAiBL,EAAEK,IAAF,EAAQG,IAAR,CAAaD,KAAb,CAAjB;OAAV,EACM8O,OADN,GAEMN,MAFN,CAEa;eAAQ7J,SAAS,EAAjB;OAFb,CADF;;;;;;UASIkK,OAAO9K,MAAP,KAAkB,CAAtB,EAAyB;YACnBgL,kBAAJ;;;YAGI1B,YAAJ,EAAe;sBACD2B,UAAUH,OAAO,CAAP,CAAV,EAAqBpP,CAArB,CAAZ;SADF,MAEO;sBACOoP,OAAO,CAAP,CAAZ;;;;aAGKE;;;;;sCA5BQR,UAAnB,4GAA+B;;;;;;;;;;;;;;;;;;;;;;SAiCxB,IAAP;;;AC3CF,SAASU,UAAT,CAAoBlP,KAApB,EAA2BmP,WAA3B,EAAwC;;;MAGlCnP,MAAM+D,QAAN,GAAiBC,MAAjB,GAA0BmL,WAA9B,EAA2C;WAClC,KAAP;;;MAGEC,iBAAcpP,KAAd,CAAJ,EAA0B;WACjB,KAAP;;;SAGK,IAAP;;;;;;AAMF,AAAe,SAASqP,uBAAT,CACb3P,CADa,EAEb4P,SAFa,EAKb;MAFAH,WAEA,uEAFc,CAEd;MADAI,QACA,uEADW,IACX;;;;;;sCACuBD,SAAvB,4GAAkC;UAAvB1O,QAAuB;;UAC1BiO,QAAQnP,EAAEkB,QAAF,CAAd;;;;UAIIiO,MAAM7K,MAAN,KAAiB,CAArB,EAAwB;YAChBhE,QAAQN,EAAEmP,MAAM,CAAN,CAAF,CAAd;;YAEIK,WAAWlP,KAAX,EAAkBmP,WAAlB,CAAJ,EAAoC;cAC9BzD,gBAAJ;cACI6D,QAAJ,EAAc;sBACFvP,MAAM4E,IAAN,EAAV;WADF,MAEO;sBACK5E,MAAM2E,IAAN,EAAV;;;cAGE+G,OAAJ,EAAa;mBACJA,OAAP;;;;;;;;;;;;;;;;;;;;SAMD,IAAP;;;AChDF;AACA,AAAe,SAASuD,SAAT,CAAmBrK,IAAnB,EAAyBlF,CAAzB,EAA4B;;;MAGnC8P,YAAY9P,aAAWkF,IAAX,cAA0BA,IAA1B,EAAlB;SACO4K,cAAc,EAAd,GAAmB5K,IAAnB,GAA0B4K,SAAjC;;;ACHa,SAASJ,gBAAT,CAAuBpP,KAAvB,EAA8B;MACrCoE,UAAUpE,MAAMoE,OAAN,GAAgB2K,OAAhB,EAAhB;MACMU,gBAAgBrL,QAAQkB,IAAR,CAAa,UAACe,MAAD,EAAY;QACvC9B,QAAQC,SAAS6B,MAAT,CAAd;QACeqJ,SAF8B,GAEZnL,KAFY,CAErCoL,KAFqC;QAEnBlN,EAFmB,GAEZ8B,KAFY,CAEnB9B,EAFmB;;QAGvCC,aAAgBgN,SAAhB,SAA6BjN,EAAnC;WACOC,WAAWyI,QAAX,CAAoB,SAApB,CAAP;GAJoB,CAAtB;;SAOOsE,kBAAkBG,SAAzB;;;ACXF;;;;AAIA,AAAe,SAASC,gBAAT,CAA0B7P,KAA1B,EAAiC;SACvCA,MAAM4E,IAAN,GAAa4B,IAAb,GAAoBxC,MAApB,IAA8B,GAArC;;;ACHa,SAAS8L,WAAT,CAAqBpQ,CAArB,EAAwB;SAC9BA,EAAEmC,cAAF,EAAkBmC,MAAlB,GAA2B,CAAlC;;;ACHa,SAASQ,QAAT,CAAkBzE,IAAlB,EAAwB;MAC7BgQ,OAD6B,GACLhQ,IADK,CAC7BgQ,OAD6B;MACpBC,UADoB,GACLjQ,IADK,CACpBiQ,UADoB;;;MAGjC,CAACD,OAAD,IAAYC,UAAhB,EAA4B;QACpBzL,QAAQ,iBAAgByL,UAAhB,EAA4B9J,MAA5B,CAAmC,UAACC,GAAD,EAAM5D,KAAN,EAAgB;UACzDrC,OAAO8P,WAAWzN,KAAX,CAAb;;UAEI,CAACrC,KAAKyO,IAAN,IAAc,CAACzO,KAAKD,KAAxB,EAA+B,OAAOkG,GAAP;;UAE3BjG,KAAKyO,IAAT,IAAiBzO,KAAKD,KAAtB;aACOkG,GAAP;KANY,EAOX,EAPW,CAAd;WAQO5B,KAAP;;;SAGKwL,OAAP;;;ACfa,SAASE,OAAT,CAAiBlQ,IAAjB,EAAuBG,IAAvB,EAA6BgQ,GAA7B,EAAkC;MAC3CnQ,KAAKgQ,OAAT,EAAkB;SACXA,OAAL,CAAa7P,IAAb,IAAqBgQ,GAArB;GADF,MAEO,IAAInQ,KAAKiQ,UAAT,EAAqB;SACrBG,YAAL,CAAkBjQ,IAAlB,EAAwBgQ,GAAxB;;;SAGKnQ,IAAP;;;ACPa,SAASqQ,QAAT,CAAkBrQ,IAAlB,EAAwBwE,KAAxB,EAA+B;MACxCxE,KAAKgQ,OAAT,EAAkB;SACXA,OAAL,GAAexL,KAAf;GADF,MAEO,IAAIxE,KAAKiQ,UAAT,EAAqB;WACnBjQ,KAAKiQ,UAAL,CAAgBhM,MAAhB,GAAyB,CAAhC,EAAmC;WAC5BqM,eAAL,CAAqBtQ,KAAKiQ,UAAL,CAAgB,CAAhB,EAAmBrB,IAAxC;;;qBAGcpK,KAAhB,EAAuB6E,OAAvB,CAA+B,UAAC1E,GAAD,EAAS;WACjCyL,YAAL,CAAkBzL,GAAlB,EAAuBH,MAAMG,GAAN,CAAvB;KADF;;;SAKK3E,IAAP;;;ACbF,mBACA,AACA,AACA,AACA,AACA,AACA,AACA,AACA,AACA,AACA,AACA,AACA,AACA,AACA,AACA,AACA,AACA,AACA,AACA,AACA,AACA,AACA,AACA,AACA,AACA;;ACzBO,IAAMuQ,UAAU,IAAIzS,MAAJ,CAAW,WAAX,EAAwB,GAAxB,CAAhB;AACP,AAAO,IAAM0S,WAAW,IAAI1S,MAAJ,CAAW,kBAAX,EAA+B,GAA/B,CAAjB;;AAEP,AAAO,IAAM2S,iBAAiB,CAC5B,QAD4B,EAE5B,OAF4B,EAG5B,MAH4B,EAI5B1S,IAJ4B,CAIvB,GAJuB,CAAvB;;ACIP;;;;;AAKA,AAAe,SAAS2S,uBAAT,CAAiC/Q,CAAjC,EAAoC;IAC/C,KAAF,EAASG,IAAT,CAAc,UAACC,CAAD,EAAIyF,GAAJ,EAAY;QAClBhB,QAAQC,SAASe,GAAT,CAAd;;qBAEgBhB,KAAhB,EAAuB6E,OAAvB,CAA+B,UAAClJ,IAAD,EAAU;UACjCD,QAAQsE,MAAMrE,IAAN,CAAd;;UAEIA,SAAS,KAAT,IAAkBoQ,QAAQtR,IAAR,CAAaiB,KAAb,CAAlB,IACAsQ,SAASvR,IAAT,CAAciB,KAAd,CADJ,EAC0B;UACtBsF,GAAF,EAAOrF,IAAP,CAAY,KAAZ,EAAmBD,KAAnB;;KALJ;GAHF;;SAaOP,CAAP;;;ACxBF,SAASgR,SAAT,CAAmBnO,KAAnB,EAA0BxC,IAA1B,EAAgC;SACvBA,KAAK6O,IAAL,KAAc,SAArB;;;AAGF,SAAS+B,aAAT,CAAuBjR,CAAvB,EAA0B;IACtBkR,IAAF,GAAStL,IAAT,CAAc,GAAd,EACST,QADT,GAES4J,MAFT,CAEgBiC,SAFhB,EAGS/N,MAHT;;SAKOjD,CAAP;;;AAGF,AAAe,SAASmR,KAAT,CAAenR,CAAf,EAAkB;IAC7B8Q,cAAF,EAAkB7N,MAAlB;;MAEIgO,cAAcjR,CAAd,CAAJ;SACOA,CAAP;;;ACVF,IAAMoR,WAAW;;;;;;;;QAAA,kBAQF7R,GARE,EAQG8R,gBARH,EAQqB7R,SARrB,EAQgC;;;;;;;;;oBAAA;;mBAGzC6R,gBAHyC;;;;;2BAAA,GAIrB;+BACL,IADK;4BAER,GAFQ;yBAGX;kCACS,WADT;oCAEW;;eATqB;;;uBAalC,EAAEzS,MAAMyS,gBAAR,EAA0B1S,UAAU2S,aAApC,EAAT;;;;;;qBAEexR,gBAAcP,GAAd,EAAmBC,SAAnB,CAf4B;;;oBAAA;;;mBAkBzC+R,OAAOrS,KAlBkC;;;;;qBAmBpCsS,MAAP,GAAgB,IAAhB;+CACOD,MApBoC;;;+CAuBtC,MAAKE,WAAL,CAAiBF,MAAjB,CAvBsC;;;;;;;;;GARhC;aAAA,6BAkC0B;QAArBvF,OAAqB,QAA3BpN,IAA2B;QAAZD,QAAY,QAAZA,QAAY;QACfS,WADe,GACCT,SAASQ,OADV,CAC/B,cAD+B;;;;;QAKnC,CAACC,YAAYqM,QAAZ,CAAqB,MAArB,CAAD,IACA,CAACrM,YAAYqM,QAAZ,CAAqB,MAArB,CADL,EACmC;YAC3B,IAAIxM,KAAJ,CAAU,qCAAV,CAAN;;;QAGEe,IAAIlC,QAAQ4T,IAAR,CAAa1F,OAAb,EAAsB,EAAE2F,qBAAqB,IAAvB,EAAtB,CAAR;;QAEI3R,EAAEkR,IAAF,GAAS7M,QAAT,GAAoBC,MAApB,KAA+B,CAAnC,EAAsC;YAC9B,IAAIrF,KAAJ,CAAU,kCAAV,CAAN;;;QAGEyB,kBAAkBV,CAAlB,CAAJ;QACI+Q,wBAAwB/Q,CAAxB,CAAJ;QACImR,MAAMnR,CAAN,CAAJ;;WAEOA,CAAP;;CAtDJ,CA0DA;;ACnEA,IAAM4R,QAAQ,SAARA,KAAQ,CAACC,SAAD,EAAYC,OAAZ;SACZA,QAAQtL,MAAR,CAAe,UAACC,GAAD,EAAMsL,MAAN,EAAiB;QAC1BA,MAAJ,IAAcF,SAAd;WACOpL,GAAP;GAFF,EAGG,EAHH,CADY;CAAd;;AAOA,AAAe,SAASuL,qBAAT,CAA+BH,SAA/B,EAA0C;SAChDA,UAAUI,gBAAV,GACLL,MAAMC,SAAN,GAAkBA,UAAUE,MAA5B,4BAAuCF,UAAUI,gBAAjD,GADK,GAGLL,MAAMC,SAAN,EAAiB,CAACA,UAAUE,MAAX,CAAjB,CAHF;;;ACRK,IAAMG,mBAAmB;UACtB,cADsB;WAErB;;;;eAII,CACT,wBADS,CAJJ;;;WASA,EATA;;;gBAaK;gBACA;;GAhBgB;;UAoBtB;eACK,CACT,mBADS;GArBiB;;SA0BvB;eACM,CACT,gBADS;GA3BiB;;kBAgCd;eACH,CACT,kBADS;;CAjCR;;ACAA,IAAMC,iBAAiB;UACpB,WADoB;WAEnB;;eAEI,CACT,qBADS,EAET,cAFS,EAGT,iBAHS,CAFJ;;;WASA,CACL,KADK,EAEL,uBAFK,CATA;;;;;;;;gBAoBK;;UAEN,IAFM;;;gBAKA,kBAAC7R,KAAD,EAAQN,CAAR,EAAc;YAChBoS,YAAYpS,EAAEjC,OAAF,GAAYiC,EAAEM,MAAM4E,IAAN,EAAF,CAAZ,GAA8B5E,MAAM+D,QAAN,EAAhD;YACI+N,UAAU9N,MAAV,KAAqB,CAArB,IAA0B8N,UAAU9T,GAAV,CAAc,CAAd,MAAqB4R,SAA/C,IACFkC,UAAU9T,GAAV,CAAc,CAAd,EAAiBkF,OAAjB,CAAyBC,WAAzB,OAA2C,KAD7C,EACoD;iBAC3C,QAAP;;;eAGK,IAAP;;;GAlCsB;;SAuCrB;eACM,CACT,uBADS,EAET,qBAFS,EAGT,IAHS;GAxCe;;UA+CpB;eACK,CACT,aADS,EAET,sBAFS;GAhDe;;OAsDvB;eACQ,CACT,sBADS;GAvDe;;kBA4DZ;eACH,CACT,CAAC,kCAAD,EAAqC,UAArC,CADS,EAET,wBAFS;;CA7DR;;ACAA,IAAM4O,qBAAqB;UACxB,eADwB;WAEvB;eACI,CACT,kBADS,CADJ;;oBAKS,KALT;;;gBAQK;sBACM,oBAAC/R,KAAD,EAAW;YACnBiJ,UAAUjJ,MAAMoE,OAAN,CAAc,UAAd,CAAhB;;YAEI6E,QAAQlF,QAAR,CAAiB,KAAjB,EAAwBC,MAAxB,KAAmC,CAAvC,EAA0C;kBAChCgO,OAAR,CAAgBhS,KAAhB;;OALM;0BAQU,YARV;kBASE;KAjBP;;;WAqBA,CACL,iBADK,EAEL,oCAFK,EAGL,MAHK,EAIL,SAJK;;GAvBuB;;UAgCxB,wBAhCwB;;SAkCzB;eACM,CACT,UADS;GAnCmB;;kBAwChB;eACH,CACT,sBADS;;;CAzCR;;ACAA,IAAMiS,mBAAmB;UACtB,aADsB;;WAGrB;gBACK;;;;;+BAKe,2BAACjS,KAAD,EAAQN,CAAR,EAAc;YAC/BwS,SAASlS,MAAMsF,IAAN,CAAW,QAAX,CAAf;YACM6M,kBAAkBzS,EAAE,iCAAF,CAAxB;wBACgByM,MAAhB,CAAuB+F,MAAvB;cACMxO,WAAN,CAAkByO,eAAlB;OATQ;;;;SAcP;KAfE;;eAkBI,CACT,uBADS,CAlBJ;;oBAsBS,KAtBT;;WAwBA,CACL,qBADK,EAEL,QAFK,EAGL,sBAHK;GA3BqB;;UAkCtB;eACK,CACT,kCADS;GAnCiB;;kBAwCd;eACH,CACT,CAAC,4CAAD,EAA+C,cAA/C,CADS;;;CAzCR;;ACAA,IAAMC,mBAAmB;UACtB,iBADsB;;SAGvB;eACM,CACT,aADS,EAET,aAFS;GAJiB;;UAUtB;eACK,CACT,CAAC,qBAAD,EAAwB,OAAxB,CADS,EAET,WAFS,EAGT,SAHS;GAXiB;;WAkBrB;eACI,CACT,cADS,EAET,eAFS,CADJ;;gBAMK;oBACI,kBAACpS,KAAD,EAAW;YACnBqS,MAAMrS,MAAME,IAAN,CAAW,KAAX,CAAV;;;;;;;;;;YAUMgF,QAAQ,GAAd;;cAEMmN,IAAI5I,OAAJ,CAAY,UAAZ,EAAwBvE,KAAxB,CAAN;cACMhF,IAAN,CAAW,KAAX,EAAkBmS,GAAlB;;KArBG;;WAyBA,CACL,KADK,EAEL,qBAFK,EAGL,2BAHK,EAIL,kBAJK,EAKL,mBALK,EAML,QANK,EAOL,kBAPK,EAQL,SARK,EASL,WATK;GA3CqB;;kBAwDd,IAxDc;;kBA0Dd,IA1Dc;;OA4DzB,IA5DyB;;iBA8Df,IA9De;;WAgErB;CAhEJ;;ACAP;;AAEA,AAAO,IAAMC,uBAAuB;UAC1B,qBAD0B;SAE3B;eACM,CACT,QADS;GAHqB;;UAQ1B;eACK,CACT,0DADS;GATqB;;WAczB;eACI,CACT,eADS,CADJ;;;;gBAOK,EAPL;;;;;WAaA;GA3ByB;;kBAgClB;eACH,CACT,CAAC,gCAAD,EAAmC,UAAnC,CADS;GAjCqB;;kBAsClB,IAtCkB;;OAwC7B,IAxC6B;;iBA0CnB,IA1CmB;;WA4CzB;CA5CJ;;ACFP;;;AAGA,AAAO,IAAMC,qBAAqB;UACxB,mBADwB;SAEzB;eACM,CACT,UADS;GAHmB;;UAQxB;eACK,CACT,eADS;GATmB;;WAcvB;eACI,CACT,iBADS,EAET,iBAFS,CADJ;;;;gBAQK,EARL;;;;;WAcA;GA5BuB;;kBAiChB;eACH,CACT,CAAC,qCAAD,EAAwC,OAAxC,CADS;GAlCmB;;kBAuChB;eACH,CACT,CAAC,uBAAD,EAA0B,OAA1B,CADS;GAxCmB;;OA6C3B;eACQ,CACT,CAAC,6BAAD,EAAgC,OAAhC,CADS;GA9CmB;;iBAmDjB,IAnDiB;;WAqDvB;CArDJ;;ACHP;;;AAGA,AAAO,IAAMC,iBAAiB;UACpB,eADoB;SAErB;eACM,CACT,eADS;GAHe;;UASpB;eACK,CACT,iBADS;GAVe;;WAgBnB;eACI,CACT,iBADS,CADJ;;;;gBAQK,EARL;;;;;WAcA,CACL,kBADK;GA9BmB;;kBAoCZ;eACH,CACT,CAAC,gCAAD,EAAmC,OAAnC,CADS;GArCe;;kBA0CZ;eACH,CACT,CAAC,uBAAD,EAA0B,OAA1B,CADS;GA3Ce;;OAgDvB;eACQ,CACT,CAAC,6BAAD,EAAgC,OAAhC,CADS;GAjDe;;iBAsDb,IAtDa;;WAwDnB;CAxDJ;;ACHP;;;AAGA,AAAO,IAAMC,eAAe;UAClB,aADkB;SAEnB;eACM,CACT,IADS;GAHa;;UASlB;eACK,CACT,qBADS;GAVa;;WAgBjB;eACI,CACT,cADS,CADJ;;;;gBAQK,EARL;;;;;WAcA,CACL,cADK;GA9BiB;;kBAoCV;eACH,CACT,WADS;GArCa;;kBA0CV;eACH;GA3Ca;;OAgDrB;eACQ,CACT,CAAC,0BAAD,EAA6B,OAA7B,CADS;GAjDa;;iBAsDX,IAtDW;;WAwDjB;CAxDJ;;ACHP;;;AAGA,AAAO,IAAMC,iBAAiB;UACpB,eADoB;SAErB;eACM,CACT,sBADS;GAHe;;UASpB;eACK,CACT,oBADS;GAVe;;WAgBnB;eACI;;qBAAA,CADJ;;;;gBAQK,EARL;;;;;WAcA,CACL,iBADK;GA9BmB;;kBAoCZ;eACH,CACT,CAAC,qBAAD,EAAwB,UAAxB,CADS;GArCe;;kBA0CZ;eACH,CACT,CAAC,uBAAD,EAA0B,OAA1B,CADS;GA3Ce;;OAgDvB;eACQ,CACT,CAAC,6BAAD,EAAgC,OAAhC,CADS;GAjDe;;iBAuDb,IAvDa;;WAyDnB;CAzDJ;;ACHP;;;AAGA,AAAO,IAAMC,oBAAoB;UACvB,kBADuB;SAExB;eACM,CACT,qBADS;GAHkB;;UASvB;eACK,CACT,gCADS,EACyB,gBADzB;GAVkB;;WAgBtB;eACI,CACT,gBADS,CADJ;;oBAMS,KANT;;;;gBAUK;UACN;KAXC;;;;;WAiBA,CACL,oBADK,EAEL,uEAFK,EAGL,YAHK;GAjCsB;;kBAwCf;eACH,CACT,gBADS;GAzCkB;;kBA+Cf;eACH,CACT,CAAC,uBAAD,EAA0B,OAA1B,CADS;GAhDkB;;OAqD1B;eACQ,CACT,CAAC,0BAAD,EAA6B,OAA7B,CADS;GAtDkB;;iBA2DhB,IA3DgB;;WA6DtB;CA7DJ;;ACHP;;;AAGA,AAAO,IAAMC,iBAAiB;UACpB,kBADoB;SAErB;eACM,CACT,gBADS;GAHe;;UASpB;eACK,CACT,eADS,EACQ,KADR;GAVe;;WAgBnB;eACI,CACT,eADS,EAET,gBAFS,CADJ;;;;gBASK,EATL;;;;;WAeA;GA/BmB;;kBAoCZ;eACH,CACT,CAAC,qCAAD,EAAwC,OAAxC,CADS;GArCe;;kBA0CZ;eACH,CACT,CAAC,uBAAD,EAA0B,OAA1B,CADS;GA3Ce;;OAgDvB;eACQ,CACT,CAAC,6BAAD,EAAgC,OAAhC,CADS;GAjDe;;iBAsDb,IAtDa;;WAwDnB;CAxDJ;;ACHP;;;AAGA,AAAO,IAAMC,wBAAwB;UAC3B,sBAD2B;SAE5B;eACM,CACT,eADS;GAHsB;;UAS3B;eACK,CACT,CAAC,qBAAD,EAAwB,OAAxB,CADS;GAVsB;;WAgB1B;eACI;;uBAAA,EAGT,kBAHS,CADJ;;;;gBASK,EATL;;;;;WAeA;GA/B0B;;kBAoCnB;eACH,CACT,CAAC,uBAAD,EAA0B,OAA1B,CADS;GArCsB;;iBA0CpB,IA1CoB;;WA4C1B;CA5CJ;;ACHP;;;AAGA,AAAO,IAAMC,oBAAoB;UACvB,kBADuB;SAExB;eACM;;KAER,uBAAD,EAA0B,OAA1B,CAFS;GAHkB;;UASvB;eACK,CACT,oCADS;GAVkB;;WAetB;eACI;;yBAAA,EAGT,gBAHS,EAGS,aAHT,EAIT,aAJS,CADJ;;;;gBAUK,EAVL;;;;;WAgBA,CACL,YADK;GA/BsB;;kBAoCf;eACH,CACT,CAAC,+CAAD,EAAkD,UAAlD,CADS;GArCkB;;kBA2Cf;eACH;;KAER,uBAAD,EAA0B,OAA1B,CAFS;GA5CkB;;OAmD1B;eACQ,CACT,CAAC,0BAAD,EAA6B,OAA7B,CADS;GApDkB;;iBAyDhB,IAzDgB;;WA2DtB;CA3DJ;;ACHA,IAAMC,oBAAoB;UACvB,cADuB;;oBAGb,CAChB,aADgB,EAEhB,gBAFgB,EAGhB,YAHgB,EAIhB,aAJgB,EAKhB,cALgB,EAMhB,WANgB,CAHa;;SAYxB;eACM,CACT,aADS;GAbkB;;UAkBvB;eACK,CACT,SADS;GAnBkB;;WAwBtB;eACI,CACT,eADS,EAET,gBAFS,CADJ;;;;gBAQK;0DAC0C,8CAAC/S,KAAD,EAAW;YACvDgT,YAAYhT,MAAME,IAAN,CAAW,IAAX,EAAiBqK,KAAjB,CAAuB,UAAvB,EAAmC,CAAnC,CAAlB;cACMrK,IAAN,CAAW,KAAX,qCAAmD8S,SAAnD;;KAXG;;;;;WAkBA;GA1CsB;;kBA8Cf;eACH,CACT,CAAC,wBAAD,EAA2B,UAA3B,CADS;GA/CkB;;kBAoDf;eACH,CACT,CAAC,uBAAD,EAA0B,OAA1B,CADS;GArDkB;;OA0D1B;eACQ;;;GA3DkB;;iBAgEhB;eACF;;;GAjEkB;;WAsEtB;eACI;;;;CAvER;;ACAP;;;AAGA,AAAO,IAAMC,yBAAyB;UAC5B,uBAD4B;SAE7B;eACM,CACT,kBADS;GAHuB;;UAQ5B;eACK,CACT,uBADS;GATuB;;WAc3B;eACI,CACT,2BADS,CADJ;;;;gBAOK,EAPL;;;;;WAaA;GA3B2B;;kBAgCpB;eACH,CACT,CAAC,8BAAD,EAAiC,OAAjC,CADS;GAjCuB;;kBAsCpB;eACH,CACT,CAAC,uBAAD,EAA0B,OAA1B,CADS;GAvCuB;;OA4C/B;eACQ,CACT,CAAC,6BAAD,EAAgC,OAAhC,CADS;GA7CuB;;iBAkDrB;eACF;;;GAnDuB;;WAwD3B;eACI;;;;CAzDR;;ACHP;;;AAGA,AAAO,IAAMC,4BAA4B;UAC/B,0BAD+B;SAEhC;eACM,CACT,aADS;GAH0B;;UAQ/B;eACK,CACT,mBADS;GAT0B;;WAc9B;eACI,CACT,mBADS,CADJ;;;;gBAOK;wDACwC,+CAAClT,KAAD,EAAQN,CAAR,EAAc;YACxDyT,OAAOC,KAAKhU,KAAL,CAAWY,MAAME,IAAN,CAAW,YAAX,CAAX,CAAb;YACQmS,GAFsD,GAE9Cc,KAAKE,OAAL,CAAa,CAAb,CAF8C,CAEtDhB,GAFsD;;YAGxDtN,OAAOrF,EAAE,SAAF,EAAaQ,IAAb,CAAkB,KAAlB,EAAyBmS,GAAzB,CAAb;cACM3O,WAAN,CAAkBqB,IAAlB;;KAZG;;;;;WAmBA;GAjC8B;;kBAsCvB;eACH,CACT,CAAC,kCAAD,EAAqC,UAArC,CADS;GAvC0B;;kBA4CvB;eACH,CACT,CAAC,uBAAD,EAA0B,OAA1B,CADS;GA7C0B;;OAkDlC;eACQ,CACT,CAAC,wBAAD,EAA2B,OAA3B,CADS;GAnD0B;;iBAwDxB;eACF;;;GAzD0B;;WA8D9B;eACI;;;;CA/DR;;ACHA,IAAMuO,kBAAkB;UACrB,YADqB;;oBAGX,CAChB,4BADgB,CAHW;;SAOtB;eACM,CACT,IADS;GARgB;;UAarB;eACK,CACT,CAAC,qBAAD,EAAwB,OAAxB,CADS;GAdgB;;WAmBpB;eACI,CACT,kBADS,CADJ;;;;gBAOK;;cAEF,gBAACtT,KAAD,EAAW;YACXuT,OACJ,kEADF;YAEMC,QAAQC,mBAAmBzT,MAAME,IAAN,CAAW,gBAAX,CAAnB,CAAd;;YAEIqT,KAAKvU,IAAL,CAAUwU,KAAV,CAAJ,EAAsB;6BACGA,MAAM5L,KAAN,CAAY2L,IAAZ,CADH;;cACbzT,CADa;cACVkT,SADU;;;gBAEd9S,IAAN,CAAW,KAAX,qCAAmD8S,SAAnD;cACM/J,UAAUjJ,MAAMoE,OAAN,CAAc,QAAd,CAAhB;kBACQ4N,OAAR,CAAgBhS,MAAM0T,KAAN,EAAhB;gBACM/Q,MAAN;;;KAnBC;;;;;WA2BA;GA9CoB;;kBAmDb;eACH,CACT,CAAC,gBAAD,EAAmB,UAAnB,CADS;GApDgB;;kBAyDb;eACH,CACT,CAAC,uBAAD,EAA0B,OAA1B,CADS;GA1DgB;;OA+DxB;eACQ;;;GAhEgB;;iBAqEd;eACF;;;GAtEgB;;WA2EpB;eACI;;;;CA5ER;;;;;;;;;;;;;;;;;;;;;;;;;ACGP,iBAAe,aAAYgR,gBAAZ,EAA8BzN,MAA9B,CAAqC,UAACC,GAAD,EAAMzB,GAAN,EAAc;MAC1D6M,YAAYoC,iBAAiBjP,GAAjB,CAAlB;sBAEKyB,GADL,EAEKuL,sBAAsBH,SAAtB,CAFL;CAFa,EAMZ,EANY,CAAf;;ACHA;AACA,AAAO,IAAMqC,kBAAkB,wCAAxB;;;;AAIP,AAAO,IAAMC,eAAe,IAAIhW,MAAJ,CAAW,aAAX,EAA0B,GAA1B,CAArB;;;;;;;;;;AAUP,AAAO;;;;;;;AAQP,AAAO;;;AAKP,AAAO,IAAMiW,iBAAiB,WAAvB;AACP,AAAO,IAAMC,kBAAkB,WAAxB;AACP,AAAO,IAAMC,uBAAuB,4BAA7B;AACP,AAAO,IAAMC,yBAAyB,oBAA/B;AACP,AAAO,IAAMC,wBAAwB,QAA9B;AACP,IAAMC,SAAS,CACb,KADa,EAEb,KAFa,EAGb,KAHa,EAIb,KAJa,EAKb,KALa,EAMb,KANa,EAOb,KAPa,EAQb,KARa,EASb,KATa,EAUb,KAVa,EAWb,KAXa,EAYb,KAZa,CAAf;AAcA,IAAMC,YAAYD,OAAOrW,IAAP,CAAY,GAAZ,CAAlB;AACA,IAAMuW,aAAa,qCAAnB;AACA,IAAMC,aAAa,wCAAnB;AACA,AAAO,IAAMC,oBACX,IAAI1W,MAAJ,OAAewW,UAAf,WAA+BC,UAA/B,wBAA4DF,SAA5D,QAA0E,IAA1E,CADK;;;;;AAMP,AAAO,IAAMI,qBAAqB,gBAA3B;;AAEP,AAAO,IAAMC,oBACX,IAAI5W,MAAJ,CAAW,2BAAX,EAAwC,GAAxC,CADK;;ACxDP;;AAEA,AAAe,SAAS6W,WAAT,CAAqBC,MAArB,EAA6B;SACnCA,OAAOlL,OAAP,CAAemK,eAAf,EAAgC,IAAhC,EAAsCpN,IAAtC,EAAP;;;ACHa,SAASqK,OAAT,CAAe+D,YAAf,EAA6B;iBAC3BA,aAAapO,IAAb,EAAf;MACIqO,SAASC,QAAT,CAAkBF,YAAlB,CAAJ,EAAqC;WAC5BA,YAAP;;;SAGK,IAAP;;;ACHF;;AAEA,AAAe,SAASG,QAAT,CAAkBC,GAAlB,QAAuC;MAAdtV,CAAc,QAAdA,CAAc;MAAXuV,OAAW,QAAXA,OAAW;;;MAEhDD,IAAIhR,MAAJ,GAAa,IAAb,IAAqBgR,IAAIhR,MAAJ,GAAa,CAAtC,EAAyC,OAAO,IAAP;;;MAGrCiR,WAAWxJ,eAAewJ,OAAf,EAAwB,EAAxB,MAAgCxJ,eAAeuJ,GAAf,EAAoB,EAApB,CAA/C,EAAwE,OAAO,IAAP;;MAElEE,UAAUjG,UAAU+F,GAAV,EAAetV,CAAf,CAAhB;;;;MAIImU,aAAa7U,IAAb,CAAkBkW,OAAlB,CAAJ,EAAgC,OAAO,IAAP;;SAEzBA,QAAQ1O,IAAR,EAAP;;;ACnBF;;;;AAIA,AASA,AAAO,SAAS2O,eAAT,CAAyBC,UAAzB,EAAqC;SACnC,CAACA,WAAWxN,KAAX,CAAiB2M,iBAAjB,KAAuC,EAAxC,EACWzW,IADX,CACgB,GADhB,EAEW2L,OAFX,CAEmByK,qBAFnB,EAE0C,GAF1C,EAGWzK,OAHX,CAGmBwK,sBAHnB,EAG2C,UAH3C,EAIWxK,OAJX,CAImBuK,oBAJnB,EAIyC,IAJzC,EAKWxN,IALX,EAAP;;;;;AAUF,AAAe,SAAS6O,kBAAT,CAA4BD,UAA5B,EAAwC;;MAEjDtB,eAAe9U,IAAf,CAAoBoW,UAApB,KAAmCrB,gBAAgB/U,IAAhB,CAAqBoW,UAArB,CAAvC,EAAyE;iBAC1DnQ,SAASmQ,UAAT,EAAqB,EAArB,CAAb;;;MAGEE,OAAOC,OAAO,IAAIC,IAAJ,CAASJ,UAAT,CAAP,CAAX;;MAEI,CAACE,KAAKG,OAAL,EAAL,EAAqB;iBACNN,gBAAgBC,UAAhB,CAAb;WACOG,OAAO,IAAIC,IAAJ,CAASJ,UAAT,CAAP,CAAP;;;SAGKE,KAAKG,OAAL,KAAiBH,KAAKI,WAAL,EAAjB,GAAsC,IAA7C;;;ACzBF;AACA,AAAe,SAASC,gBAAT,CACblQ,OADa,QASb;MANE/F,CAMF,QANEA,CAMF;mCALEkW,kBAKF;MALEA,kBAKF,yCALuB,IAKvB;wBAJEpI,KAIF;MAJEA,KAIF,8BAJU,EAIV;sBAHEvO,GAGF;MAHEA,GAGF,4BAHQ,EAGR;iCAFE4W,cAEF;MAFEA,cAEF,uCAFmB,IAEnB;;;;qBAGgBpQ,OAAhB,EAAyB/F,CAAzB;;;;;MAKImW,cAAJ,EAAoBzQ,YAAYK,OAAZ,EAAqB/F,CAArB;;;;;aAKT+F,OAAX,EAAoB/F,CAApB,EAAuBT,GAAvB;;;;gBAIcwG,OAAd,EAAuB/F,CAAvB;;;;;gBAKW+F,OAAX,EAAoB/F,CAApB;;;eAGa+F,OAAb,EAAsB/F,CAAtB,EAAyB8N,KAAzB;;;uBAGkB/H,OAAlB,EAA2B/F,CAA3B,EAA8BT,GAA9B;;;;;;MAMI4W,cAAJ,EAAoBvI,aAAU7H,OAAV,EAAmB/F,CAAnB,EAAsBkW,kBAAtB;;;cAGRnQ,OAAZ,EAAqB/F,CAArB;;;qBAGgB+F,OAAhB,EAAyB/F,CAAzB;;SAEO+F,OAAP;;;AC5Da,SAASqQ,aAAT,CAAoBtI,KAApB,QAAuC;MAAVvO,GAAU,QAAVA,GAAU;MAALS,CAAK,QAALA,CAAK;;;;MAGhD8U,mBAAmBxV,IAAnB,CAAwBwO,KAAxB,CAAJ,EAAoC;YAC1BuI,kBAAkBvI,KAAlB,EAAyBvO,GAAzB,CAAR;;;;;MAKEuO,MAAMxJ,MAAN,GAAe,GAAnB,EAAwB;;QAEhBgS,KAAKtW,EAAE,IAAF,CAAX;QACIsW,GAAGhS,MAAH,KAAc,CAAlB,EAAqB;cACXgS,GAAGpR,IAAH,EAAR;;;;;SAKGqK,UAAUzB,KAAV,EAAiB9N,CAAjB,EAAoB8G,IAApB,EAAP;;;ACfF,SAASyP,sBAAT,CAAgCC,UAAhC,EAA4CtR,IAA5C,EAAkD;;;;MAI5CsR,WAAWlS,MAAX,IAAqB,CAAzB,EAA4B;;;;;UAIpBmS,aAAaD,WAAWhQ,MAAX,CAAkB,UAACC,GAAD,EAAMiQ,SAAN,EAAoB;YACnDA,SAAJ,IAAiBjQ,IAAIiQ,SAAJ,IAAiBjQ,IAAIiQ,SAAJ,IAAiB,CAAlC,GAAsC,CAAvD;eACOjQ,GAAP;OAFiB,EAGhB,EAHgB,CAAnB;;kCAME,iBAAgBgQ,UAAhB,EACQjQ,MADR,CACe,UAACC,GAAD,EAAMzB,GAAN,EAAc;YAChByB,IAAI,CAAJ,IAASgQ,WAAWzR,GAAX,CAAb,EAA8B;iBACrB,CAACA,GAAD,EAAMyR,WAAWzR,GAAX,CAAN,CAAP;;;eAGKyB,GAAP;OANT,EAOU,CAAC,CAAD,EAAI,CAAJ,CAPV,CAVwB;;UASnBkQ,OATmB;UASVC,SATU;;;;;;;;UAuBtBA,aAAa,CAAb,IAAkBD,QAAQrS,MAAR,IAAkB,CAAxC,EAA2C;qBAC5BY,KAAK2F,KAAL,CAAW8L,OAAX,CAAb;;;UAGIE,YAAY,CAACL,WAAW,CAAX,CAAD,EAAgBA,WAAW5N,KAAX,CAAiB,CAAC,CAAlB,CAAhB,CAAlB;UACMkO,aAAaD,UAAUrQ,MAAV,CAAiB,UAACC,GAAD,EAAMhJ,GAAN;eAAcgJ,IAAInC,MAAJ,GAAa7G,IAAI6G,MAAjB,GAA0BmC,GAA1B,GAAgChJ,GAA9C;OAAjB,EAAoE,EAApE,CAAnB;;UAEIqZ,WAAWxS,MAAX,GAAoB,EAAxB,EAA4B;;aACnBwS;;;;;WAGF5R;;;;;;;SAGF,IAAP;;;AAGF,SAAS6R,oBAAT,CAA8BP,UAA9B,EAA0CjX,GAA1C,EAA+C;;;;;;;mBAO5BE,IAAIC,KAAJ,CAAUH,GAAV,CAP4B;MAOrC6L,IAPqC,cAOrCA,IAPqC;;MAQvC4L,cAAc5L,KAAKrB,OAAL,CAAagL,iBAAb,EAAgC,EAAhC,CAApB;;MAEMkC,YAAYT,WAAW,CAAX,EAAc/S,WAAd,GAA4BsG,OAA5B,CAAoC,GAApC,EAAyC,EAAzC,CAAlB;MACMmN,iBAAiBC,MAAMC,WAAN,CAAkBH,SAAlB,EAA6BD,WAA7B,CAAvB;;MAEIE,iBAAiB,GAAjB,IAAwBD,UAAU3S,MAAV,GAAmB,CAA/C,EAAkD;WACzCkS,WAAW5N,KAAX,CAAiB,CAAjB,EAAoBxK,IAApB,CAAyB,EAAzB,CAAP;;;MAGIiZ,UAAUb,WAAW5N,KAAX,CAAiB,CAAC,CAAlB,EAAqB,CAArB,EAAwBnF,WAAxB,GAAsCsG,OAAtC,CAA8C,GAA9C,EAAmD,EAAnD,CAAhB;MACMuN,eAAeH,MAAMC,WAAN,CAAkBC,OAAlB,EAA2BL,WAA3B,CAArB;;MAEIM,eAAe,GAAf,IAAsBD,QAAQ/S,MAAR,IAAkB,CAA5C,EAA+C;WACtCkS,WAAW5N,KAAX,CAAiB,CAAjB,EAAoB,CAAC,CAArB,EAAwBxK,IAAxB,CAA6B,EAA7B,CAAP;;;SAGK,IAAP;;;;;AAKF,AAAe,SAASiY,iBAAT,CAA2BvI,KAA3B,EAA4C;MAAVvO,GAAU,uEAAJ,EAAI;;;;MAGnDiX,aAAa1I,MAAMjD,KAAN,CAAYiK,kBAAZ,CAAnB;MACI0B,WAAWlS,MAAX,KAAsB,CAA1B,EAA6B;WACpBwJ,KAAP;;;MAGEyJ,WAAWhB,uBAAuBC,UAAvB,EAAmC1I,KAAnC,CAAf;MACIyJ,QAAJ,EAAc,OAAOA,QAAP;;aAEHR,qBAAqBP,UAArB,EAAiCjX,GAAjC,CAAX;MACIgY,QAAJ,EAAc,OAAOA,QAAP;;;;SAIPzJ,KAAP;;;AC1FF,IAAM0J,WAAW;UACPxC,WADO;kBAECyC,OAFD;OAGVpC,QAHU;kBAICM,kBAJD;WAKN+B,gBALM;SAMRtB;CANT,CASA,AAEA,AACA,AACA,AACA,AACA,AACA,AACA;;ACdA;;;;;;;;;;;AAWA,AAAe,SAASuB,eAAT,CAAyB3X,CAAzB,EAA4B4X,IAA5B,EAAkC;;;;;;MAM3CA,KAAKjV,uBAAT,EAAkC;QAC5BA,wBAAwB3C,CAAxB,CAAJ;;;MAGE2E,uBAAoB3E,CAApB,CAAJ;MACIyJ,gBAAazJ,CAAb,EAAgB4X,KAAKzO,WAArB,CAAJ;MACM0O,gBAAgB5K,oBAAiBjN,CAAjB,CAAtB;;SAEO6X,aAAP;;;AC3BF,IAAMC,0BAA0B;eACjB;6BACc,IADd;iBAEE,IAFF;wBAGS;GAJQ;;;;;;;;;;;;;;;;;;;;;SAAA,yBA0BGF,IA1BH,EA0BS;QAA7B5X,CAA6B,QAA7BA,CAA6B;QAA1BiF,IAA0B,QAA1BA,IAA0B;QAApB6I,KAAoB,QAApBA,KAAoB;QAAbvO,GAAa,QAAbA,GAAa;;wBACzB,KAAKwY,WAAjB,EAAiCH,IAAjC;;QAEI5X,KAAKlC,QAAQ4T,IAAR,CAAazM,IAAb,CAAT;;;;QAII5E,OAAO,KAAK2X,cAAL,CAAoBhY,CAApB,EAAuB8N,KAAvB,EAA8BvO,GAA9B,EAAmCqY,IAAnC,CAAX;;QAEIzH,iBAAiB9P,IAAjB,CAAJ,EAA4B;aACnB,KAAK4X,kBAAL,CAAwB5X,IAAxB,EAA8BL,CAA9B,CAAP;;;;;;;;;;wCAKgB,iBAAgB4X,IAAhB,EAAsB7I,MAAtB,CAA6B;eAAK6I,KAAKM,CAAL,MAAY,IAAjB;OAA7B,CAAlB,4GAAuE;YAA5DlT,GAA4D;;aAChEA,GAAL,IAAY,KAAZ;YACIlH,QAAQ4T,IAAR,CAAazM,IAAb,CAAJ;;eAEO,KAAK+S,cAAL,CAAoBhY,CAApB,EAAuB8N,KAAvB,EAA8BvO,GAA9B,EAAmCqY,IAAnC,CAAP;;YAEIzH,iBAAiB9P,IAAjB,CAAJ,EAA4B;;;;;;;;;;;;;;;;;;;WAKvB,KAAK4X,kBAAL,CAAwB5X,IAAxB,EAA8BL,CAA9B,CAAP;GApD4B;;;;gBAAA,0BAwDfA,CAxDe,EAwDZ8N,KAxDY,EAwDLvO,GAxDK,EAwDAqY,IAxDA,EAwDM;WAC3BF,iBACGC,gBAAgB3X,CAAhB,EAAmB4X,IAAnB,CADH,EAEL;UAAA;0BAEsBA,KAAK1B,kBAF3B;kBAAA;;KAFK,CAAP;GAzD4B;;;;;;oBAAA,8BAsEX7V,IAtEW,EAsELL,CAtEK,EAsEF;QACtB,CAACK,IAAL,EAAW;aACF,IAAP;;;WAGKyJ,gBAAgB9J,EAAEiF,IAAF,CAAO5E,IAAP,CAAhB,CAAP;;;;;;;CA3EJ,CAqFA;;AC7FA;;;;;;;AAOA,AAAO,IAAM8X,yBAAyB,CACpC,iBADoC,EAEpC,UAFoC,EAGpC,SAHoC,EAIpC,UAJoC,EAKpC,OALoC,CAA/B;;;;AAUP,AAAO,IAAMC,uBAAuB,CAClC,UADkC,CAA7B;;;;;;;;;AAWP,AAAO,IAAMC,yBAAyB,CACpC,sBADoC,EAEpC,kBAFoC,EAGpC,kBAHoC,EAIpC,YAJoC,EAKpC,mBALoC,EAMpC,cANoC,CAA/B;;AASP,AAAO,IAAMC,uBAAuB,CAClC,YADkC,EAElC,cAFkC,EAGlC,cAHkC,EAIlC,aAJkC,EAKlC,aALkC,EAMlC,aANkC,EAOlC,aAPkC,EAQlC,eARkC,EASlC,eATkC,EAUlC,iBAVkC,EAWlC,UAXkC,EAYlC,YAZkC,EAalC,IAbkC,EAclC,iBAdkC,EAelC,OAfkC,CAA7B;;ACxBP,IAAMC,wBAAwB;SAAA,yBACG;QAArBvY,CAAqB,QAArBA,CAAqB;QAAlBT,GAAkB,QAAlBA,GAAkB;QAAbiZ,SAAa,QAAbA,SAAa;;;;QAGzB1K,cAAJ;;YAEQa,mBAAgB3O,CAAhB,EAAmBmY,sBAAnB,EAA2CK,SAA3C,CAAR;QACI1K,KAAJ,EAAW,OAAOsI,cAAWtI,KAAX,EAAkB,EAAEvO,QAAF,EAAOS,IAAP,EAAlB,CAAP;;;;YAIH2P,wBAAqB3P,CAArB,EAAwBqY,sBAAxB,CAAR;QACIvK,KAAJ,EAAW,OAAOsI,cAAWtI,KAAX,EAAkB,EAAEvO,QAAF,EAAOS,IAAP,EAAlB,CAAP;;;YAGH2O,mBAAgB3O,CAAhB,EAAmBoY,oBAAnB,EAAyCI,SAAzC,CAAR;QACI1K,KAAJ,EAAW,OAAOsI,cAAWtI,KAAX,EAAkB,EAAEvO,QAAF,EAAOS,IAAP,EAAlB,CAAP;;;YAGH2P,wBAAqB3P,CAArB,EAAwBsY,oBAAxB,CAAR;QACIxK,KAAJ,EAAW,OAAOsI,cAAWtI,KAAX,EAAkB,EAAEvO,QAAF,EAAOS,IAAP,EAAlB,CAAP;;;WAGJ,EAAP;;CAvBJ,CA2BA;;ACxCA;;;;;;AAMA,AAAO,IAAMyY,mBAAmB,CAC9B,KAD8B,EAE9B,OAF8B,EAG9B,WAH8B,EAI9B,eAJ8B,EAK9B,YAL8B,EAM9B,WAN8B,EAO9B,SAP8B,CAAzB;;AAUP,AAAO,IAAMC,oBAAoB,GAA1B;;;;;;;;;AASP,AAAO,IAAMC,mBAAmB,CAC9B,sBAD8B,EAE9B,mBAF8B,EAG9B,oBAH8B,EAI9B,mBAJ8B,EAK9B,oBAL8B,EAM9B,qBAN8B,EAO9B,aAP8B,EAQ9B,iBAR8B,EAS9B,oBAT8B,EAU9B,qBAV8B,EAW9B,eAX8B,EAY9B,YAZ8B,EAa9B,YAb8B,EAc9B,cAd8B,EAe9B,cAf8B,EAgB9B,yBAhB8B,EAiB9B,qBAjB8B,EAkB9B,qBAlB8B,EAmB9B,SAnB8B,EAoB9B,SApB8B,EAqB9B,gBArB8B,EAsB9B,gBAtB8B,EAuB9B,SAvB8B,CAAzB;;;;AA4BP,IAAMC,WAAW,aAAjB;AACA,AAAO,IAAMC,sBAAsB,CACjC,CAAC,SAAD,EAAYD,QAAZ,CADiC,EAEjC,CAAC,SAAD,EAAYA,QAAZ,CAFiC,CAA5B;;ACzCP,IAAME,yBAAyB;SAAA,yBACH;QAAhB9Y,CAAgB,QAAhBA,CAAgB;QAAbwY,SAAa,QAAbA,SAAa;;QACpBvD,eAAJ;;;;aAIStG,mBAAgB3O,CAAhB,EAAmByY,gBAAnB,EAAqCD,SAArC,CAAT;QACIvD,UAAUA,OAAO3Q,MAAP,GAAgBoU,iBAA9B,EAAiD;aACxC1D,YAAYC,MAAZ,CAAP;;;;aAIOtF,wBAAqB3P,CAArB,EAAwB2Y,gBAAxB,EAA0C,CAA1C,CAAT;QACI1D,UAAUA,OAAO3Q,MAAP,GAAgBoU,iBAA9B,EAAiD;aACxC1D,YAAYC,MAAZ,CAAP;;;;;;;;;;wCAK8B4D,mBAAhC,4GAAqD;;;;;YAAzC3X,QAAyC;YAA/B6X,KAA+B;;YAC7C1Y,OAAOL,EAAEkB,QAAF,CAAb;YACIb,KAAKiE,MAAL,KAAgB,CAApB,EAAuB;cACfY,OAAO7E,KAAK6E,IAAL,EAAb;cACI6T,MAAMzZ,IAAN,CAAW4F,IAAX,CAAJ,EAAsB;mBACb8P,YAAY9P,IAAZ,CAAP;;;;;;;;;;;;;;;;;;;WAKC,IAAP;;CA7BJ,CAiCA;;AC9CA;;;;AAIA,AAAO,IAAM8T,2BAA2B,CACtC,wBADsC,EAEtC,aAFsC,EAGtC,SAHsC,EAItC,gBAJsC,EAKtC,WALsC,EAMtC,cANsC,EAOtC,UAPsC,EAQtC,UARsC,EAStC,SATsC,EAUtC,eAVsC,EAWtC,UAXsC,EAYtC,cAZsC,EAatC,qBAbsC,EActC,cAdsC,EAetC,SAfsC,EAgBtC,MAhBsC,CAAjC;;;;;AAsBP,AAAO,IAAMC,2BAA2B,CACtC,4BADsC,EAEtC,oBAFsC,EAGtC,0BAHsC,EAItC,kBAJsC,EAKtC,oBALsC,EAMtC,kBANsC,EAOtC,iBAPsC,EAQtC,aARsC,EAStC,eATsC,EAUtC,qBAVsC,EAWtC,mBAXsC,EAYtC,cAZsC,EAatC,aAbsC,EActC,YAdsC,EAetC,kBAfsC,EAgBtC,WAhBsC,EAiBtC,UAjBsC,CAAjC;;;;;AAuBP,IAAMC,kBAAkB,mDAAxB;AACA,AAAO,IAAMC,yBAAyB;;AAEpC,IAAIhb,MAAJ,CAAW,4BAAX,EAAyC,GAAzC,CAFoC;;;;AAMpC,IAAIA,MAAJ,CAAW,6BAAX,EAA0C,GAA1C,CANoC;;AAQpC,IAAIA,MAAJ,iBAAyB+a,eAAzB,kBAAuD,GAAvD,CARoC,CAA/B;;ACrCP,IAAME,gCAAgC;SAAA,yBACL;QAArBpZ,CAAqB,QAArBA,CAAqB;QAAlBT,GAAkB,QAAlBA,GAAkB;QAAbiZ,SAAa,QAAbA,SAAa;;QACzBa,sBAAJ;;;;oBAIgB1K,mBAAgB3O,CAAhB,EAAmBgZ,wBAAnB,EAA6CR,SAA7C,EAAwD,KAAxD,CAAhB;QACIa,aAAJ,EAAmB,OAAO1D,mBAAmB0D,aAAnB,CAAP;;;;oBAIH1J,wBAAqB3P,CAArB,EAAwBiZ,wBAAxB,CAAhB;QACII,aAAJ,EAAmB,OAAO1D,mBAAmB0D,aAAnB,CAAP;;;oBAGHrP,eAAezK,GAAf,EAAoB4Z,sBAApB,CAAhB;QACIE,aAAJ,EAAmB,OAAO1D,mBAAmB0D,aAAnB,CAAP;;WAEZ,IAAP;;CAlBJ,CAsBA;;ACnCA;;;;;;;;;;;;;;;;;AAiBA,IAAMC,sBAAsB;;SAAA,qBAEhB;WACD,IAAP;;CAHJ;;AAOA;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACxBA;;;AAGA,AAAO,IAAMC,2BAA2B,CACtC,UADsC,EAEtC,eAFsC,EAGtC,WAHsC,CAAjC;;AAMP,AAAO,IAAMC,2BAA2B,CACtC,qBADsC,CAAjC;;AAIP,AAAO,IAAMC,gCAAgC,CAC3C,QAD2C,EAE3C,YAF2C,EAG3C,OAH2C,EAI3C,OAJ2C,EAK3C,UAL2C,CAAtC;AAOP,AAAO,IAAMC,mCAAmC,IAAIvb,MAAJ,CAAWsb,8BAA8Brb,IAA9B,CAAmC,GAAnC,CAAX,EAAoD,GAApD,CAAzC;;AAEP,AAAO,IAAMub,gCAAgC,CAC3C,QAD2C,EAE3C,QAF2C,EAG3C,OAH2C,EAI3C,UAJ2C,EAK3C,UAL2C,EAM3C,MAN2C,EAO3C,IAP2C,EAQ3C,YAR2C,EAS3C,MAT2C,EAU3C,QAV2C,EAW3C,QAX2C,EAY3C,KAZ2C,EAa3C,QAb2C,EAc3C,SAd2C,EAe3C,QAf2C,EAgB3C,SAhB2C,EAiB3C,SAjB2C,EAkB3C,QAlB2C,EAmB3C,OAnB2C,EAoB3C,UApB2C,EAqB3C,SArB2C,EAsB3C,OAtB2C,EAuB3C,OAvB2C,EAwB3C,KAxB2C,EAyB3C,aAzB2C,CAAtC;AA2BP,AAAO,IAAMC,mCAAmC,IAAIzb,MAAJ,CAAWwb,8BAA8Bvb,IAA9B,CAAmC,GAAnC,CAAX,EAAoD,GAApD,CAAzC;;AAEP,AAAO,IAAMyb,SAAS,gBAAf;AACP,AAAO,IAAMC,SAAS,kBAAf;;AC3CP,SAASC,MAAT,CAAgBzZ,KAAhB,EAAuB;UACXA,MAAME,IAAN,CAAW,OAAX,KAAuB,EAAjC,WAAuCF,MAAME,IAAN,CAAW,IAAX,KAAoB,EAA3D;;;;AAIF,AAAO,SAASwZ,aAAT,CAAuBza,GAAvB,EAA4B;QAC3BA,IAAIuH,IAAJ,EAAN;MACIgB,QAAQ,CAAZ;;MAEI4R,iCAAiCpa,IAAjC,CAAsCC,GAAtC,CAAJ,EAAgD;aACrC,EAAT;;;MAGEqa,iCAAiCta,IAAjC,CAAsCC,GAAtC,CAAJ,EAAgD;aACrC,EAAT;;;;;MAKEsa,OAAOva,IAAP,CAAYC,GAAZ,CAAJ,EAAsB;aACX,EAAT;;;MAGEua,OAAOxa,IAAP,CAAYC,GAAZ,CAAJ,EAAsB;aACX,EAAT;;;;;SAKKuI,KAAP;;;;AAIF,AAAO,SAASmS,SAAT,CAAmB5U,IAAnB,EAAyB;MAC1BA,KAAK7E,IAAL,CAAU,KAAV,CAAJ,EAAsB;WACb,CAAP;;;SAGK,CAAP;;;;;AAKF,AAAO,SAAS0Z,cAAT,CAAwB7U,IAAxB,EAA8B;MAC/ByC,QAAQ,CAAZ;MACMqS,aAAa9U,KAAKX,OAAL,CAAa,QAAb,EAAuBsI,KAAvB,EAAnB;;MAEImN,WAAW7V,MAAX,KAAsB,CAA1B,EAA6B;aAClB,EAAT;;;MAGIiF,UAAUlE,KAAKsB,MAAL,EAAhB;MACIyT,iBAAJ;MACI7Q,QAAQjF,MAAR,KAAmB,CAAvB,EAA0B;eACbiF,QAAQ5C,MAAR,EAAX;;;GAGD4C,OAAD,EAAU6Q,QAAV,EAAoB1Q,OAApB,CAA4B,UAACpJ,KAAD,EAAW;QACjC6G,iBAAe7H,IAAf,CAAoBya,OAAOzZ,KAAP,CAApB,CAAJ,EAAwC;eAC7B,EAAT;;GAFJ;;SAMOwH,KAAP;;;;;AAKF,AAAO,SAASuS,cAAT,CAAwBhV,IAAxB,EAA8B;MAC/ByC,QAAQ,CAAZ;MACMyE,WAAWlH,KAAK9B,IAAL,EAAjB;MACMK,UAAU2I,SAASjO,GAAT,CAAa,CAAb,CAAhB;;MAEIsF,WAAWA,QAAQJ,OAAR,CAAgBC,WAAhB,OAAkC,YAAjD,EAA+D;aACpD,EAAT;;;MAGE0D,iBAAe7H,IAAf,CAAoBya,OAAOxN,QAAP,CAApB,CAAJ,EAA2C;aAChC,EAAT;;;SAGKzE,KAAP;;;AAGF,AAAO,SAASwS,iBAAT,CAA2BjV,IAA3B,EAAiC;MAClCyC,QAAQ,CAAZ;;MAEMtC,QAAQwC,WAAW3C,KAAK7E,IAAL,CAAU,OAAV,CAAX,CAAd;MACM8E,SAAS0C,WAAW3C,KAAK7E,IAAL,CAAU,QAAV,CAAX,CAAf;MACMmS,MAAMtN,KAAK7E,IAAL,CAAU,KAAV,CAAZ;;;MAGIgF,SAASA,SAAS,EAAtB,EAA0B;aACf,EAAT;;;;MAIEF,UAAUA,UAAU,EAAxB,EAA4B;aACjB,EAAT;;;MAGEE,SAASF,MAAT,IAAmB,CAACqN,IAAIlH,QAAJ,CAAa,QAAb,CAAxB,EAAgD;QACxC8O,OAAO/U,QAAQF,MAArB;QACIiV,OAAO,IAAX,EAAiB;;eACN,GAAT;KADF,MAEO;eACI/R,KAAKgS,KAAL,CAAWD,OAAO,IAAlB,CAAT;;;;SAIGzS,KAAP;;;AAGF,AAAO,SAAS2S,eAAT,CAAyBC,KAAzB,EAAgC7X,KAAhC,EAAuC;SACpC6X,MAAMpW,MAAN,GAAe,CAAhB,GAAqBzB,KAA5B;;;AC1GF;;;;;;;;AAQA,IAAM8X,+BAA+B;SAAA,yBACM;QAA/B3a,CAA+B,QAA/BA,CAA+B;QAA5BgM,OAA4B,QAA5BA,OAA4B;QAAnBwM,SAAmB,QAAnBA,SAAmB;QAARvT,IAAQ,QAARA,IAAQ;;QACnC2V,iBAAJ;QACI,CAAC5a,EAAEjC,OAAH,IAAciC,EAAE,MAAF,EAAUsE,MAAV,KAAqB,CAAvC,EAA0C;QACtC,GAAF,EAAO0I,KAAP,GAAesF,OAAf,CAAuBrN,IAAvB;;;;;;;QAOI4V,WACJlM,mBACE3O,CADF,EAEEuZ,wBAFF,EAGEf,SAHF,EAIE,KAJF,CADF;;QAQIqC,QAAJ,EAAc;iBACDpD,QAAWoD,QAAX,CAAX;;UAEID,QAAJ,EAAc,OAAOA,QAAP;;;;;;QAMVvM,WAAWrO,EAAEgM,OAAF,CAAjB;QACM8O,OAAO9a,EAAE,KAAF,EAASqO,QAAT,EAAmBgB,OAAnB,EAAb;QACM0L,YAAY,EAAlB;;SAEKrR,OAAL,CAAa,UAAC7D,GAAD,EAAMhD,KAAN,EAAgB;UACrBwC,OAAOrF,EAAE6F,GAAF,CAAb;UACM8M,MAAMtN,KAAK7E,IAAL,CAAU,KAAV,CAAZ;;UAEI,CAACmS,GAAL,EAAU;;UAEN7K,QAAQkS,cAAcrH,GAAd,CAAZ;eACSsH,UAAU5U,IAAV,CAAT;eACS6U,eAAe7U,IAAf,CAAT;eACSgV,eAAehV,IAAf,CAAT;eACSiV,kBAAkBjV,IAAlB,CAAT;eACSoV,gBAAgBK,IAAhB,EAAsBjY,KAAtB,CAAT;;gBAEU8P,GAAV,IAAiB7K,KAAjB;KAbF;;gCAiBE,iBAAgBiT,SAAhB,EAA2BvU,MAA3B,CAAkC,UAACC,GAAD,EAAMzB,GAAN;aAChC+V,UAAU/V,GAAV,IAAiByB,IAAI,CAAJ,CAAjB,GAA0B,CAACzB,GAAD,EAAM+V,UAAU/V,GAAV,CAAN,CAA1B,GAAkDyB,GADlB;KAAlC,EAEE,CAAC,IAAD,EAAO,CAAP,CAFF,CAhDqC;;QA+ChCuU,MA/CgC;QA+CxB5O,QA/CwB;;QAoDnCA,WAAW,CAAf,EAAkB;iBACLqL,QAAWuD,MAAX,CAAX;;UAEIJ,QAAJ,EAAc,OAAOA,QAAP;;;;;;;;;;wCAKOpB,wBAAvB,4GAAiD;YAAtCtY,QAAsC;;YACzCZ,QAAQN,EAAEkB,QAAF,EAAY8L,KAAZ,EAAd;YACM2F,MAAMrS,MAAME,IAAN,CAAW,KAAX,CAAZ;YACImS,GAAJ,EAAS;qBACI8E,QAAW9E,GAAX,CAAX;cACIiI,QAAJ,EAAc,OAAOA,QAAP;;;YAGVhb,OAAOU,MAAME,IAAN,CAAW,MAAX,CAAb;YACIZ,IAAJ,EAAU;qBACG6X,QAAW7X,IAAX,CAAX;cACIgb,QAAJ,EAAc,OAAOA,QAAP;;;YAGVra,QAAQD,MAAME,IAAN,CAAW,OAAX,CAAd;YACID,KAAJ,EAAW;qBACEkX,QAAWlX,KAAX,CAAX;cACIqa,QAAJ,EAAc,OAAOA,QAAP;;;;;;;;;;;;;;;;;;WAIX,IAAP;;CAlFJ;;AAsFA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AC7Ge,SAASK,eAAT,CAAyBnT,KAAzB,EAAgCoT,UAAhC,EAA4Ctb,IAA5C,EAAkD;;;;;;MAM3DkI,QAAQ,CAAZ,EAAe;QACPqT,aAAa,IAAIC,QAAQC,eAAZ,CAA4B,IAA5B,EAAkCH,UAAlC,EAA8Ctb,IAA9C,EAAoD0b,KAApD,EAAnB;;;;;;;QAOMC,cAAc,MAAMJ,UAA1B;QACMK,eAAe,EAAE,OAAOD,cAAc,GAArB,CAAF,CAArB;WACOzT,QAAQ0T,YAAf;;;SAGK,CAAP;;;ACnBa,SAASC,aAAT,CAAuBhN,QAAvB,EAAiC9D,OAAjC,EAA0C;;;;;MAKnD7C,QAAQ,CAAZ;;MAEI0C,YAAYlL,IAAZ,CAAiBmP,SAAS3H,IAAT,EAAjB,CAAJ,EAAuC;QAC/B4U,gBAAgBnW,SAASkJ,QAAT,EAAmB,EAAnB,CAAtB;;;;QAIIiN,gBAAgB,CAApB,EAAuB;cACb,CAAC,EAAT;KADF,MAEO;cACGlT,KAAKE,GAAL,CAAS,CAAT,EAAY,KAAKgT,aAAjB,CAAR;;;;;;QAME/Q,WAAWA,WAAW+Q,aAA1B,EAAyC;eAC9B,EAAT;;;;SAIG5T,KAAP;;;AC5Ba,SAAS6T,eAAT,CAAyBhR,OAAzB,EAAkCiR,IAAlC,EAAwC;;;;MAIjDjR,WAAW,CAACiR,IAAhB,EAAsB;WACb,EAAP;;;SAGK,CAAP;;;ACRK,IAAMvU,aAAW,IAAjB;;;;AAIP,AAAO,IAAMwU,0BAAwB,CACnC,OADmC,EAEnC,SAFmC,EAGnC,SAHmC,EAInC,SAJmC,EAKnC,QALmC,EAMnC,OANmC,EAOnC,OAPmC,EAQnC,OARmC,EASnC,KATmC,EAUnC,OAVmC,EAWnC,MAXmC,EAYnC,QAZmC,EAanC,KAbmC,EAcnC,iBAdmC,CAA9B;AAgBP,AAAO,IAAMC,6BAA2B,IAAI3d,MAAJ,CAAW0d,wBAAsBzd,IAAtB,CAA2B,GAA3B,CAAX,EAA4C,GAA5C,CAAjC;;;;;AAKP,AAAO,IAAM2d,sBAAoB,IAAI5d,MAAJ,CAAW,4CAAX,EAAyD,GAAzD,CAA1B;;;;AAIP,AAAO,IAAM6d,qBAAmB,IAAI7d,MAAJ,CAAW,kBAAX,EAA+B,GAA/B,CAAzB;;;;AAIP,AAAO,IAAM8d,sBAAoB,IAAI9d,MAAJ,CAAW,yBAAX,EAAsC,GAAtC,CAA1B;;8EAGP,AAAO,AAAMiE;;AClCE,SAAS8Z,oBAAT,CAA8Btc,IAA9B,EAAoC;;MAE7Ckc,2BAAyBxc,IAAzB,CAA8BM,IAA9B,CAAJ,EAAyC;WAChC,CAAC,EAAR;;;SAGK,CAAP;;;ACAF,SAASuc,SAAT,CAAiBC,KAAjB,EAAwB;UACZA,MAAM5b,IAAN,CAAW,OAAX,KAAuB,EAAjC,WAAuC4b,MAAM5b,IAAN,CAAW,IAAX,KAAoB,EAA3D;;;AAGF,AAAe,SAAS0Z,gBAAT,CAAwBkC,KAAxB,EAA+B;;;;MAIxC7S,UAAU6S,MAAMzV,MAAN,EAAd;MACI0V,gBAAgB,KAApB;MACIC,gBAAgB,KAApB;MACIxU,QAAQ,CAAZ;;cAEWvK,MAAM,CAAN,EAAS,CAAT,CAAX,EAAwBmM,OAAxB,CAAgC,YAAM;QAChCH,QAAQjF,MAAR,KAAmB,CAAvB,EAA0B;;;;QAIpBiY,aAAaJ,UAAQ5S,OAAR,EAAiB,GAAjB,CAAnB;;;;QAII,CAAC8S,aAAD,IAAkBja,QAAQ9C,IAAR,CAAaid,UAAb,CAAtB,EAAgD;sBAC9B,IAAhB;eACS,EAAT;;;;;;QAME,CAACD,aAAD,IAAkBpa,kBAAkB5C,IAAlB,CAAuBid,UAAvB,CAAlB,IACET,2BAAyBxc,IAAzB,CAA8Bid,UAA9B,CADN,EACiD;UAC3C,CAACva,kBAAkB1C,IAAlB,CAAuBid,UAAvB,CAAL,EAAyC;wBACvB,IAAhB;iBACS,EAAT;;;;cAIMhT,QAAQ5C,MAAR,EAAV;GAzBF;;SA4BOmB,KAAP;;;AC/Ca,SAAS0U,aAAT,CAAuBC,QAAvB,EAAiC;;;MAG1CR,oBAAkB3c,IAAlB,CAAuBmd,QAAvB,CAAJ,EAAsC;WAC7B,CAAC,GAAR;;;SAGK,CAAP;;;ACFa,SAASC,WAAT,CACb9c,IADa,EAEbsb,UAFa,EAGbyB,OAHa,EAIbnd,SAJa,EAKbiP,QALa,EAMbmO,YANa,EAOb;;MAEIA,aAAahX,IAAb,CAAkB;WAAOhG,SAASL,GAAhB;GAAlB,MAA2C2Q,SAA/C,EAA0D;WACjD,KAAP;;;;;MAKE,CAACtQ,IAAD,IAASA,SAASsb,UAAlB,IAAgCtb,SAAS+c,OAA7C,EAAsD;WAC7C,KAAP;;;MAGMhf,QAZR,GAYqB6B,SAZrB,CAYQ7B,QAZR;;mBAa+B8B,IAAIC,KAAJ,CAAUE,IAAV,CAb/B;MAakBid,QAblB,cAaQlf,QAbR;;;;;MAgBIkf,aAAalf,QAAjB,EAA2B;WAClB,KAAP;;;;;MAKImf,WAAWld,KAAKmK,OAAL,CAAa4S,OAAb,EAAsB,EAAtB,CAAjB;MACI,CAACtV,WAAS/H,IAAT,CAAcwd,QAAd,CAAL,EAA8B;WACrB,KAAP;;;;;MAKEhB,2BAAyBxc,IAAzB,CAA8BmP,QAA9B,CAAJ,EAA6C;WACpC,KAAP;;;;MAIEA,SAASnK,MAAT,GAAkB,EAAtB,EAA0B;WACjB,KAAP;;;SAGK,IAAP;;;ACpDa,SAASyY,YAAT,CAAsBnd,IAAtB,EAA4Bod,SAA5B,EAAuC;;;;;MAKhD,CAACA,UAAU1d,IAAV,CAAeM,IAAf,CAAL,EAA2B;WAClB,CAAC,EAAR;;;SAGK,CAAP;;;ACPa,SAASqd,iBAAT,CAA2BR,QAA3B,EAAqC;;MAE9CV,oBAAkBzc,IAAlB,CAAuBmd,QAAvB,CAAJ,EAAsC;WAC7B,EAAP;;;SAGK,CAAP;;;ACHa,SAASS,aAAT,CAAuBT,QAAvB,EAAiC;;MAE1CT,mBAAiB1c,IAAjB,CAAsBmd,QAAtB,CAAJ,EAAqC;;;;;QAK/BV,oBAAkBzc,IAAlB,CAAuBmd,QAAvB,CAAJ,EAAsC;aAC7B,CAAC,EAAR;;;;SAIG,CAAP;;;ACOK,SAASU,aAAT,CAAuBR,OAAvB,EAAgC;SAC9B,IAAIxe,MAAJ,OAAewe,OAAf,EAA0B,GAA1B,CAAP;;;AAGF,SAASR,OAAT,CAAiBC,KAAjB,EAAwB3N,QAAxB,EAAkC;UACtBA,YAAY2N,MAAMlX,IAAN,EAAtB,WAAsCkX,MAAM5b,IAAN,CAAW,OAAX,KAAuB,EAA7D,WAAmE4b,MAAM5b,IAAN,CAAW,IAAX,KAAoB,EAAvF;;;AAGF,AAAe,SAAS4c,UAAT,OAOZ;MANDC,KAMC,QANDA,KAMC;MALDnC,UAKC,QALDA,UAKC;MAJDyB,OAIC,QAJDA,OAIC;MAHDnd,SAGC,QAHDA,SAGC;MAFDQ,CAEC,QAFDA,CAEC;+BADD4c,YACC;MADDA,YACC,qCADc,EACd;;cACWpd,aAAaC,IAAIC,KAAJ,CAAUwb,UAAV,CAAzB;MACM8B,YAAYG,cAAcR,OAAd,CAAlB;MACMf,OAAOxL,YAAYpQ,CAAZ,CAAb;;;;;;;;;MASMsd,cAAcD,MAAM7W,MAAN,CAAa,UAAC+W,aAAD,EAAgBC,IAAhB,EAAyB;;;;QAIlD3Y,QAAQC,SAAS0Y,IAAT,CAAd;;;QAGI,CAAC3Y,MAAMjF,IAAX,EAAiB,OAAO2d,aAAP;;QAEX3d,OAAOgL,aAAa/F,MAAMjF,IAAnB,CAAb;QACMwc,QAAQpc,EAAEwd,IAAF,CAAd;QACM/O,WAAW2N,MAAMlX,IAAN,EAAjB;;QAEI,CAACwX,YAAY9c,IAAZ,EAAkBsb,UAAlB,EAA8ByB,OAA9B,EAAuCnd,SAAvC,EAAkDiP,QAAlD,EAA4DmO,YAA5D,CAAL,EAAgF;aACvEW,aAAP;;;;QAIE,CAACA,cAAc3d,IAAd,CAAL,EAA0B;oBACVA,IAAd,IAAsB;eACb,CADa;0BAAA;;OAAtB;KADF,MAMO;oBACSA,IAAd,EAAoB6O,QAApB,GAAkC8O,cAAc3d,IAAd,EAAoB6O,QAAtD,SAAkEA,QAAlE;;;QAGIgP,eAAeF,cAAc3d,IAAd,CAArB;QACM6c,WAAWN,QAAQC,KAAR,EAAe3N,QAAf,CAAjB;QACM9D,UAAUF,eAAe7K,IAAf,CAAhB;;QAEIkI,QAAQiV,aAAand,IAAb,EAAmBod,SAAnB,CAAZ;aACSC,kBAAkBR,QAAlB,CAAT;aACSS,cAAcT,QAAd,CAAT;aACSD,cAAcC,QAAd,CAAT;aACSvC,iBAAekC,KAAf,CAAT;aACSF,qBAAqBtc,IAArB,CAAT;aACS+b,gBAAgBhR,OAAhB,EAAyBiR,IAAzB,CAAT;aACSH,cAAchN,QAAd,EAAwB9D,OAAxB,CAAT;aACSsQ,gBAAgBnT,KAAhB,EAAuBoT,UAAvB,EAAmCtb,IAAnC,CAAT;;iBAEakI,KAAb,GAAqBA,KAArB;;WAEOyV,aAAP;GA5CkB,EA6CjB,EA7CiB,CAApB;;SA+CO,iBAAgBD,WAAhB,EAA6BhZ,MAA7B,KAAwC,CAAxC,GAA4C,IAA5C,GAAmDgZ,WAA1D;;;AC1FF;;AAEA,IAAMI,8BAA8B;SAAA,yBACgB;QAAxC1d,CAAwC,QAAxCA,CAAwC;QAArCT,GAAqC,QAArCA,GAAqC;QAAhCC,SAAgC,QAAhCA,SAAgC;iCAArBod,YAAqB;QAArBA,YAAqB,qCAAN,EAAM;;gBACpCpd,aAAaC,IAAIC,KAAJ,CAAUH,GAAV,CAAzB;;QAEM2b,aAAatQ,aAAarL,GAAb,CAAnB;QACMod,UAAUzR,eAAe3L,GAAf,EAAoBC,SAApB,CAAhB;;QAEM6d,QAAQrd,EAAE,SAAF,EAAaqP,OAAb,EAAd;;QAEMsO,cAAcP,WAAW;kBAAA;4BAAA;sBAAA;0BAAA;UAAA;;KAAX,CAApB;;;QAUI,CAACO,WAAL,EAAkB,OAAO,IAAP;;;;QAIZC,UAAU,iBAAgBD,WAAhB,EAA6BnX,MAA7B,CAAoC,UAACC,GAAD,EAAM+W,IAAN,EAAe;UAC3DK,aAAaF,YAAYH,IAAZ,CAAnB;aACOK,WAAW/V,KAAX,GAAmBrB,IAAIqB,KAAvB,GAA+B+V,UAA/B,GAA4CpX,GAAnD;KAFc,EAGb,EAAEqB,OAAO,CAAC,GAAV,EAHa,CAAhB;;;;QAOI8V,QAAQ9V,KAAR,IAAiB,EAArB,EAAyB;aAChB8V,QAAQhe,IAAf;;;WAGK,IAAP;;CAlCJ,CAsCA;;AChDO,IAAMke,2BAA2B,CACtC,QADsC,CAAjC;;ACKP,SAASC,WAAT,CAAqBxe,GAArB,EAA0B;MAClBC,YAAYC,IAAIC,KAAJ,CAAUH,GAAV,CAAlB;MACQ5B,QAFgB,GAEH6B,SAFG,CAEhB7B,QAFgB;;SAGjBA,QAAP;;;AAGF,SAAS4T,MAAT,CAAgBhS,GAAhB,EAAqB;SACZ;YAAA;YAEGwe,YAAYxe,GAAZ;GAFV;;;AAMF,IAAMye,sBAAsB;SAAA,yBACK;QAArBhe,CAAqB,QAArBA,CAAqB;QAAlBT,GAAkB,QAAlBA,GAAkB;QAAbiZ,SAAa,QAAbA,SAAa;;QACvByF,aAAaje,EAAE,qBAAF,CAAnB;QACIie,WAAW3Z,MAAX,KAAsB,CAA1B,EAA6B;UACrB1E,OAAOqe,WAAWzd,IAAX,CAAgB,MAAhB,CAAb;UACIZ,IAAJ,EAAU;eACD2R,OAAO3R,IAAP,CAAP;;;;QAIEse,UAAUvP,mBAAgB3O,CAAhB,EAAmB8d,wBAAnB,EAA6CtF,SAA7C,CAAhB;QACI0F,OAAJ,EAAa;aACJ3M,OAAO2M,OAAP,CAAP;;;WAGK3M,OAAOhS,GAAP,CAAP;;CAfJ,CAoBA;;ACtCO,IAAM4e,yBAAyB,CACpC,gBADoC,EAEpC,qBAFoC,CAA/B;;ACSA,SAAShN,OAAT,CAAenF,OAAf,EAAwBhM,CAAxB,EAA4C;MAAjBoe,SAAiB,uEAAL,GAAK;;YACvCpS,QAAQjC,OAAR,CAAgB,UAAhB,EAA4B,GAA5B,EAAiCjD,IAAjC,EAAV;SACOuX,UAAUrS,OAAV,EAAmBoS,SAAnB,EAA8B,EAAEE,SAAS,UAAX,EAA9B,CAAP;;;AAGF,IAAMC,0BAA0B;SAAA,yBACK;QAAzBve,CAAyB,QAAzBA,CAAyB;QAAtBgM,OAAsB,QAAtBA,OAAsB;QAAbwM,SAAa,QAAbA,SAAa;;QAC3BjD,UAAU5G,mBAAgB3O,CAAhB,EAAmBme,sBAAnB,EAA2C3F,SAA3C,CAAhB;QACIjD,OAAJ,EAAa;aACJpE,QAAM5B,UAAUgG,OAAV,EAAmBvV,CAAnB,CAAN,CAAP;;;QAGIoe,YAAY,GAAlB;QACMI,eAAexS,QAAQpD,KAAR,CAAc,CAAd,EAAiBwV,YAAY,CAA7B,CAArB;WACOjN,QAAMnR,EAAEwe,YAAF,EAAgBtZ,IAAhB,EAAN,EAA8BlF,CAA9B,EAAiCoe,SAAjC,CAAP;;CATJ,CAaA;;ACvBA,IAAMK,4BAA4B;SAAA,yBACX;QAAXzS,OAAW,QAAXA,OAAW;;QACbhM,IAAIlC,QAAQ4T,IAAR,CAAa1F,OAAb,CAAV;QACMqC,WAAWrO,EAAE,KAAF,EAASgN,KAAT,EAAjB;;QAEM9H,OAAO4E,gBAAgBuE,SAASnJ,IAAT,EAAhB,CAAb;WACOA,KAAK2F,KAAL,CAAW,IAAX,EAAiBvG,MAAxB;;CANJ,CAUA;;ACAA,IAAMoa,mBAAmB;;UAEf,GAFe;SAGhBnG,sBAAsBoG,OAHN;kBAIPvF,8BAA8BuF,OAJvB;UAKf7F,uBAAuB6F,OALR;WAMd7G,wBAAwB6G,OAAxB,CAAgCC,IAAhC,CAAqC9G,uBAArC,CANc;kBAOP6C,6BAA6BgE,OAPtB;OAQlBrF,oBAAoBqF,OARF;iBASRjB,4BAA4BiB,OATpB;kBAUPX,oBAAoBW,OAVb;WAWdJ,wBAAwBI,OAXV;cAYXF,0BAA0BE,OAZf;aAaZ;QAAG7Q,KAAH,QAAGA,KAAH;WAAe+Q,gBAAgBC,YAAhB,CAA6BhR,KAA7B,CAAf;GAbY;;SAAA,mBAefvP,OAfe,EAeN;QACP0G,IADO,GACK1G,OADL,CACP0G,IADO;QACDjF,CADC,GACKzB,OADL,CACDyB,CADC;;;QAGXiF,QAAQ,CAACjF,CAAb,EAAgB;UACR+e,SAASjhB,QAAQ4T,IAAR,CAAazM,IAAb,CAAf;cACQjF,CAAR,GAAY+e,MAAZ;;;QAGIjR,QAAQ,KAAKA,KAAL,CAAWvP,OAAX,CAAd;QACMygB,iBAAiB,KAAKA,cAAL,CAAoBzgB,OAApB,CAAvB;QACM0W,SAAS,KAAKA,MAAL,CAAY1W,OAAZ,CAAf;QACMyN,UAAU,KAAKA,OAAL,cAAkBzN,OAAlB,IAA2BuP,YAA3B,IAAhB;QACMmR,iBAAiB,KAAKA,cAAL,cAAyB1gB,OAAzB,IAAkCyN,gBAAlC,IAAvB;QACMsJ,MAAM,KAAKA,GAAL,cAAc/W,OAAd,IAAuByN,gBAAvB,IAAZ;QACMkT,gBAAgB,KAAKA,aAAL,CAAmB3gB,OAAnB,CAAtB;QACMgX,UAAU,KAAKA,OAAL,cAAkBhX,OAAlB,IAA2ByN,gBAA3B,IAAhB;QACMmT,aAAa,KAAKA,UAAL,cAAqB5gB,OAArB,IAA8ByN,gBAA9B,IAAnB;QACMoT,YAAY,KAAKA,SAAL,CAAe,EAAEtR,YAAF,EAAf,CAAlB;;0BACwB,KAAKuR,cAAL,CAAoB9gB,OAApB,CAlBT;QAkBPgB,GAlBO,mBAkBPA,GAlBO;QAkBFwS,MAlBE,mBAkBFA,MAlBE;;WAoBR;kBAAA;oBAAA;sBAGWiN,kBAAkB,IAH7B;cAAA;oCAAA;sBAAA;kCAAA;cAAA;oBAAA;sBAAA;4BAAA;;KAAP;;CAnCJ,CAoDA;;AC7De,SAASM,YAAT,CAAsB/f,GAAtB,EAA2BC,SAA3B,EAAsC;cACvCA,aAAaC,IAAIC,KAAJ,CAAUH,GAAV,CAAzB;mBACqBC,SAF8B;MAE3C7B,QAF2C,cAE3CA,QAF2C;;MAG7C4hB,aAAa5hB,SAASkN,KAAT,CAAe,GAAf,EAAoBjC,KAApB,CAA0B,CAAC,CAA3B,EAA8BxK,IAA9B,CAAmC,GAAnC,CAAnB;;SAEOohB,WAAW7hB,QAAX,KAAwB6hB,WAAWD,UAAX,CAAxB,IAAkDb,gBAAzD;;;ACNF;AACA,AAAO,SAASe,gBAAT,CAA0BpR,QAA1B,EAAoCrO,CAApC,QAAkD;MAATmR,KAAS,QAATA,KAAS;;MACnD,CAACA,KAAL,EAAY,OAAO9C,QAAP;;IAEV8C,MAAM/S,IAAN,CAAW,GAAX,CAAF,EAAmBiQ,QAAnB,EAA6BpL,MAA7B;;SAEOoL,QAAP;;;;AAIF,AAAO,SAASqR,iBAAT,CAA2BrR,QAA3B,EAAqCrO,CAArC,SAAwD;MAAd2f,UAAc,SAAdA,UAAc;;MACzD,CAACA,UAAL,EAAiB,OAAOtR,QAAP;;mBAEDsR,UAAhB,EAA4BjW,OAA5B,CAAoC,UAAC1E,GAAD,EAAS;QACrC4a,WAAW5f,EAAEgF,GAAF,EAAOqJ,QAAP,CAAjB;QACM9N,QAAQof,WAAW3a,GAAX,CAAd;;;QAGI,OAAOzE,KAAP,KAAiB,QAArB,EAA+B;eACpBJ,IAAT,CAAc,UAAC0C,KAAD,EAAQxC,IAAR,EAAiB;yBACfL,EAAEK,IAAF,CAAd,EAAuBL,CAAvB,EAA0B2f,WAAW3a,GAAX,CAA1B;OADF;KADF,MAIO,IAAI,OAAOzE,KAAP,KAAiB,UAArB,EAAiC;;eAE7BJ,IAAT,CAAc,UAAC0C,KAAD,EAAQxC,IAAR,EAAiB;YACvBkR,SAAShR,MAAMP,EAAEK,IAAF,CAAN,EAAeL,CAAf,CAAf;;YAEI,OAAOuR,MAAP,KAAkB,QAAtB,EAAgC;2BAChBvR,EAAEK,IAAF,CAAd,EAAuBL,CAAvB,EAA0BuR,MAA1B;;OAJJ;;GAXJ;;SAqBOlD,QAAP;;;AAGF,SAASwR,oBAAT,CAA8B7f,CAA9B,EAAiC4P,SAAjC,EAA4C;SACnCA,UAAUhK,IAAV,CAAe,UAAC1E,QAAD,EAAc;QAC9B4e,MAAMC,OAAN,CAAc7e,QAAd,CAAJ,EAA6B;qCACTA,QADS;UACpB8e,CADoB;UACjBxf,IADiB;;aAEpBR,EAAEggB,CAAF,EAAK1b,MAAL,KAAgB,CAAhB,IAAqBtE,EAAEggB,CAAF,EAAKxf,IAAL,CAAUA,IAAV,CAArB,IAAwCR,EAAEggB,CAAF,EAAKxf,IAAL,CAAUA,IAAV,EAAgBsG,IAAhB,OAA2B,EAA1E;;;WAGK9G,EAAEkB,QAAF,EAAYoD,MAAZ,KAAuB,CAAvB,IAA4BtE,EAAEkB,QAAF,EAAYgE,IAAZ,GAAmB4B,IAAnB,OAA8B,EAAjE;GANK,CAAP;;;AAUF,AAAO,SAASmZ,MAAT,CAAgBrI,IAAhB,EAAsB;MACnB5X,CADmB,GAC8B4X,IAD9B,CACnB5X,CADmB;MAChBkP,IADgB,GAC8B0I,IAD9B,CAChB1I,IADgB;MACVgR,cADU,GAC8BtI,IAD9B,CACVsI,cADU;0BAC8BtI,IAD9B,CACMuI,WADN;MACMA,WADN,qCACoB,KADpB;;;MAGvB,CAACD,cAAL,EAAqB,OAAO,IAAP;;;;MAIjB,OAAOA,cAAP,KAA0B,QAA9B,EAAwC,OAAOA,cAAP;;MAEhCtQ,SATmB,GASkBsQ,cATlB,CASnBtQ,SATmB;8BASkBsQ,cATlB,CASR/J,cATQ;MASRA,cATQ,yCASS,IATT;;;MAWrBiK,mBAAmBP,qBAAqB7f,CAArB,EAAwB4P,SAAxB,CAAzB;;MAEI,CAACwQ,gBAAL,EAAuB,OAAO,IAAP;;;;;;;;MAQnBD,WAAJ,EAAiB;QACX9R,WAAWrO,EAAEogB,gBAAF,CAAf;;;aAGSC,IAAT,CAAcrgB,EAAE,aAAF,CAAd;eACWqO,SAAS1H,MAAT,EAAX;;eAEW+Y,kBAAkBrR,QAAlB,EAA4BrO,CAA5B,EAA+BkgB,cAA/B,CAAX;eACWT,iBAAiBpR,QAAjB,EAA2BrO,CAA3B,EAA8BkgB,cAA9B,CAAX;;eAEW1I,SAAStI,IAAT,EAAeb,QAAf,eAA8BuJ,IAA9B,IAAoCzB,8BAApC,IAAX;;WAEOnW,EAAEiF,IAAF,CAAOoJ,QAAP,CAAP;;;MAGEkD,eAAJ;;;;MAIIuO,MAAMC,OAAN,CAAcK,gBAAd,CAAJ,EAAqC;2CACVA,gBADU;QAC5Blf,QAD4B;QAClBV,IADkB;;aAE1BR,EAAEkB,QAAF,EAAYV,IAAZ,CAAiBA,IAAjB,EAAuBsG,IAAvB,EAAT;GAFF,MAGO;aACI9G,EAAEogB,gBAAF,EAAoBlb,IAApB,GAA2B4B,IAA3B,EAAT;;;;;MAKEqP,cAAJ,EAAoB;WACXqB,SAAStI,IAAT,EAAeqC,MAAf,EAAuBqG,IAAvB,CAAP;;;SAGKrG,MAAP;;;AAGF,SAAS+O,aAAT,CAAuB1I,IAAvB,EAA6B;MACnB1I,IADmB,GACkB0I,IADlB,CACnB1I,IADmB;MACb2C,SADa,GACkB+F,IADlB,CACb/F,SADa;uBACkB+F,IADlB,CACF2I,QADE;MACFA,QADE,kCACS,IADT;;;MAGrBhP,SAAS0O,oBAAYrI,IAAZ,IAAkBsI,gBAAgBrO,UAAU3C,IAAV,CAAlC,IAAf;;;MAGIqC,MAAJ,EAAY;WACHA,MAAP;;;;;MAKEgP,QAAJ,EAAc,OAAO7B,iBAAiBxP,IAAjB,EAAuB0I,IAAvB,CAAP;;SAEP,IAAP;;;AAGF,IAAM4I,gBAAgB;SAAA,qBACwB;QAApC3O,SAAoC,uEAAxB6M,gBAAwB;QAAN9G,IAAM;gBACFA,IADE;QAClC6I,WADkC,SAClCA,WADkC;QACrBC,cADqB,SACrBA,cADqB;;;QAGtC7O,UAAUE,MAAV,KAAqB,GAAzB,EAA8B,OAAOF,UAAU8M,OAAV,CAAkB/G,IAAlB,CAAP;;wBAGzBA,IADL;;;;QAKI6I,WAAJ,EAAiB;UACTzU,WAAUsU,2BACX1I,IADW,IACL1I,MAAM,SADD,EACYiR,aAAa,IADzB,EAC+BrS,OAAO4S;SADtD;aAGO;;OAAP;;QAII5S,QAAQwS,2BAAmB1I,IAAnB,IAAyB1I,MAAM,OAA/B,IAAd;QACM8P,iBAAiBsB,2BAAmB1I,IAAnB,IAAyB1I,MAAM,gBAA/B,IAAvB;QACM+F,SAASqL,2BAAmB1I,IAAnB,IAAyB1I,MAAM,QAA/B,IAAf;QACMgQ,gBAAgBoB,2BAAmB1I,IAAnB,IAAyB1I,MAAM,eAA/B,IAAtB;QACMlD,UAAUsU,2BACX1I,IADW,IACL1I,MAAM,SADD,EACYiR,aAAa,IADzB,EAC+BrS;OAD/C;QAGMmR,iBAAiBqB,2BAAmB1I,IAAnB,IAAyB1I,MAAM,gBAA/B,EAAiDlD,gBAAjD,IAAvB;QACMuJ,UAAU+K,2BAAmB1I,IAAnB,IAAyB1I,MAAM,SAA/B,EAA0ClD,gBAA1C,IAAhB;QACMsJ,MAAMgL,2BAAmB1I,IAAnB,IAAyB1I,MAAM,KAA/B,EAAsClD,gBAAtC,EAA+CuJ,gBAA/C,IAAZ;QACM4J,aAAamB,2BAAmB1I,IAAnB,IAAyB1I,MAAM,YAA/B,EAA6ClD,gBAA7C,IAAnB;QACMoT,YAAYkB,2BAAmB1I,IAAnB,IAAyB1I,MAAM,WAA/B,EAA4CpB,YAA5C,IAAlB;;gBAEEwS,2BAAmB1I,IAAnB,IAAyB1I,MAAM,gBAA/B,QAAsD,EAAE3P,KAAK,IAAP,EAAawS,QAAQ,IAArB,EA/Bd;QA8BlCxS,GA9BkC,SA8BlCA,GA9BkC;QA8B7BwS,MA9B6B,SA8B7BA,MA9B6B;;WAiCnC;kBAAA;sBAAA;oBAAA;oCAAA;oCAAA;cAAA;kCAAA;cAAA;oBAAA;sBAAA;4BAAA;;KAAP;;CAlCJ,CAmDA;;AC3KA;wDAAe;QAEXmN,aAFW,SAEXA,aAFW;QAGXja,IAHW,SAGXA,IAHW;QAIXjF,CAJW,SAIXA,CAJW;QAKXwY,SALW,SAKXA,SALW;QAMXjH,MANW,SAMXA,MANW;QAOXoP,SAPW,SAOXA,SAPW;QAQX7S,KARW,SAQXA,KARW;QASXvO,GATW,SASXA,GATW;;;;;;;iBAAA,GAaD,CAbC;wBAAA,GAcQ,CAACqL,aAAarL,GAAb,CAAD,CAdR;;;;;;kBAkBN2f,iBAAiB0B,QAAQ,EAlBnB;;;;;qBAmBF,CAAT;;mBACUxP,SAASyP,MAAT,CAAgB3B,aAAhB,CApBC;;;aAAA;;mBAqBJlf,EAAEiF,IAAF,EAAP;;yBArBW,GAuBW;mBACfia,aADe;wBAAA;kBAAA;kCAAA;2BAKP,IALO;8BAMJpR,KANI;;aAvBX;0BAAA,GAiCY0S,cAAc7B,OAAd,CAAsBgC,SAAtB,EAAiCG,aAAjC,CAjCZ;;;yBAmCElV,IAAb,CAAkBsT,aAAlB;kCAEK3N,MADL;uBAEcA,OAAOvF,OAAnB,qBAA0C4U,KAA1C,aAAuDG,eAAe/U;;;4BAGxD+U,eAAe7B,aAA/B;;;;;sBAzCW,GA4CMR,iBAAiBS,UAAjB,CAA4B,EAAEnT,mBAAiBuF,OAAOvF,OAAxB,WAAF,EAA5B,CA5CN;0DA8CRuF,MA9CQ;2BA+CEqP,KA/CF;8BAgDKA,KAhDL;;;;;;;;;;GAAf;;WAA8BI,eAA9B;;;;SAA8BA,eAA9B;;;ACOA,IAAMC,UAAU;OAAA,iBACF1hB,GADE,EACG0F,IADH,EACoB;;;QAAX2S,IAAW,uEAAJ,EAAI;;;;;;;;oCAI5BA,IAJ4B,CAE9BsJ,aAF8B,EAE9BA,aAF8B,uCAEd,IAFc,yCAI5BtJ,IAJ4B,CAG9B2I,QAH8B,EAG9BA,QAH8B,kCAGnB,IAHmB;;;;;;kBAS5B,CAAChhB,GAAD,IAAQzB,QAAQC,OAApB,EAA6B;sBACrBojB,OAAOC,QAAP,CAAgBxhB,IAAtB,CAD2B;uBAEpBqF,QAAQnH,QAAQmH,IAAR,EAAf;;;uBAX8B,GAcdxF,IAAIC,KAAJ,CAAUH,GAAV,CAdc;;kBAgB3B7B,YAAY8B,SAAZ,CAhB2B;;;;;+CAiBvB5B,OAAOiC,MAjBgB;;;uBAAA,GAoBdyf,aAAa/f,GAAb,EAAkBC,SAAlB,CApBc;;;;qBAuBhB4R,SAASyP,MAAT,CAAgBthB,GAAhB,EAAqB0F,IAArB,EAA2BzF,SAA3B,CAvBgB;;;eAAA;;mBA0B5BQ,EAAEwR,MA1B0B;;;;;+CA2BvBxR,CA3BuB;;;;;;kBAgC5B,CAACiF,IAAL,EAAW;uBACFjF,EAAEiF,IAAF,EAAP;;;;;uBAjC8B,GAsCdjF,EAAE,MAAF,EAAUiB,GAAV,CAAc,UAACb,CAAD,EAAIC,IAAJ;uBAAaL,EAAEK,IAAF,EAAQG,IAAR,CAAa,MAAb,CAAb;eAAd,EAAiD6O,OAAjD,EAtCc;oBAAA,GAwCnBmR,cAAc7B,OAAd,CACXgC,SADW,EAEX;wBAAA;0BAAA;oBAAA;oCAAA;oCAAA;;eAFW,CAxCmB;wBAmDCpP,MAnDD,EAmDxBzD,KAnDwB,WAmDxBA,KAnDwB,EAmDjBoR,aAnDiB,WAmDjBA,aAnDiB;;;;oBAsD5BgC,iBAAiBhC,aAtDW;;;;;;qBAuDf8B,gBACb;oCAAA;4CAAA;0BAAA;oBAAA;oCAAA;8BAAA;4BAAA;;eADa,CAvDe;;;oBAAA;;;;;oCAqEzBzP,MADL;6BAEe,CAFf;gCAGkB;;;;+CAIbA,MA3EyB;;;;;;;;;GADpB;;;WA+EL,CAAC,CAACzT,QAAQC,OA/EL;;;;eAAA,yBAmFMwB,GAnFN,EAmFW;;;;;;;;;qBACV6R,SAASyP,MAAT,CAAgBthB,GAAhB,CADU;;;;;;;;;;;;;CAnF3B,CAyFA;;"}